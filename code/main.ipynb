{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3352b22-5ea7-4d30-bd93-ee4b59f226b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbdbcba9-a11c-4e9a-a6c8-9dee3b0c1380",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_path = \"data/train/X_train.npy\"\n",
    "y_train_path = \"data/train/y_train.npy\"\n",
    "X_test_path  = \"data/test/X_test.npy\"\n",
    "ids_train_path = \"data/train/ids.npy\"\n",
    "ids_test_path = \"data/test/ids.npy\"\n",
    "metadata_train_path = \"data/train/metadata_train.csv\"\n",
    "metadata_test_path = \"data/test/metadata_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a1ae09e-9ec8-4c03-a3b0-f55feffec03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(X_train_path, y_train_path, X_test_path, ids_train_path, ids_test_path):\n",
    "    X_train = np.load(X_train_path)\n",
    "    y_train = np.load(y_train_path)\n",
    "    X_test = np.load(X_test_path)\n",
    "    ids_train = np.load(ids_train_path)\n",
    "    ids_test = np.load(ids_test_path)\n",
    "    return X_train, y_train, X_test, ids_train, ids_test\n",
    "\n",
    "def load_metadata(metadata_train_path, metadata_test_path):\n",
    "    metadata_train = pd.read_csv(metadata_train_path)\n",
    "    metadata_test = pd.read_csv(metadata_test_path)\n",
    "    return metadata_train, metadata_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a635c82c-18ca-48d1-9390-88f1e98f30d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, ids_train, ids_test = load_data(X_train_path, y_train_path, X_test_path, ids_train_path, ids_test_path)\n",
    "metadata_train, metadata_test = load_metadata(metadata_train_path, metadata_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e2ae54d-0b28-4777-bede-1bb0627a1b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretreatment for data correlation\n",
    "categorical_cols = [\n",
    "    \"Organism group\",\n",
    "    \"Isolation type\",\n",
    "    \"Location\",\n",
    "    \"Isolation source\",\n",
    "    \"Laboratory typing platform\",\n",
    "    \"Testing standard\"\n",
    "]\n",
    "numerical_cols = [\"Days Since Ref Date\"]\n",
    "\n",
    "def prepare_metadata(metadata_train, metadata_test):\n",
    "    #unknown is a new value possible for missing values\n",
    "    metadata_train[categorical_cols] = metadata_train[categorical_cols].fillna(\"Unknown\")\n",
    "    metadata_test[categorical_cols] = metadata_test[categorical_cols].fillna(\"Unknown\")\n",
    "    \n",
    "    #remove timezones\n",
    "    metadata_train[\"Create date\"] = pd.to_datetime(metadata_train[\"Create date\"], utc=True).dt.tz_localize(None)\n",
    "    metadata_test[\"Create date\"]  = pd.to_datetime(metadata_test[\"Create date\"], utc=True).dt.tz_localize(None)\n",
    "    \n",
    "    #compute days since ref_date\n",
    "    #print(min(metadata_train[\"Create date\"].min(), metadata_test[\"Create date\"].min())) #2013\n",
    "    ref_date = pd.to_datetime(\"2010-01-01\") # smaller than 2013\n",
    "    metadata_train[\"Days Since Ref Date\"] = (pd.to_datetime(metadata_train[\"Create date\"]) - ref_date).dt.days\n",
    "    metadata_test[\"Days Since Ref Date\"]  = (pd.to_datetime(metadata_test[\"Create date\"]) - ref_date).dt.days\n",
    "        \n",
    "    metadata_train.drop(columns=[\"Create date\", \"Unnamed: 0\"], inplace=True)\n",
    "    metadata_test.drop(columns=[\"Create date\", \"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "    encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    \n",
    "    metadata_train_cat = encoder.fit_transform(metadata_train[categorical_cols])\n",
    "    metadata_test_cat  = encoder.transform(metadata_test[categorical_cols])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    metadata_train_num = scaler.fit_transform(metadata_train[numerical_cols])\n",
    "    metadata_test_num  = scaler.transform(metadata_test[numerical_cols])\n",
    "\n",
    "    metadata_train_features = np.hstack([metadata_train_cat, metadata_train_num])\n",
    "    metadata_test_features  = np.hstack([metadata_test_cat, metadata_test_num])\n",
    "\n",
    "    return metadata_train_features, metadata_test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "531e98d6-5b4d-44c5-9c2b-c196e814ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_train_features, metadata_test_features = prepare_metadata(metadata_train, metadata_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "03f47187-badb-4686-908d-91b65f8f0d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_variance_features(X_train, X_test, top_k=50000, batch_size=10000):\n",
    "    n_features = X_train.shape[1]\n",
    "    variances = np.zeros(n_features)\n",
    "\n",
    "    #compute variance in batches\n",
    "    for start in tqdm(range(0, n_features, batch_size), desc=\"Computing variance in batches\"):\n",
    "        end = min(start + batch_size, n_features)\n",
    "        batch = X_train[:, start:end]\n",
    "        variances[start:end] = np.var(batch, axis=0)\n",
    "\n",
    "    # select top_k features\n",
    "    top_features = np.argsort(variances)[-top_k:]\n",
    "\n",
    "    # reduce matrices\n",
    "    X_train_reduced = X_train[:, top_features]\n",
    "    X_test_reduced  = X_test[:, top_features]\n",
    "\n",
    "    return X_train_reduced, X_test_reduced, top_features\n",
    "\n",
    "def transform_tfidf(X_train, X_test, n_components=1000):\n",
    "    tfidf = TfidfTransformer()\n",
    "    X_train_reduced = tfidf.fit_transform(X_train)\n",
    "    X_test_reduced = tfidf.transform(X_test)\n",
    "\n",
    "    svd = TruncatedSVD(n_components=n_components)\n",
    "    normalizer = Normalizer()\n",
    "\n",
    "    X_train_svd = normalizer.fit_transform(svd.fit_transform(X_train_reduced)).astype(np.float32)\n",
    "    X_test_svd = normalizer.transform(svd.transform(X_test_reduced)).astype(np.float32)\n",
    "    return X_train_svd, X_test_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1cc00cc9-9c1e-4612-9bb3-914306fb5a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing variance in batches: 100%|██████████| 100/100 [00:07<00:00, 12.66it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_reduced, X_test_reduced, top_features_variance = select_top_variance_features(X_train, X_test, top_k=100000, batch_size=10000)\n",
    "\n",
    "X_train_reduced, X_test_reduced = transform_tfidf(X_train_reduced, X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "757caf9b-2916-4e83-8e1e-4381a21e316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_reduced = np.hstack([X_train_reduced.toarray(), metadata_train_features])\n",
    "#X_test_reduced = np.hstack([X_test_reduced.toarray(),  metadata_test_features]) \n",
    "\n",
    "X_train_reduced = np.hstack([X_train_reduced, metadata_train_features])\n",
    "X_test_reduced = np.hstack([X_test_reduced,  metadata_test_features]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "823aab6a-9ea2-4e5a-9c6d-f2780b2d2bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1939, 1105)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f845c67-44f3-40d5-a843-d00da4be4a61",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "HYPERPARAMETER TUNING FOR ALL MODELS\n",
      "================================================================================\n",
      "Tuning XGBoost...\n",
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
      "[CV] END colsample_bytree=0.749816047538945, gamma=0.2852142919229748, learning_rate=0.15639878836228102, max_depth=7, min_child_weight=5, n_estimators=202, reg_alpha=0.44583275285359114, reg_lambda=0.19994983163600577, subsample=0.7836995567863468; total time=  12.3s\n",
      "[CV] END colsample_bytree=0.7334834444556088, gamma=0.04286004537658223, learning_rate=0.14017769458977059, max_depth=7, min_child_weight=2, n_estimators=393, reg_alpha=0.0007787658410143283, reg_lambda=1.984423118582435, subsample=0.8469926038510867; total time=  22.3s\n",
      "[CV] END colsample_bytree=0.8446612641953124, gamma=0.002119891565915222, learning_rate=0.014612485008283152, max_depth=5, min_child_weight=3, n_estimators=269, reg_alpha=0.04666566321361543, reg_lambda=1.9475110376829183, subsample=0.6931085361721216; total time=  34.4s\n",
      "[CV] END colsample_bytree=0.6362425738131283, gamma=0.1855158027999262, learning_rate=0.08649239825343255, max_depth=6, min_child_weight=1, n_estimators=230, reg_alpha=0.8599404067363206, reg_lambda=1.3606150771755594, subsample=0.7801997007878172; total time=  22.6s\n",
      "[CV] END colsample_bytree=0.6053059844639466, gamma=0.28266052670545583, learning_rate=0.12265764356910785, max_depth=4, min_child_weight=1, n_estimators=152, reg_alpha=0.230893825622149, reg_lambda=0.48205093205202343, subsample=0.8733054075301833; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.8439986631130484, gamma=0.2499584735208493, learning_rate=0.04467293070155442, max_depth=3, min_child_weight=4, n_estimators=149, reg_alpha=0.662522284353982, reg_lambda=0.6234221521788219, subsample=0.8080272084711243; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.8186841117373118, gamma=0.05545633665765811, learning_rate=0.20391692555291174, max_depth=4, min_child_weight=4, n_estimators=261, reg_alpha=0.3951502360018144, reg_lambda=1.8533177315875884, subsample=0.8909087983425683; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7306163075223342, gamma=0.1711331923216198, learning_rate=0.11416685200516473, max_depth=8, min_child_weight=5, n_estimators=307, reg_alpha=0.7473201101373809, reg_lambda=1.0793842647781595, subsample=0.8347004662655393; total time=  18.6s\n",
      "[CV] END colsample_bytree=0.9861021229056552, gamma=0.1821102743060054, learning_rate=0.06519983640450867, max_depth=7, min_child_weight=5, n_estimators=164, reg_alpha=0.01563640674119393, reg_lambda=0.8468029614127393, subsample=0.7579526072702278; total time=  19.0s\n",
      "[CV] END colsample_bytree=0.7173952698872152, gamma=0.004223946814525336, learning_rate=0.049768480817761036, max_depth=5, min_child_weight=3, n_estimators=388, reg_alpha=0.6059599747810114, reg_lambda=1.852601757026698, subsample=0.8604308102007778; total time=  32.2s\n",
      "[CV] END colsample_bytree=0.9659838702175123, gamma=0.2550115733369398, learning_rate=0.09989013482764068, max_depth=3, min_child_weight=6, n_estimators=315, reg_alpha=0.6659223566174967, reg_lambda=1.1825955754154542, subsample=0.7098887171960256; total time=  13.2s\n",
      "[CV] END colsample_bytree=0.8244973703390804, gamma=0.11487806242613695, learning_rate=0.20434241907782077, max_depth=5, min_child_weight=1, n_estimators=104, reg_alpha=0.5612771975694962, reg_lambda=1.541934359909122, subsample=0.7975182385457563; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.8090931317527976, gamma=0.12826230550756487, learning_rate=0.015083825348819038, max_depth=7, min_child_weight=3, n_estimators=162, reg_alpha=0.8957635956735194, reg_lambda=0.9507404463642235, subsample=0.8253102287905535; total time=  33.5s\n",
      "[CV] END colsample_bytree=0.878206434570451, gamma=0.0417994363217627, learning_rate=0.13088347585556345, max_depth=9, min_child_weight=3, n_estimators=128, reg_alpha=0.22879816549162246, reg_lambda=0.15395981965758598, subsample=0.7159005811655073; total time=  14.9s\n",
      "[CV] END colsample_bytree=0.6644885149016018, gamma=0.2789092957027719, learning_rate=0.17162407591288342, max_depth=3, min_child_weight=5, n_estimators=233, reg_alpha=0.45653457048291024, reg_lambda=0.4368808744336672, subsample=0.7666039791481465; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.9533121035675474, gamma=0.09730350630158219, learning_rate=0.03441759094013467, max_depth=3, min_child_weight=6, n_estimators=324, reg_alpha=0.2721322493846353, reg_lambda=1.2953802410827246, subsample=0.6002081507981263; total time=  15.7s\n",
      "[CV] END colsample_bytree=0.7410275425336676, gamma=0.0914343774474087, learning_rate=0.04293117062858835, max_depth=5, min_child_weight=1, n_estimators=264, reg_alpha=0.6924360328902703, reg_lambda=0.538824667597043, subsample=0.6976502088991097; total time=  30.8s\n",
      "[CV] END colsample_bytree=0.6673164168691722, gamma=0.06562926587192107, learning_rate=0.12162040040346823, max_depth=6, min_child_weight=1, n_estimators=151, reg_alpha=0.2468760628386012, reg_lambda=1.3926085456795767, subsample=0.8849082359697769; total time=  18.9s\n",
      "[CV] END colsample_bytree=0.6592347719813599, gamma=0.29932214551468256, learning_rate=0.063356202855057, max_depth=4, min_child_weight=2, n_estimators=319, reg_alpha=0.05147875124998935, reg_lambda=0.5572929284732229, subsample=0.9633063543866615; total time=  19.0s\n",
      "[CV] END colsample_bytree=0.695824756266789, gamma=0.04346846162736693, learning_rate=0.10789055205551261, max_depth=8, min_child_weight=4, n_estimators=302, reg_alpha=0.36965445606140446, reg_lambda=0.48431987655485176, subsample=0.9212559025519583; total time=  18.3s\n",
      "[CV] END colsample_bytree=0.7881202537784153, gamma=0.2950269422684529, learning_rate=0.08976488848891061, max_depth=9, min_child_weight=1, n_estimators=300, reg_alpha=0.32078006497173583, reg_lambda=0.37303702079970846, subsample=0.6163100566219055; total time=  25.5s\n",
      "[CV] END colsample_bytree=0.8363571772752967, gamma=0.2032693085526847, learning_rate=0.013317565785571231, max_depth=5, min_child_weight=3, n_estimators=247, reg_alpha=0.6451727904094499, reg_lambda=0.3487328580099829, subsample=0.8763750952409863; total time=  32.1s\n",
      "[CV] END colsample_bytree=0.7546941385202149, gamma=0.28101899662102037, learning_rate=0.037504188829198655, max_depth=6, min_child_weight=1, n_estimators=250, reg_alpha=0.5414479738275658, reg_lambda=1.3915687986901644, subsample=0.6914200087189198; total time=  39.3s\n",
      "[CV] END colsample_bytree=0.6699819708383744, gamma=0.29465050299883067, learning_rate=0.11332717825420285, max_depth=3, min_child_weight=2, n_estimators=353, reg_alpha=0.8972157579533268, reg_lambda=1.800836114326661, subsample=0.8532405829093072; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.7356119164194803, gamma=0.10476287238379826, learning_rate=0.1551911357740479, max_depth=5, min_child_weight=4, n_estimators=251, reg_alpha=0.4045081271221901, reg_lambda=1.7755401975219196, subsample=0.9403713795070051; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.9742539976883791, gamma=0.23560219533418306, learning_rate=0.14379765094284575, max_depth=8, min_child_weight=3, n_estimators=211, reg_alpha=0.1014715428660321, reg_lambda=1.3270035382161116, subsample=0.6020246335384875; total time=  15.6s\n",
      "[CV] END colsample_bytree=0.6643232205669994, gamma=0.16462013680997584, learning_rate=0.14837903953853868, max_depth=7, min_child_weight=1, n_estimators=260, reg_alpha=0.018075363615520867, reg_lambda=0.9877874303668692, subsample=0.6715290836885315; total time=  16.8s\n",
      "[CV] END colsample_bytree=0.7465875138331439, gamma=0.22325115691696867, learning_rate=0.15418798485042587, max_depth=3, min_child_weight=4, n_estimators=121, reg_alpha=0.24398964337908358, reg_lambda=1.9460211095048912, subsample=0.7572390898667042; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.9568186220708453, gamma=0.18934158779917887, learning_rate=0.1689622607083297, max_depth=8, min_child_weight=1, n_estimators=383, reg_alpha=0.6689240596630996, reg_lambda=1.7283351301438061, subsample=0.6920741072966221; total time=  20.7s\n",
      "[CV] END colsample_bytree=0.7996773519539009, gamma=0.17160125976275492, learning_rate=0.16371080286126183, max_depth=3, min_child_weight=4, n_estimators=319, reg_alpha=0.46994451399094295, reg_lambda=0.5591206835935172, subsample=0.9533976089065036; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.8990875095589655, gamma=0.28592155410718595, learning_rate=0.07615006093410273, max_depth=8, min_child_weight=5, n_estimators=194, reg_alpha=0.9636199770892528, reg_lambda=1.7060189109347201, subsample=0.7177795568278342; total time=  18.9s[CV] END colsample_bytree=0.749816047538945, gamma=0.2852142919229748, learning_rate=0.15639878836228102, max_depth=7, min_child_weight=5, n_estimators=202, reg_alpha=0.44583275285359114, reg_lambda=0.19994983163600577, subsample=0.7836995567863468; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.7334834444556088, gamma=0.04286004537658223, learning_rate=0.14017769458977059, max_depth=7, min_child_weight=2, n_estimators=393, reg_alpha=0.0007787658410143283, reg_lambda=1.984423118582435, subsample=0.8469926038510867; total time=  22.7s\n",
      "[CV] END colsample_bytree=0.8446612641953124, gamma=0.002119891565915222, learning_rate=0.014612485008283152, max_depth=5, min_child_weight=3, n_estimators=269, reg_alpha=0.04666566321361543, reg_lambda=1.9475110376829183, subsample=0.6931085361721216; total time=  35.6s\n",
      "[CV] END colsample_bytree=0.6362425738131283, gamma=0.1855158027999262, learning_rate=0.08649239825343255, max_depth=6, min_child_weight=1, n_estimators=230, reg_alpha=0.8599404067363206, reg_lambda=1.3606150771755594, subsample=0.7801997007878172; total time=  22.7s\n",
      "[CV] END colsample_bytree=0.6053059844639466, gamma=0.28266052670545583, learning_rate=0.12265764356910785, max_depth=4, min_child_weight=1, n_estimators=152, reg_alpha=0.230893825622149, reg_lambda=0.48205093205202343, subsample=0.8733054075301833; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.8439986631130484, gamma=0.2499584735208493, learning_rate=0.04467293070155442, max_depth=3, min_child_weight=4, n_estimators=149, reg_alpha=0.662522284353982, reg_lambda=0.6234221521788219, subsample=0.8080272084711243; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.8186841117373118, gamma=0.05545633665765811, learning_rate=0.20391692555291174, max_depth=4, min_child_weight=4, n_estimators=261, reg_alpha=0.3951502360018144, reg_lambda=1.8533177315875884, subsample=0.8909087983425683; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.7306163075223342, gamma=0.1711331923216198, learning_rate=0.11416685200516473, max_depth=8, min_child_weight=5, n_estimators=307, reg_alpha=0.7473201101373809, reg_lambda=1.0793842647781595, subsample=0.8347004662655393; total time=  18.0s\n",
      "[CV] END colsample_bytree=0.9861021229056552, gamma=0.1821102743060054, learning_rate=0.06519983640450867, max_depth=7, min_child_weight=5, n_estimators=164, reg_alpha=0.01563640674119393, reg_lambda=0.8468029614127393, subsample=0.7579526072702278; total time=  19.3s\n",
      "[CV] END colsample_bytree=0.7173952698872152, gamma=0.004223946814525336, learning_rate=0.049768480817761036, max_depth=5, min_child_weight=3, n_estimators=388, reg_alpha=0.6059599747810114, reg_lambda=1.852601757026698, subsample=0.8604308102007778; total time=  32.0s\n",
      "[CV] END colsample_bytree=0.9659838702175123, gamma=0.2550115733369398, learning_rate=0.09989013482764068, max_depth=3, min_child_weight=6, n_estimators=315, reg_alpha=0.6659223566174967, reg_lambda=1.1825955754154542, subsample=0.7098887171960256; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.8244973703390804, gamma=0.11487806242613695, learning_rate=0.20434241907782077, max_depth=5, min_child_weight=1, n_estimators=104, reg_alpha=0.5612771975694962, reg_lambda=1.541934359909122, subsample=0.7975182385457563; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.8090931317527976, gamma=0.12826230550756487, learning_rate=0.015083825348819038, max_depth=7, min_child_weight=3, n_estimators=162, reg_alpha=0.8957635956735194, reg_lambda=0.9507404463642235, subsample=0.8253102287905535; total time=  33.6s\n",
      "[CV] END colsample_bytree=0.878206434570451, gamma=0.0417994363217627, learning_rate=0.13088347585556345, max_depth=9, min_child_weight=3, n_estimators=128, reg_alpha=0.22879816549162246, reg_lambda=0.15395981965758598, subsample=0.7159005811655073; total time=  15.3s\n",
      "[CV] END colsample_bytree=0.6644885149016018, gamma=0.2789092957027719, learning_rate=0.17162407591288342, max_depth=3, min_child_weight=5, n_estimators=233, reg_alpha=0.45653457048291024, reg_lambda=0.4368808744336672, subsample=0.7666039791481465; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.9533121035675474, gamma=0.09730350630158219, learning_rate=0.03441759094013467, max_depth=3, min_child_weight=6, n_estimators=324, reg_alpha=0.2721322493846353, reg_lambda=1.2953802410827246, subsample=0.6002081507981263; total time=  15.8s\n",
      "[CV] END colsample_bytree=0.7410275425336676, gamma=0.0914343774474087, learning_rate=0.04293117062858835, max_depth=5, min_child_weight=1, n_estimators=264, reg_alpha=0.6924360328902703, reg_lambda=0.538824667597043, subsample=0.6976502088991097; total time=  31.0s\n",
      "[CV] END colsample_bytree=0.6673164168691722, gamma=0.06562926587192107, learning_rate=0.12162040040346823, max_depth=6, min_child_weight=1, n_estimators=151, reg_alpha=0.2468760628386012, reg_lambda=1.3926085456795767, subsample=0.8849082359697769; total time=  18.3s\n",
      "[CV] END colsample_bytree=0.6592347719813599, gamma=0.29932214551468256, learning_rate=0.063356202855057, max_depth=4, min_child_weight=2, n_estimators=319, reg_alpha=0.05147875124998935, reg_lambda=0.5572929284732229, subsample=0.9633063543866615; total time=  19.1s\n",
      "[CV] END colsample_bytree=0.695824756266789, gamma=0.04346846162736693, learning_rate=0.10789055205551261, max_depth=8, min_child_weight=4, n_estimators=302, reg_alpha=0.36965445606140446, reg_lambda=0.48431987655485176, subsample=0.9212559025519583; total time=  18.2s\n",
      "[CV] END colsample_bytree=0.7881202537784153, gamma=0.2950269422684529, learning_rate=0.08976488848891061, max_depth=9, min_child_weight=1, n_estimators=300, reg_alpha=0.32078006497173583, reg_lambda=0.37303702079970846, subsample=0.6163100566219055; total time=  26.5s\n",
      "[CV] END colsample_bytree=0.8363571772752967, gamma=0.2032693085526847, learning_rate=0.013317565785571231, max_depth=5, min_child_weight=3, n_estimators=247, reg_alpha=0.6451727904094499, reg_lambda=0.3487328580099829, subsample=0.8763750952409863; total time=  32.2s\n",
      "[CV] END colsample_bytree=0.7546941385202149, gamma=0.28101899662102037, learning_rate=0.037504188829198655, max_depth=6, min_child_weight=1, n_estimators=250, reg_alpha=0.5414479738275658, reg_lambda=1.3915687986901644, subsample=0.6914200087189198; total time=  39.7s\n",
      "[CV] END colsample_bytree=0.6699819708383744, gamma=0.29465050299883067, learning_rate=0.11332717825420285, max_depth=3, min_child_weight=2, n_estimators=353, reg_alpha=0.8972157579533268, reg_lambda=1.800836114326661, subsample=0.8532405829093072; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.7356119164194803, gamma=0.10476287238379826, learning_rate=0.1551911357740479, max_depth=5, min_child_weight=4, n_estimators=251, reg_alpha=0.4045081271221901, reg_lambda=1.7755401975219196, subsample=0.9403713795070051; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.9742539976883791, gamma=0.23560219533418306, learning_rate=0.14379765094284575, max_depth=8, min_child_weight=3, n_estimators=211, reg_alpha=0.1014715428660321, reg_lambda=1.3270035382161116, subsample=0.6020246335384875; total time=  15.4s\n",
      "[CV] END colsample_bytree=0.6643232205669994, gamma=0.16462013680997584, learning_rate=0.14837903953853868, max_depth=7, min_child_weight=1, n_estimators=260, reg_alpha=0.018075363615520867, reg_lambda=0.9877874303668692, subsample=0.6715290836885315; total time=  16.7s\n",
      "[CV] END colsample_bytree=0.7465875138331439, gamma=0.22325115691696867, learning_rate=0.15418798485042587, max_depth=3, min_child_weight=4, n_estimators=121, reg_alpha=0.24398964337908358, reg_lambda=1.9460211095048912, subsample=0.7572390898667042; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.9568186220708453, gamma=0.18934158779917887, learning_rate=0.1689622607083297, max_depth=8, min_child_weight=1, n_estimators=383, reg_alpha=0.6689240596630996, reg_lambda=1.7283351301438061, subsample=0.6920741072966221; total time=  20.8s\n",
      "[CV] END colsample_bytree=0.7996773519539009, gamma=0.17160125976275492, learning_rate=0.16371080286126183, max_depth=3, min_child_weight=4, n_estimators=319, reg_alpha=0.46994451399094295, reg_lambda=0.5591206835935172, subsample=0.9533976089065036; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.8990875095589655, gamma=0.28592155410718595, learning_rate=0.07615006093410273, max_depth=8, min_child_weight=5, n_estimators=194, reg_alpha=0.9636199770892528, reg_lambda=1.7060189109347201, subsample=0.7177795568278342; total time=  18.9s[CV] END colsample_bytree=0.749816047538945, gamma=0.2852142919229748, learning_rate=0.15639878836228102, max_depth=7, min_child_weight=5, n_estimators=202, reg_alpha=0.44583275285359114, reg_lambda=0.19994983163600577, subsample=0.7836995567863468; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.7334834444556088, gamma=0.04286004537658223, learning_rate=0.14017769458977059, max_depth=7, min_child_weight=2, n_estimators=393, reg_alpha=0.0007787658410143283, reg_lambda=1.984423118582435, subsample=0.8469926038510867; total time=  22.4s\n",
      "[CV] END colsample_bytree=0.8446612641953124, gamma=0.002119891565915222, learning_rate=0.014612485008283152, max_depth=5, min_child_weight=3, n_estimators=269, reg_alpha=0.04666566321361543, reg_lambda=1.9475110376829183, subsample=0.6931085361721216; total time=  34.6s\n",
      "[CV] END colsample_bytree=0.6362425738131283, gamma=0.1855158027999262, learning_rate=0.08649239825343255, max_depth=6, min_child_weight=1, n_estimators=230, reg_alpha=0.8599404067363206, reg_lambda=1.3606150771755594, subsample=0.7801997007878172; total time=  22.4s\n",
      "[CV] END colsample_bytree=0.6053059844639466, gamma=0.28266052670545583, learning_rate=0.12265764356910785, max_depth=4, min_child_weight=1, n_estimators=152, reg_alpha=0.230893825622149, reg_lambda=0.48205093205202343, subsample=0.8733054075301833; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.8439986631130484, gamma=0.2499584735208493, learning_rate=0.04467293070155442, max_depth=3, min_child_weight=4, n_estimators=149, reg_alpha=0.662522284353982, reg_lambda=0.6234221521788219, subsample=0.8080272084711243; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.8186841117373118, gamma=0.05545633665765811, learning_rate=0.20391692555291174, max_depth=4, min_child_weight=4, n_estimators=261, reg_alpha=0.3951502360018144, reg_lambda=1.8533177315875884, subsample=0.8909087983425683; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7306163075223342, gamma=0.1711331923216198, learning_rate=0.11416685200516473, max_depth=8, min_child_weight=5, n_estimators=307, reg_alpha=0.7473201101373809, reg_lambda=1.0793842647781595, subsample=0.8347004662655393; total time=  18.3s\n",
      "[CV] END colsample_bytree=0.9861021229056552, gamma=0.1821102743060054, learning_rate=0.06519983640450867, max_depth=7, min_child_weight=5, n_estimators=164, reg_alpha=0.01563640674119393, reg_lambda=0.8468029614127393, subsample=0.7579526072702278; total time=  19.2s\n",
      "[CV] END colsample_bytree=0.7173952698872152, gamma=0.004223946814525336, learning_rate=0.049768480817761036, max_depth=5, min_child_weight=3, n_estimators=388, reg_alpha=0.6059599747810114, reg_lambda=1.852601757026698, subsample=0.8604308102007778; total time=  31.8s\n",
      "[CV] END colsample_bytree=0.9659838702175123, gamma=0.2550115733369398, learning_rate=0.09989013482764068, max_depth=3, min_child_weight=6, n_estimators=315, reg_alpha=0.6659223566174967, reg_lambda=1.1825955754154542, subsample=0.7098887171960256; total time=  13.3s\n",
      "[CV] END colsample_bytree=0.8244973703390804, gamma=0.11487806242613695, learning_rate=0.20434241907782077, max_depth=5, min_child_weight=1, n_estimators=104, reg_alpha=0.5612771975694962, reg_lambda=1.541934359909122, subsample=0.7975182385457563; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.8090931317527976, gamma=0.12826230550756487, learning_rate=0.015083825348819038, max_depth=7, min_child_weight=3, n_estimators=162, reg_alpha=0.8957635956735194, reg_lambda=0.9507404463642235, subsample=0.8253102287905535; total time=  31.9s\n",
      "[CV] END colsample_bytree=0.878206434570451, gamma=0.0417994363217627, learning_rate=0.13088347585556345, max_depth=9, min_child_weight=3, n_estimators=128, reg_alpha=0.22879816549162246, reg_lambda=0.15395981965758598, subsample=0.7159005811655073; total time=  13.2s\n",
      "[CV] END colsample_bytree=0.6644885149016018, gamma=0.2789092957027719, learning_rate=0.17162407591288342, max_depth=3, min_child_weight=5, n_estimators=233, reg_alpha=0.45653457048291024, reg_lambda=0.4368808744336672, subsample=0.7666039791481465; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.6644885149016018, gamma=0.2789092957027719, learning_rate=0.17162407591288342, max_depth=3, min_child_weight=5, n_estimators=233, reg_alpha=0.45653457048291024, reg_lambda=0.4368808744336672, subsample=0.7666039791481465; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.9533121035675474, gamma=0.09730350630158219, learning_rate=0.03441759094013467, max_depth=3, min_child_weight=6, n_estimators=324, reg_alpha=0.2721322493846353, reg_lambda=1.2953802410827246, subsample=0.6002081507981263; total time=  16.0s\n",
      "[CV] END colsample_bytree=0.7410275425336676, gamma=0.0914343774474087, learning_rate=0.04293117062858835, max_depth=5, min_child_weight=1, n_estimators=264, reg_alpha=0.6924360328902703, reg_lambda=0.538824667597043, subsample=0.6976502088991097; total time=  31.9s\n",
      "[CV] END colsample_bytree=0.6673164168691722, gamma=0.06562926587192107, learning_rate=0.12162040040346823, max_depth=6, min_child_weight=1, n_estimators=151, reg_alpha=0.2468760628386012, reg_lambda=1.3926085456795767, subsample=0.8849082359697769; total time=  18.1s\n",
      "[CV] END colsample_bytree=0.6592347719813599, gamma=0.29932214551468256, learning_rate=0.063356202855057, max_depth=4, min_child_weight=2, n_estimators=319, reg_alpha=0.05147875124998935, reg_lambda=0.5572929284732229, subsample=0.9633063543866615; total time=  19.9s\n",
      "[CV] END colsample_bytree=0.695824756266789, gamma=0.04346846162736693, learning_rate=0.10789055205551261, max_depth=8, min_child_weight=4, n_estimators=302, reg_alpha=0.36965445606140446, reg_lambda=0.48431987655485176, subsample=0.9212559025519583; total time=  18.3s\n",
      "[CV] END colsample_bytree=0.7881202537784153, gamma=0.2950269422684529, learning_rate=0.08976488848891061, max_depth=9, min_child_weight=1, n_estimators=300, reg_alpha=0.32078006497173583, reg_lambda=0.37303702079970846, subsample=0.6163100566219055; total time=  26.7s\n",
      "[CV] END colsample_bytree=0.8363571772752967, gamma=0.2032693085526847, learning_rate=0.013317565785571231, max_depth=5, min_child_weight=3, n_estimators=247, reg_alpha=0.6451727904094499, reg_lambda=0.3487328580099829, subsample=0.8763750952409863; total time=  33.4s\n",
      "[CV] END colsample_bytree=0.7546941385202149, gamma=0.28101899662102037, learning_rate=0.037504188829198655, max_depth=6, min_child_weight=1, n_estimators=250, reg_alpha=0.5414479738275658, reg_lambda=1.3915687986901644, subsample=0.6914200087189198; total time=  40.4s\n",
      "[CV] END colsample_bytree=0.6699819708383744, gamma=0.29465050299883067, learning_rate=0.11332717825420285, max_depth=3, min_child_weight=2, n_estimators=353, reg_alpha=0.8972157579533268, reg_lambda=1.800836114326661, subsample=0.8532405829093072; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.7356119164194803, gamma=0.10476287238379826, learning_rate=0.1551911357740479, max_depth=5, min_child_weight=4, n_estimators=251, reg_alpha=0.4045081271221901, reg_lambda=1.7755401975219196, subsample=0.9403713795070051; total time=  12.7s\n",
      "[CV] END colsample_bytree=0.9742539976883791, gamma=0.23560219533418306, learning_rate=0.14379765094284575, max_depth=8, min_child_weight=3, n_estimators=211, reg_alpha=0.1014715428660321, reg_lambda=1.3270035382161116, subsample=0.6020246335384875; total time=  15.9s\n",
      "[CV] END colsample_bytree=0.6643232205669994, gamma=0.16462013680997584, learning_rate=0.14837903953853868, max_depth=7, min_child_weight=1, n_estimators=260, reg_alpha=0.018075363615520867, reg_lambda=0.9877874303668692, subsample=0.6715290836885315; total time=  17.5s\n",
      "[CV] END colsample_bytree=0.9568186220708453, gamma=0.18934158779917887, learning_rate=0.1689622607083297, max_depth=8, min_child_weight=1, n_estimators=383, reg_alpha=0.6689240596630996, reg_lambda=1.7283351301438061, subsample=0.6920741072966221; total time=  20.6s\n",
      "[CV] END colsample_bytree=0.7996773519539009, gamma=0.17160125976275492, learning_rate=0.16371080286126183, max_depth=3, min_child_weight=4, n_estimators=319, reg_alpha=0.46994451399094295, reg_lambda=0.5591206835935172, subsample=0.9533976089065036; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.8990875095589655, gamma=0.28592155410718595, learning_rate=0.07615006093410273, max_depth=8, min_child_weight=5, n_estimators=194, reg_alpha=0.9636199770892528, reg_lambda=1.7060189109347201, subsample=0.7177795568278342; total time=  20.0s[CV] END colsample_bytree=0.749816047538945, gamma=0.2852142919229748, learning_rate=0.15639878836228102, max_depth=7, min_child_weight=5, n_estimators=202, reg_alpha=0.44583275285359114, reg_lambda=0.19994983163600577, subsample=0.7836995567863468; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.7334834444556088, gamma=0.04286004537658223, learning_rate=0.14017769458977059, max_depth=7, min_child_weight=2, n_estimators=393, reg_alpha=0.0007787658410143283, reg_lambda=1.984423118582435, subsample=0.8469926038510867; total time=  22.8s\n",
      "[CV] END colsample_bytree=0.8446612641953124, gamma=0.002119891565915222, learning_rate=0.014612485008283152, max_depth=5, min_child_weight=3, n_estimators=269, reg_alpha=0.04666566321361543, reg_lambda=1.9475110376829183, subsample=0.6931085361721216; total time=  36.3s\n",
      "[CV] END colsample_bytree=0.6362425738131283, gamma=0.1855158027999262, learning_rate=0.08649239825343255, max_depth=6, min_child_weight=1, n_estimators=230, reg_alpha=0.8599404067363206, reg_lambda=1.3606150771755594, subsample=0.7801997007878172; total time=  23.2s\n",
      "[CV] END colsample_bytree=0.6053059844639466, gamma=0.28266052670545583, learning_rate=0.12265764356910785, max_depth=4, min_child_weight=1, n_estimators=152, reg_alpha=0.230893825622149, reg_lambda=0.48205093205202343, subsample=0.8733054075301833; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.8439986631130484, gamma=0.2499584735208493, learning_rate=0.04467293070155442, max_depth=3, min_child_weight=4, n_estimators=149, reg_alpha=0.662522284353982, reg_lambda=0.6234221521788219, subsample=0.8080272084711243; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.8186841117373118, gamma=0.05545633665765811, learning_rate=0.20391692555291174, max_depth=4, min_child_weight=4, n_estimators=261, reg_alpha=0.3951502360018144, reg_lambda=1.8533177315875884, subsample=0.8909087983425683; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.7306163075223342, gamma=0.1711331923216198, learning_rate=0.11416685200516473, max_depth=8, min_child_weight=5, n_estimators=307, reg_alpha=0.7473201101373809, reg_lambda=1.0793842647781595, subsample=0.8347004662655393; total time=  18.5s\n",
      "[CV] END colsample_bytree=0.9861021229056552, gamma=0.1821102743060054, learning_rate=0.06519983640450867, max_depth=7, min_child_weight=5, n_estimators=164, reg_alpha=0.01563640674119393, reg_lambda=0.8468029614127393, subsample=0.7579526072702278; total time=  19.7s\n",
      "[CV] END colsample_bytree=0.7173952698872152, gamma=0.004223946814525336, learning_rate=0.049768480817761036, max_depth=5, min_child_weight=3, n_estimators=388, reg_alpha=0.6059599747810114, reg_lambda=1.852601757026698, subsample=0.8604308102007778; total time=  32.3s\n",
      "[CV] END colsample_bytree=0.9659838702175123, gamma=0.2550115733369398, learning_rate=0.09989013482764068, max_depth=3, min_child_weight=6, n_estimators=315, reg_alpha=0.6659223566174967, reg_lambda=1.1825955754154542, subsample=0.7098887171960256; total time=  13.2s\n",
      "[CV] END colsample_bytree=0.8244973703390804, gamma=0.11487806242613695, learning_rate=0.20434241907782077, max_depth=5, min_child_weight=1, n_estimators=104, reg_alpha=0.5612771975694962, reg_lambda=1.541934359909122, subsample=0.7975182385457563; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.8090931317527976, gamma=0.12826230550756487, learning_rate=0.015083825348819038, max_depth=7, min_child_weight=3, n_estimators=162, reg_alpha=0.8957635956735194, reg_lambda=0.9507404463642235, subsample=0.8253102287905535; total time=  35.6s\n",
      "[CV] END colsample_bytree=0.878206434570451, gamma=0.0417994363217627, learning_rate=0.13088347585556345, max_depth=9, min_child_weight=3, n_estimators=128, reg_alpha=0.22879816549162246, reg_lambda=0.15395981965758598, subsample=0.7159005811655073; total time=  15.4s\n",
      "[CV] END colsample_bytree=0.9533121035675474, gamma=0.09730350630158219, learning_rate=0.03441759094013467, max_depth=3, min_child_weight=6, n_estimators=324, reg_alpha=0.2721322493846353, reg_lambda=1.2953802410827246, subsample=0.6002081507981263; total time=  15.9s\n",
      "[CV] END colsample_bytree=0.7410275425336676, gamma=0.0914343774474087, learning_rate=0.04293117062858835, max_depth=5, min_child_weight=1, n_estimators=264, reg_alpha=0.6924360328902703, reg_lambda=0.538824667597043, subsample=0.6976502088991097; total time=  30.7s\n",
      "[CV] END colsample_bytree=0.6673164168691722, gamma=0.06562926587192107, learning_rate=0.12162040040346823, max_depth=6, min_child_weight=1, n_estimators=151, reg_alpha=0.2468760628386012, reg_lambda=1.3926085456795767, subsample=0.8849082359697769; total time=  18.2s\n",
      "[CV] END colsample_bytree=0.6592347719813599, gamma=0.29932214551468256, learning_rate=0.063356202855057, max_depth=4, min_child_weight=2, n_estimators=319, reg_alpha=0.05147875124998935, reg_lambda=0.5572929284732229, subsample=0.9633063543866615; total time=  18.6s\n",
      "[CV] END colsample_bytree=0.695824756266789, gamma=0.04346846162736693, learning_rate=0.10789055205551261, max_depth=8, min_child_weight=4, n_estimators=302, reg_alpha=0.36965445606140446, reg_lambda=0.48431987655485176, subsample=0.9212559025519583; total time=  18.2s\n",
      "[CV] END colsample_bytree=0.7881202537784153, gamma=0.2950269422684529, learning_rate=0.08976488848891061, max_depth=9, min_child_weight=1, n_estimators=300, reg_alpha=0.32078006497173583, reg_lambda=0.37303702079970846, subsample=0.6163100566219055; total time=  25.7s\n",
      "[CV] END colsample_bytree=0.8363571772752967, gamma=0.2032693085526847, learning_rate=0.013317565785571231, max_depth=5, min_child_weight=3, n_estimators=247, reg_alpha=0.6451727904094499, reg_lambda=0.3487328580099829, subsample=0.8763750952409863; total time=  32.6s\n",
      "[CV] END colsample_bytree=0.7546941385202149, gamma=0.28101899662102037, learning_rate=0.037504188829198655, max_depth=6, min_child_weight=1, n_estimators=250, reg_alpha=0.5414479738275658, reg_lambda=1.3915687986901644, subsample=0.6914200087189198; total time=  39.5s\n",
      "[CV] END colsample_bytree=0.6699819708383744, gamma=0.29465050299883067, learning_rate=0.11332717825420285, max_depth=3, min_child_weight=2, n_estimators=353, reg_alpha=0.8972157579533268, reg_lambda=1.800836114326661, subsample=0.8532405829093072; total time=  12.0s\n",
      "[CV] END colsample_bytree=0.7356119164194803, gamma=0.10476287238379826, learning_rate=0.1551911357740479, max_depth=5, min_child_weight=4, n_estimators=251, reg_alpha=0.4045081271221901, reg_lambda=1.7755401975219196, subsample=0.9403713795070051; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.9742539976883791, gamma=0.23560219533418306, learning_rate=0.14379765094284575, max_depth=8, min_child_weight=3, n_estimators=211, reg_alpha=0.1014715428660321, reg_lambda=1.3270035382161116, subsample=0.6020246335384875; total time=  15.4s\n",
      "[CV] END colsample_bytree=0.6643232205669994, gamma=0.16462013680997584, learning_rate=0.14837903953853868, max_depth=7, min_child_weight=1, n_estimators=260, reg_alpha=0.018075363615520867, reg_lambda=0.9877874303668692, subsample=0.6715290836885315; total time=  16.7s\n",
      "[CV] END colsample_bytree=0.7465875138331439, gamma=0.22325115691696867, learning_rate=0.15418798485042587, max_depth=3, min_child_weight=4, n_estimators=121, reg_alpha=0.24398964337908358, reg_lambda=1.9460211095048912, subsample=0.7572390898667042; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.7465875138331439, gamma=0.22325115691696867, learning_rate=0.15418798485042587, max_depth=3, min_child_weight=4, n_estimators=121, reg_alpha=0.24398964337908358, reg_lambda=1.9460211095048912, subsample=0.7572390898667042; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.9568186220708453, gamma=0.18934158779917887, learning_rate=0.1689622607083297, max_depth=8, min_child_weight=1, n_estimators=383, reg_alpha=0.6689240596630996, reg_lambda=1.7283351301438061, subsample=0.6920741072966221; total time=  21.5s\n",
      "[CV] END colsample_bytree=0.7996773519539009, gamma=0.17160125976275492, learning_rate=0.16371080286126183, max_depth=3, min_child_weight=4, n_estimators=319, reg_alpha=0.46994451399094295, reg_lambda=0.5591206835935172, subsample=0.9533976089065036; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.8990875095589655, gamma=0.28592155410718595, learning_rate=0.07615006093410273, max_depth=8, min_child_weight=5, n_estimators=194, reg_alpha=0.9636199770892528, reg_lambda=1.7060189109347201, subsample=0.7177795568278342; total time=  21.8sBest params: {'colsample_bytree': np.float64(0.8363571772752967), 'gamma': np.float64(0.2032693085526847), 'learning_rate': np.float64(0.013317565785571231), 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 247, 'reg_alpha': np.float64(0.6451727904094499), 'reg_lambda': np.float64(0.3487328580099829), 'subsample': np.float64(0.8763750952409863)}\n",
      "Best ROC-AUC: 0.6020\n",
      "\n",
      "Tuning LightGBM...\n",
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bytree=0.7540390914407701, gamma=0.25534100145505706, learning_rate=0.07338440103125553, max_depth=4, min_child_weight=1, n_estimators=322, reg_alpha=0.8442131407263114, reg_lambda=1.8600336696216637, subsample=0.6281664523398175; total time=  24.7s\n",
      "[CV] END colsample_bytree=0.6835674870461441, gamma=0.20134305504721517, learning_rate=0.08172935625923278, max_depth=9, min_child_weight=3, n_estimators=372, reg_alpha=0.8486697949246744, reg_lambda=0.27324266288405763, subsample=0.8835643987640474; total time=  22.0s\n",
      "[CV] END colsample_bytree=0.8211279907631631, gamma=0.08895304309433955, learning_rate=0.0939561712892553, max_depth=4, min_child_weight=1, n_estimators=112, reg_alpha=0.08159418040024036, reg_lambda=0.010369725547973552, subsample=0.8511577659794545; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.6777095814048169, gamma=0.021282275099978296, learning_rate=0.08935676544277768, max_depth=8, min_child_weight=4, n_estimators=242, reg_alpha=0.375582952639944, reg_lambda=0.187963879681738, subsample=0.8313120563984696; total time=  17.4s\n",
      "[CV] END colsample_bytree=0.6143769095186968, gamma=0.13967940543973803, learning_rate=0.11852892694151533, max_depth=7, min_child_weight=6, n_estimators=157, reg_alpha=0.03050024993904943, reg_lambda=0.07469637749842883, subsample=0.9290402242638633; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.6143769095186968, gamma=0.13967940543973803, learning_rate=0.11852892694151533, max_depth=7, min_child_weight=6, n_estimators=157, reg_alpha=0.03050024993904943, reg_lambda=0.07469637749842883, subsample=0.9290402242638633; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.7440762565645052, gamma=0.038118153795565435, learning_rate=0.11444865201096087, max_depth=7, min_child_weight=4, n_estimators=207, reg_alpha=0.6228904758190003, reg_lambda=0.170694929987536, subsample=0.6206726884674431; total time=  14.6s\n",
      "[CV] END colsample_bytree=0.8125418526272592, gamma=0.16219053648303194, learning_rate=0.13748598029964132, max_depth=6, min_child_weight=5, n_estimators=223, reg_alpha=0.7145951041799521, reg_lambda=0.08213503353575158, subsample=0.7595283605779178; total time=  12.7s\n",
      "[CV] END colsample_bytree=0.7734082950322968, gamma=0.2232127928997346, learning_rate=0.06017210546933224, max_depth=4, min_child_weight=5, n_estimators=378, reg_alpha=0.42831447494010777, reg_lambda=1.3769998015307328, subsample=0.6232774382033774; total time=  21.4s\n",
      "[CV] END colsample_bytree=0.9660854910505922, gamma=0.13270566891933133, learning_rate=0.05795747183148065, max_depth=8, min_child_weight=1, n_estimators=336, reg_alpha=0.27993389694594284, reg_lambda=1.9097305613263882, subsample=0.8951587666783074; total time=  51.3s\n",
      "[CV] END colsample_bytree=0.8217416210045603, gamma=0.18351622387030567, learning_rate=0.09392001248555798, max_depth=6, min_child_weight=2, n_estimators=243, reg_alpha=0.15864644764249103, reg_lambda=0.24032929561128435, subsample=0.7367518666865607; total time=  20.2s\n",
      "[CV] END colsample_bytree=0.6367196263253767, gamma=0.028247096480568033, learning_rate=0.07228266187825884, max_depth=8, min_child_weight=4, n_estimators=303, reg_alpha=0.017161101831750236, reg_lambda=1.5267288460078219, subsample=0.9227651908203118; total time=  24.2s\n",
      "[CV] END colsample_bytree=0.8503439662856945, gamma=0.1509408775740263, learning_rate=0.18129796823766448, max_depth=7, min_child_weight=5, n_estimators=103, reg_alpha=0.6158511643899138, reg_lambda=1.8877832091215143, subsample=0.977700638850067; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.8503439662856945, gamma=0.1509408775740263, learning_rate=0.18129796823766448, max_depth=7, min_child_weight=5, n_estimators=103, reg_alpha=0.6158511643899138, reg_lambda=1.8877832091215143, subsample=0.977700638850067; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.9468795734220015, gamma=0.1909210792338034, learning_rate=0.17018985893647998, max_depth=6, min_child_weight=2, n_estimators=262, reg_alpha=0.6432882184423532, reg_lambda=0.9165057809830333, subsample=0.818246715726374; total time=  14.2s\n",
      "[CV] END colsample_bytree=0.6155852529240934, gamma=0.18547616530136785, learning_rate=0.07731084297774529, max_depth=4, min_child_weight=5, n_estimators=189, reg_alpha=0.34062456946424, reg_lambda=0.5213890564718062, subsample=0.7984149817173625; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.8771561434767757, gamma=0.10450098133595921, learning_rate=0.19732963037114148, max_depth=6, min_child_weight=1, n_estimators=376, reg_alpha=0.9675805515202475, reg_lambda=1.0959437664961746, subsample=0.7693883769232475; total time=  16.2s\n",
      "[CV] END colsample_bytree=0.8274081134999833, gamma=0.17277737257742537, learning_rate=0.15632955105992805, max_depth=6, min_child_weight=2, n_estimators=195, reg_alpha=0.34080354025301784, reg_lambda=1.8615146512071294, subsample=0.9433651007372047; total time=  13.7s\n",
      "[CV] END colsample_bytree=0.7715976109500073, gamma=0.2252613203374492, learning_rate=0.1609085748169365, max_depth=3, min_child_weight=6, n_estimators=372, reg_alpha=0.5343274735305634, reg_lambda=0.9931223813661554, subsample=0.7558472344876814; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.749816047538945, learning_rate=0.20014286128198325, max_depth=5, min_child_weight=8.796910002727692, n_estimators=120, num_leaves=94, reg_alpha=0.45924889196586716, reg_lambda=0.6674172222780437, subsample=0.6571467271687763; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bytree=0.7540390914407701, gamma=0.25534100145505706, learning_rate=0.07338440103125553, max_depth=4, min_child_weight=1, n_estimators=322, reg_alpha=0.8442131407263114, reg_lambda=1.8600336696216637, subsample=0.6281664523398175; total time=  24.5s\n",
      "[CV] END colsample_bytree=0.6835674870461441, gamma=0.20134305504721517, learning_rate=0.08172935625923278, max_depth=9, min_child_weight=3, n_estimators=372, reg_alpha=0.8486697949246744, reg_lambda=0.27324266288405763, subsample=0.8835643987640474; total time=  22.5s\n",
      "[CV] END colsample_bytree=0.8211279907631631, gamma=0.08895304309433955, learning_rate=0.0939561712892553, max_depth=4, min_child_weight=1, n_estimators=112, reg_alpha=0.08159418040024036, reg_lambda=0.010369725547973552, subsample=0.8511577659794545; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.6777095814048169, gamma=0.021282275099978296, learning_rate=0.08935676544277768, max_depth=8, min_child_weight=4, n_estimators=242, reg_alpha=0.375582952639944, reg_lambda=0.187963879681738, subsample=0.8313120563984696; total time=  18.0s\n",
      "[CV] END colsample_bytree=0.6143769095186968, gamma=0.13967940543973803, learning_rate=0.11852892694151533, max_depth=7, min_child_weight=6, n_estimators=157, reg_alpha=0.03050024993904943, reg_lambda=0.07469637749842883, subsample=0.9290402242638633; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.7440762565645052, gamma=0.038118153795565435, learning_rate=0.11444865201096087, max_depth=7, min_child_weight=4, n_estimators=207, reg_alpha=0.6228904758190003, reg_lambda=0.170694929987536, subsample=0.6206726884674431; total time=  14.2s\n",
      "[CV] END colsample_bytree=0.8125418526272592, gamma=0.16219053648303194, learning_rate=0.13748598029964132, max_depth=6, min_child_weight=5, n_estimators=223, reg_alpha=0.7145951041799521, reg_lambda=0.08213503353575158, subsample=0.7595283605779178; total time=  12.7s\n",
      "[CV] END colsample_bytree=0.7734082950322968, gamma=0.2232127928997346, learning_rate=0.06017210546933224, max_depth=4, min_child_weight=5, n_estimators=378, reg_alpha=0.42831447494010777, reg_lambda=1.3769998015307328, subsample=0.6232774382033774; total time=  20.0s\n",
      "[CV] END colsample_bytree=0.9660854910505922, gamma=0.13270566891933133, learning_rate=0.05795747183148065, max_depth=8, min_child_weight=1, n_estimators=336, reg_alpha=0.27993389694594284, reg_lambda=1.9097305613263882, subsample=0.8951587666783074; total time=  49.8s\n",
      "[CV] END colsample_bytree=0.8217416210045603, gamma=0.18351622387030567, learning_rate=0.09392001248555798, max_depth=6, min_child_weight=2, n_estimators=243, reg_alpha=0.15864644764249103, reg_lambda=0.24032929561128435, subsample=0.7367518666865607; total time=  19.4s\n",
      "[CV] END colsample_bytree=0.6367196263253767, gamma=0.028247096480568033, learning_rate=0.07228266187825884, max_depth=8, min_child_weight=4, n_estimators=303, reg_alpha=0.017161101831750236, reg_lambda=1.5267288460078219, subsample=0.9227651908203118; total time=  24.5s\n",
      "[CV] END colsample_bytree=0.7385217284357604, gamma=0.1394021438818834, learning_rate=0.1399547365285527, max_depth=4, min_child_weight=2, n_estimators=345, reg_alpha=0.6350936508676438, reg_lambda=0.09060801954408904, subsample=0.7498450458505885; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.8503439662856945, gamma=0.1509408775740263, learning_rate=0.18129796823766448, max_depth=7, min_child_weight=5, n_estimators=103, reg_alpha=0.6158511643899138, reg_lambda=1.8877832091215143, subsample=0.977700638850067; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.9468795734220015, gamma=0.1909210792338034, learning_rate=0.17018985893647998, max_depth=6, min_child_weight=2, n_estimators=262, reg_alpha=0.6432882184423532, reg_lambda=0.9165057809830333, subsample=0.818246715726374; total time=  14.2s\n",
      "[CV] END colsample_bytree=0.97658592351061, gamma=0.11583079134023228, learning_rate=0.20223811276478287, max_depth=4, min_child_weight=3, n_estimators=143, reg_alpha=0.27396112732113376, reg_lambda=0.42917823941674826, subsample=0.7509036332911904; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.6155852529240934, gamma=0.18547616530136785, learning_rate=0.07731084297774529, max_depth=4, min_child_weight=5, n_estimators=189, reg_alpha=0.34062456946424, reg_lambda=0.5213890564718062, subsample=0.7984149817173625; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.8771561434767757, gamma=0.10450098133595921, learning_rate=0.19732963037114148, max_depth=6, min_child_weight=1, n_estimators=376, reg_alpha=0.9675805515202475, reg_lambda=1.0959437664961746, subsample=0.7693883769232475; total time=  16.5s\n",
      "[CV] END colsample_bytree=0.8274081134999833, gamma=0.17277737257742537, learning_rate=0.15632955105992805, max_depth=6, min_child_weight=2, n_estimators=195, reg_alpha=0.34080354025301784, reg_lambda=1.8615146512071294, subsample=0.9433651007372047; total time=  13.8s\n",
      "[CV] END colsample_bytree=0.7715976109500073, gamma=0.2252613203374492, learning_rate=0.1609085748169365, max_depth=3, min_child_weight=6, n_estimators=372, reg_alpha=0.5343274735305634, reg_lambda=0.9931223813661554, subsample=0.7558472344876814; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.749816047538945, learning_rate=0.20014286128198325, max_depth=5, min_child_weight=8.796910002727692, n_estimators=120, num_leaves=94, reg_alpha=0.45924889196586716, reg_lambda=0.6674172222780437, subsample=0.6571467271687763; total time= 1.5min\n",
      "\n",
      "[CV] END colsample_bytree=0.7540390914407701, gamma=0.25534100145505706, learning_rate=0.07338440103125553, max_depth=4, min_child_weight=1, n_estimators=322, reg_alpha=0.8442131407263114, reg_lambda=1.8600336696216637, subsample=0.6281664523398175; total time=  24.0s\n",
      "[CV] END colsample_bytree=0.6835674870461441, gamma=0.20134305504721517, learning_rate=0.08172935625923278, max_depth=9, min_child_weight=3, n_estimators=372, reg_alpha=0.8486697949246744, reg_lambda=0.27324266288405763, subsample=0.8835643987640474; total time=  22.6s\n",
      "[CV] END colsample_bytree=0.8211279907631631, gamma=0.08895304309433955, learning_rate=0.0939561712892553, max_depth=4, min_child_weight=1, n_estimators=112, reg_alpha=0.08159418040024036, reg_lambda=0.010369725547973552, subsample=0.8511577659794545; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.6777095814048169, gamma=0.021282275099978296, learning_rate=0.08935676544277768, max_depth=8, min_child_weight=4, n_estimators=242, reg_alpha=0.375582952639944, reg_lambda=0.187963879681738, subsample=0.8313120563984696; total time=  18.0s\n",
      "[CV] END colsample_bytree=0.6143769095186968, gamma=0.13967940543973803, learning_rate=0.11852892694151533, max_depth=7, min_child_weight=6, n_estimators=157, reg_alpha=0.03050024993904943, reg_lambda=0.07469637749842883, subsample=0.9290402242638633; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.7440762565645052, gamma=0.038118153795565435, learning_rate=0.11444865201096087, max_depth=7, min_child_weight=4, n_estimators=207, reg_alpha=0.6228904758190003, reg_lambda=0.170694929987536, subsample=0.6206726884674431; total time=  14.2s\n",
      "[CV] END colsample_bytree=0.8125418526272592, gamma=0.16219053648303194, learning_rate=0.13748598029964132, max_depth=6, min_child_weight=5, n_estimators=223, reg_alpha=0.7145951041799521, reg_lambda=0.08213503353575158, subsample=0.7595283605779178; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.7734082950322968, gamma=0.2232127928997346, learning_rate=0.06017210546933224, max_depth=4, min_child_weight=5, n_estimators=378, reg_alpha=0.42831447494010777, reg_lambda=1.3769998015307328, subsample=0.6232774382033774; total time=  20.1s\n",
      "[CV] END colsample_bytree=0.9660854910505922, gamma=0.13270566891933133, learning_rate=0.05795747183148065, max_depth=8, min_child_weight=1, n_estimators=336, reg_alpha=0.27993389694594284, reg_lambda=1.9097305613263882, subsample=0.8951587666783074; total time=  50.1s\n",
      "[CV] END colsample_bytree=0.8217416210045603, gamma=0.18351622387030567, learning_rate=0.09392001248555798, max_depth=6, min_child_weight=2, n_estimators=243, reg_alpha=0.15864644764249103, reg_lambda=0.24032929561128435, subsample=0.7367518666865607; total time=  19.6s\n",
      "[CV] END colsample_bytree=0.6367196263253767, gamma=0.028247096480568033, learning_rate=0.07228266187825884, max_depth=8, min_child_weight=4, n_estimators=303, reg_alpha=0.017161101831750236, reg_lambda=1.5267288460078219, subsample=0.9227651908203118; total time=  24.3s\n",
      "[CV] END colsample_bytree=0.7385217284357604, gamma=0.1394021438818834, learning_rate=0.1399547365285527, max_depth=4, min_child_weight=2, n_estimators=345, reg_alpha=0.6350936508676438, reg_lambda=0.09060801954408904, subsample=0.7498450458505885; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.8503439662856945, gamma=0.1509408775740263, learning_rate=0.18129796823766448, max_depth=7, min_child_weight=5, n_estimators=103, reg_alpha=0.6158511643899138, reg_lambda=1.8877832091215143, subsample=0.977700638850067; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.9468795734220015, gamma=0.1909210792338034, learning_rate=0.17018985893647998, max_depth=6, min_child_weight=2, n_estimators=262, reg_alpha=0.6432882184423532, reg_lambda=0.9165057809830333, subsample=0.818246715726374; total time=  14.1s\n",
      "[CV] END colsample_bytree=0.97658592351061, gamma=0.11583079134023228, learning_rate=0.20223811276478287, max_depth=4, min_child_weight=3, n_estimators=143, reg_alpha=0.27396112732113376, reg_lambda=0.42917823941674826, subsample=0.7509036332911904; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.6155852529240934, gamma=0.18547616530136785, learning_rate=0.07731084297774529, max_depth=4, min_child_weight=5, n_estimators=189, reg_alpha=0.34062456946424, reg_lambda=0.5213890564718062, subsample=0.7984149817173625; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.8771561434767757, gamma=0.10450098133595921, learning_rate=0.19732963037114148, max_depth=6, min_child_weight=1, n_estimators=376, reg_alpha=0.9675805515202475, reg_lambda=1.0959437664961746, subsample=0.7693883769232475; total time=  16.3s\n",
      "[CV] END colsample_bytree=0.8274081134999833, gamma=0.17277737257742537, learning_rate=0.15632955105992805, max_depth=6, min_child_weight=2, n_estimators=195, reg_alpha=0.34080354025301784, reg_lambda=1.8615146512071294, subsample=0.9433651007372047; total time=  14.0s\n",
      "[CV] END colsample_bytree=0.7715976109500073, gamma=0.2252613203374492, learning_rate=0.1609085748169365, max_depth=3, min_child_weight=6, n_estimators=372, reg_alpha=0.5343274735305634, reg_lambda=0.9931223813661554, subsample=0.7558472344876814; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.749816047538945, learning_rate=0.20014286128198325, max_depth=5, min_child_weight=8.796910002727692, n_estimators=120, num_leaves=94, reg_alpha=0.45924889196586716, reg_lambda=0.6674172222780437, subsample=0.6571467271687763; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bytree=0.7540390914407701, gamma=0.25534100145505706, learning_rate=0.07338440103125553, max_depth=4, min_child_weight=1, n_estimators=322, reg_alpha=0.8442131407263114, reg_lambda=1.8600336696216637, subsample=0.6281664523398175; total time=  24.1s\n",
      "[CV] END colsample_bytree=0.6835674870461441, gamma=0.20134305504721517, learning_rate=0.08172935625923278, max_depth=9, min_child_weight=3, n_estimators=372, reg_alpha=0.8486697949246744, reg_lambda=0.27324266288405763, subsample=0.8835643987640474; total time=  22.7s\n",
      "[CV] END colsample_bytree=0.8211279907631631, gamma=0.08895304309433955, learning_rate=0.0939561712892553, max_depth=4, min_child_weight=1, n_estimators=112, reg_alpha=0.08159418040024036, reg_lambda=0.010369725547973552, subsample=0.8511577659794545; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.6777095814048169, gamma=0.021282275099978296, learning_rate=0.08935676544277768, max_depth=8, min_child_weight=4, n_estimators=242, reg_alpha=0.375582952639944, reg_lambda=0.187963879681738, subsample=0.8313120563984696; total time=  19.5s\n",
      "[CV] END colsample_bytree=0.7440762565645052, gamma=0.038118153795565435, learning_rate=0.11444865201096087, max_depth=7, min_child_weight=4, n_estimators=207, reg_alpha=0.6228904758190003, reg_lambda=0.170694929987536, subsample=0.6206726884674431; total time=  14.5s\n",
      "[CV] END colsample_bytree=0.8125418526272592, gamma=0.16219053648303194, learning_rate=0.13748598029964132, max_depth=6, min_child_weight=5, n_estimators=223, reg_alpha=0.7145951041799521, reg_lambda=0.08213503353575158, subsample=0.7595283605779178; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.7734082950322968, gamma=0.2232127928997346, learning_rate=0.06017210546933224, max_depth=4, min_child_weight=5, n_estimators=378, reg_alpha=0.42831447494010777, reg_lambda=1.3769998015307328, subsample=0.6232774382033774; total time=  20.0s\n",
      "[CV] END colsample_bytree=0.9660854910505922, gamma=0.13270566891933133, learning_rate=0.05795747183148065, max_depth=8, min_child_weight=1, n_estimators=336, reg_alpha=0.27993389694594284, reg_lambda=1.9097305613263882, subsample=0.8951587666783074; total time=  49.6s\n",
      "[CV] END colsample_bytree=0.8217416210045603, gamma=0.18351622387030567, learning_rate=0.09392001248555798, max_depth=6, min_child_weight=2, n_estimators=243, reg_alpha=0.15864644764249103, reg_lambda=0.24032929561128435, subsample=0.7367518666865607; total time=  19.2s\n",
      "[CV] END colsample_bytree=0.6367196263253767, gamma=0.028247096480568033, learning_rate=0.07228266187825884, max_depth=8, min_child_weight=4, n_estimators=303, reg_alpha=0.017161101831750236, reg_lambda=1.5267288460078219, subsample=0.9227651908203118; total time=  24.2s\n",
      "[CV] END colsample_bytree=0.7385217284357604, gamma=0.1394021438818834, learning_rate=0.1399547365285527, max_depth=4, min_child_weight=2, n_estimators=345, reg_alpha=0.6350936508676438, reg_lambda=0.09060801954408904, subsample=0.7498450458505885; total time=  12.9s\n",
      "[CV] END colsample_bytree=0.7385217284357604, gamma=0.1394021438818834, learning_rate=0.1399547365285527, max_depth=4, min_child_weight=2, n_estimators=345, reg_alpha=0.6350936508676438, reg_lambda=0.09060801954408904, subsample=0.7498450458505885; total time=  13.1s\n",
      "[CV] END colsample_bytree=0.9468795734220015, gamma=0.1909210792338034, learning_rate=0.17018985893647998, max_depth=6, min_child_weight=2, n_estimators=262, reg_alpha=0.6432882184423532, reg_lambda=0.9165057809830333, subsample=0.818246715726374; total time=  13.8s\n",
      "[CV] END colsample_bytree=0.97658592351061, gamma=0.11583079134023228, learning_rate=0.20223811276478287, max_depth=4, min_child_weight=3, n_estimators=143, reg_alpha=0.27396112732113376, reg_lambda=0.42917823941674826, subsample=0.7509036332911904; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.97658592351061, gamma=0.11583079134023228, learning_rate=0.20223811276478287, max_depth=4, min_child_weight=3, n_estimators=143, reg_alpha=0.27396112732113376, reg_lambda=0.42917823941674826, subsample=0.7509036332911904; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.6155852529240934, gamma=0.18547616530136785, learning_rate=0.07731084297774529, max_depth=4, min_child_weight=5, n_estimators=189, reg_alpha=0.34062456946424, reg_lambda=0.5213890564718062, subsample=0.7984149817173625; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.8771561434767757, gamma=0.10450098133595921, learning_rate=0.19732963037114148, max_depth=6, min_child_weight=1, n_estimators=376, reg_alpha=0.9675805515202475, reg_lambda=1.0959437664961746, subsample=0.7693883769232475; total time=  16.8s\n",
      "[CV] END colsample_bytree=0.8274081134999833, gamma=0.17277737257742537, learning_rate=0.15632955105992805, max_depth=6, min_child_weight=2, n_estimators=195, reg_alpha=0.34080354025301784, reg_lambda=1.8615146512071294, subsample=0.9433651007372047; total time=  14.0s\n",
      "[CV] END colsample_bytree=0.7715976109500073, gamma=0.2252613203374492, learning_rate=0.1609085748169365, max_depth=3, min_child_weight=6, n_estimators=372, reg_alpha=0.5343274735305634, reg_lambda=0.9931223813661554, subsample=0.7558472344876814; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.749816047538945, learning_rate=0.20014286128198325, max_depth=5, min_child_weight=8.796910002727692, n_estimators=120, num_leaves=94, reg_alpha=0.45924889196586716, reg_lambda=0.6674172222780437, subsample=0.6571467271687763; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8603553891795411, learning_rate=0.021282315805420053, max_depth=6, min_child_weight=10.385527090157503, n_estimators=291, num_leaves=79, reg_alpha=0.18340450985343382, reg_lambda=0.6084844859190754, subsample=0.8099025726528951; total time= 6.0min\n",
      "[CV] END colsample_bytree=0.7727780074568463, learning_rate=0.06824582803960838, max_depth=5, min_child_weight=4.998609717152554, n_estimators=287, num_leaves=99, reg_alpha=0.23277134043030423, reg_lambda=0.1812128690656416, subsample=0.8473544037332349; total time= 3.8min\n",
      "[CV] END colsample_bytree=0.7529847965068651, learning_rate=0.20664617716135766, max_depth=3, min_child_weight=1.4645041271999772, n_estimators=234, num_leaves=40, reg_alpha=0.450499251969543, reg_lambda=0.026529922319733057, subsample=0.9768807022739411; total time= 1.7min\n",
      "[CV] END colsample_bytree=0.8253152871382157, learning_rate=0.08708330050798323, max_depth=4, min_child_weight=1.9767211400638387, n_estimators=191, num_leaves=79, reg_alpha=0.12203823484477883, reg_lambda=0.9903538202225404, subsample=0.6137554084460873; total time= 2.6min\n",
      "[CV] END colsample_bytree=0.9637281608315128, learning_rate=0.061755996320003385, max_depth=6, min_child_weight=4.11711076089411, n_estimators=153, num_leaves=23, reg_alpha=0.18485445552552704, reg_lambda=1.9391692555291171, subsample=0.9100531293444458; total time= 3.5min\n",
      "[CV] END colsample_bytree=0.9757995766256756, learning_rate=0.18896547008552977, max_depth=8, min_child_weight=8.27271995856421, n_estimators=370, num_leaves=91, reg_alpha=0.5704439744053994, reg_lambda=1.0416685200516473, subsample=0.9844688097397396; total time= 2.5min\n",
      "[CV] END colsample_bytree=0.9378135394712606, learning_rate=0.1594640220274762, max_depth=9, min_child_weight=9.287375091519294, n_estimators=316, num_leaves=79, reg_alpha=0.5426960831582485, reg_lambda=0.2818484499495253, subsample=0.9208787923016158; total time= 2.4min\n",
      "[CV] END colsample_bytree=0.6298202574719083, learning_rate=0.20737738732010347, max_depth=3, min_child_weight=2.987156815341724, n_estimators=162, num_leaves=30, reg_alpha=0.19884240408880516, reg_lambda=1.4226839054973, subsample=0.9160702162124823; total time= 1.4min\n",
      "[CV] END colsample_bytree=0.8423839899124046, learning_rate=0.19526017570266982, max_depth=4, min_child_weight=2.158690595251297, n_estimators=234, num_leaves=92, reg_alpha=0.6232981268275579, reg_lambda=0.6617960497052984, subsample=0.6254233401144095; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.7243929286862649, learning_rate=0.07503666440534941, max_depth=5, min_child_weight=6.912977877077271, n_estimators=313, num_leaves=54, reg_alpha=0.4722149251619493, reg_lambda=0.2391884918766034, subsample=0.885297914889198; total time= 3.4min\n",
      "[CV] END colsample_bytree=0.9043140194467589, learning_rate=0.12225543951389925, max_depth=9, min_child_weight=3.5606832276132394, n_estimators=382, num_leaves=28, reg_alpha=0.7106628896857874, reg_lambda=0.22178164162366265, subsample=0.7757346007463081; total time= 4.0min\n",
      "[CV] END colsample_bytree=0.6806876809341584, learning_rate=0.18915271913470388, max_depth=3, min_child_weight=4.143559810763267, n_estimators=195, num_leaves=23, reg_alpha=0.907566473926093, reg_lambda=0.4985844582977499, subsample=0.7641531692142519; total time= 1.5min\n",
      "[CV] END colsample_bytree=0.9022204554172195, learning_rate=0.0557596330983245, max_depth=9, min_child_weight=3.8975145291376805, n_estimators=185, num_leaves=47, reg_alpha=0.9296976523425731, reg_lambda=1.616240759128834, subsample=0.8533615026041694; total time= 4.6min\n",
      "[CV] END colsample_bytree=0.9485842360750871, learning_rate=0.17073441537982292, max_depth=6, min_child_weight=5.165099478703662, n_estimators=227, num_leaves=81, reg_alpha=0.11005192452767676, reg_lambda=0.45587032508388337, subsample=0.7708431154505025; total time= 2.1min\n",
      "[CV] END colsample_bytree=0.9272059063689972, learning_rate=0.1821461166512687, max_depth=9, min_child_weight=2.6465585314294175, n_estimators=236, num_leaves=81, reg_alpha=0.22210781047073025, reg_lambda=0.2397307346673656, subsample=0.7350460685614512; total time= 2.5min\n",
      "[CV] END colsample_bytree=0.9771638815650077, learning_rate=0.07464058640415104, max_depth=3, min_child_weight=5.038361710580408, n_estimators=151, num_leaves=31, reg_alpha=0.25178229582536416, reg_lambda=0.9944970117847709, subsample=0.7203513239267079; total time= 1.3min\n",
      "[CV] END colsample_bytree=0.713936197750987, learning_rate=0.01737738947090656, max_depth=3, min_child_weight=10.766149558326529, n_estimators=319, num_leaves=73, reg_alpha=0.033050732900548385, reg_lambda=0.690142496053366, subsample=0.8537405378805455; total time= 3.6min\n",
      "[CV] END colsample_bytree=0.8722821806219068, learning_rate=0.11618691666342727, max_depth=4, min_child_weight=10.856504541106007, n_estimators=346, num_leaves=87, reg_alpha=0.08085332633271525, reg_lambda=0.7393089121228089, subsample=0.6968639753109703; total time= 4.4min\n",
      "[CV] END colsample_bytree=0.9212559025519583, learning_rate=0.10406012688920768, max_depth=4, min_child_weight=7.335297107608947, n_estimators=339, num_leaves=35, reg_alpha=0.835302495589238, reg_lambda=0.6415601299434717, subsample=0.6746074041599417; total time= 4.8min\n",
      "[CV] END colsample_bytree=0.6163100566219055, learning_rate=0.12817858863764836, max_depth=5, min_child_weight=3.202410475655483, n_estimators=246, num_leaves=39, reg_alpha=0.6451727904094499, reg_lambda=0.3487328580099829, subsample=0.8763750952409863; total time= 4.8min\n",
      "[CV] END colsample_bytree=0.7546941385202149, learning_rate=0.19734599774734693, max_depth=3, min_child_weight=7.7569011703928075, n_estimators=250, num_leaves=50, reg_alpha=0.877339353380981, reg_lambda=0.5158832554303112, subsample=0.8639936184136716; total time= 2.6min\n",
      "[CV] END colsample_bytree=0.9268888800804863, learning_rate=0.12104016231989247, max_depth=6, min_child_weight=3.60829174830409, n_estimators=353, num_leaves=31, reg_alpha=0.5582934536070976, reg_lambda=1.7652726863786794, subsample=0.6754828433365517; total time= 6.5min\n",
      "[CV] END colsample_bytree=0.7115485410368727, learning_rate=0.15007156599455426, max_depth=5, min_child_weight=9.563242918780924, n_estimators=153, num_leaves=52, reg_alpha=0.6420316461542878, reg_lambda=0.16827992999009767, subsample=0.6646514856378455; total time= 2.7min\n",
      "[CV] END colsample_bytree=0.9594216754108317, learning_rate=0.131285811931918, max_depth=5, min_child_weight=4.722827665617431, n_estimators=198, num_leaves=44, reg_alpha=0.005061583846218687, reg_lambda=0.3216161028349973, subsample=0.8194935157466344; total time= 3.6min\n",
      "[CV] END colsample_bytree=0.8767580790770773, learning_rate=0.14039225190052013, max_depth=3, min_child_weight=2.759252526773454, n_estimators=167, num_leaves=52, reg_alpha=0.4938937151834346, reg_lambda=0.3576454184426576, subsample=0.7465875138331439; total time= 2.3min\n",
      "[CV] END colsample_bytree=0.8767580790770773, learning_rate=0.14039225190052013, max_depth=3, min_child_weight=2.759252526773454, n_estimators=167, num_leaves=52, reg_alpha=0.4938937151834346, reg_lambda=0.3576454184426576, subsample=0.7465875138331439; total time= 2.1min\n",
      "[CV] END colsample_bytree=0.8524554503989051, learning_rate=0.1689622607083297, max_depth=8, min_child_weight=7.451033620305648, n_estimators=246, num_leaves=23, reg_alpha=0.02431596643145384, reg_lambda=1.2909445918143356, subsample=0.6708442717628196; total time= 3.6min\n",
      "[CV] END colsample_bytree=0.9761834337411657, learning_rate=0.20078571540051748, max_depth=7, min_child_weight=9.83494022266259, n_estimators=332, num_leaves=56, reg_alpha=0.9283185625877254, reg_lambda=0.8563682966346287, subsample=0.9866619276174678; total time= 3.7min\n",
      "[CV] END colsample_bytree=0.9854479908357011, learning_rate=0.18060189109347202, max_depth=9, min_child_weight=4.056970192871819, n_estimators=260, num_leaves=86, reg_alpha=0.1694927466860925, reg_lambda=1.1136025249167003, subsample=0.9744619096643123; total time= 3.5min\n",
      "[CV] END colsample_bytree=0.8784119186699892, learning_rate=0.124012234017873, max_depth=4, min_child_weight=7.150072266991698, n_estimators=250, num_leaves=85, reg_alpha=0.25416364906973876, reg_lambda=0.5905811768378775, subsample=0.7290203056954402; total time= 3.1min"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8603553891795411, learning_rate=0.021282315805420053, max_depth=6, min_child_weight=10.385527090157503, n_estimators=291, num_leaves=79, reg_alpha=0.18340450985343382, reg_lambda=0.6084844859190754, subsample=0.8099025726528951; total time= 5.8min\n",
      "[CV] END colsample_bytree=0.7727780074568463, learning_rate=0.06824582803960838, max_depth=5, min_child_weight=4.998609717152554, n_estimators=287, num_leaves=99, reg_alpha=0.23277134043030423, reg_lambda=0.1812128690656416, subsample=0.8473544037332349; total time= 3.7min\n",
      "[CV] END colsample_bytree=0.7529847965068651, learning_rate=0.20664617716135766, max_depth=3, min_child_weight=1.4645041271999772, n_estimators=234, num_leaves=40, reg_alpha=0.450499251969543, reg_lambda=0.026529922319733057, subsample=0.9768807022739411; total time= 1.8min\n",
      "[CV] END colsample_bytree=0.8253152871382157, learning_rate=0.08708330050798323, max_depth=4, min_child_weight=1.9767211400638387, n_estimators=191, num_leaves=79, reg_alpha=0.12203823484477883, reg_lambda=0.9903538202225404, subsample=0.6137554084460873; total time= 2.6min\n",
      "[CV] END colsample_bytree=0.9637281608315128, learning_rate=0.061755996320003385, max_depth=6, min_child_weight=4.11711076089411, n_estimators=153, num_leaves=23, reg_alpha=0.18485445552552704, reg_lambda=1.9391692555291171, subsample=0.9100531293444458; total time= 3.4min\n",
      "[CV] END colsample_bytree=0.9757995766256756, learning_rate=0.18896547008552977, max_depth=8, min_child_weight=8.27271995856421, n_estimators=370, num_leaves=91, reg_alpha=0.5704439744053994, reg_lambda=1.0416685200516473, subsample=0.9844688097397396; total time= 2.5min\n",
      "[CV] END colsample_bytree=0.9378135394712606, learning_rate=0.1594640220274762, max_depth=9, min_child_weight=9.287375091519294, n_estimators=316, num_leaves=79, reg_alpha=0.5426960831582485, reg_lambda=0.2818484499495253, subsample=0.9208787923016158; total time= 2.4min\n",
      "[CV] END colsample_bytree=0.6298202574719083, learning_rate=0.20737738732010347, max_depth=3, min_child_weight=2.987156815341724, n_estimators=162, num_leaves=30, reg_alpha=0.19884240408880516, reg_lambda=1.4226839054973, subsample=0.9160702162124823; total time= 1.4min\n",
      "[CV] END colsample_bytree=0.8423839899124046, learning_rate=0.19526017570266982, max_depth=4, min_child_weight=2.158690595251297, n_estimators=234, num_leaves=92, reg_alpha=0.6232981268275579, reg_lambda=0.6617960497052984, subsample=0.6254233401144095; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.7243929286862649, learning_rate=0.07503666440534941, max_depth=5, min_child_weight=6.912977877077271, n_estimators=313, num_leaves=54, reg_alpha=0.4722149251619493, reg_lambda=0.2391884918766034, subsample=0.885297914889198; total time= 3.4min\n",
      "[CV] END colsample_bytree=0.9043140194467589, learning_rate=0.12225543951389925, max_depth=9, min_child_weight=3.5606832276132394, n_estimators=382, num_leaves=28, reg_alpha=0.7106628896857874, reg_lambda=0.22178164162366265, subsample=0.7757346007463081; total time= 4.1min\n",
      "[CV] END colsample_bytree=0.6806876809341584, learning_rate=0.18915271913470388, max_depth=3, min_child_weight=4.143559810763267, n_estimators=195, num_leaves=23, reg_alpha=0.907566473926093, reg_lambda=0.4985844582977499, subsample=0.7641531692142519; total time= 1.6min\n",
      "[CV] END colsample_bytree=0.9022204554172195, learning_rate=0.0557596330983245, max_depth=9, min_child_weight=3.8975145291376805, n_estimators=185, num_leaves=47, reg_alpha=0.9296976523425731, reg_lambda=1.616240759128834, subsample=0.8533615026041694; total time= 4.4min\n",
      "[CV] END colsample_bytree=0.9485842360750871, learning_rate=0.17073441537982292, max_depth=6, min_child_weight=5.165099478703662, n_estimators=227, num_leaves=81, reg_alpha=0.11005192452767676, reg_lambda=0.45587032508388337, subsample=0.7708431154505025; total time= 2.0min\n",
      "[CV] END colsample_bytree=0.9272059063689972, learning_rate=0.1821461166512687, max_depth=9, min_child_weight=2.6465585314294175, n_estimators=236, num_leaves=81, reg_alpha=0.22210781047073025, reg_lambda=0.2397307346673656, subsample=0.7350460685614512; total time= 2.6min\n",
      "[CV] END colsample_bytree=0.9771638815650077, learning_rate=0.07464058640415104, max_depth=3, min_child_weight=5.038361710580408, n_estimators=151, num_leaves=31, reg_alpha=0.25178229582536416, reg_lambda=0.9944970117847709, subsample=0.7203513239267079; total time= 1.4min\n",
      "[CV] END colsample_bytree=0.713936197750987, learning_rate=0.01737738947090656, max_depth=3, min_child_weight=10.766149558326529, n_estimators=319, num_leaves=73, reg_alpha=0.033050732900548385, reg_lambda=0.690142496053366, subsample=0.8537405378805455; total time= 4.3min\n",
      "[CV] END colsample_bytree=0.8722821806219068, learning_rate=0.11618691666342727, max_depth=4, min_child_weight=10.856504541106007, n_estimators=346, num_leaves=87, reg_alpha=0.08085332633271525, reg_lambda=0.7393089121228089, subsample=0.6968639753109703; total time= 4.4min\n",
      "[CV] END colsample_bytree=0.9212559025519583, learning_rate=0.10406012688920768, max_depth=4, min_child_weight=7.335297107608947, n_estimators=339, num_leaves=35, reg_alpha=0.835302495589238, reg_lambda=0.6415601299434717, subsample=0.6746074041599417; total time= 5.1min\n",
      "[CV] END colsample_bytree=0.6163100566219055, learning_rate=0.12817858863764836, max_depth=5, min_child_weight=3.202410475655483, n_estimators=246, num_leaves=39, reg_alpha=0.6451727904094499, reg_lambda=0.3487328580099829, subsample=0.8763750952409863; total time= 5.0min\n",
      "[CV] END colsample_bytree=0.7546941385202149, learning_rate=0.19734599774734693, max_depth=3, min_child_weight=7.7569011703928075, n_estimators=250, num_leaves=50, reg_alpha=0.877339353380981, reg_lambda=0.5158832554303112, subsample=0.8639936184136716; total time= 2.8min\n",
      "[CV] END colsample_bytree=0.9268888800804863, learning_rate=0.12104016231989247, max_depth=6, min_child_weight=3.60829174830409, n_estimators=353, num_leaves=31, reg_alpha=0.5582934536070976, reg_lambda=1.7652726863786794, subsample=0.6754828433365517; total time= 6.5min\n",
      "[CV] END colsample_bytree=0.7115485410368727, learning_rate=0.15007156599455426, max_depth=5, min_child_weight=9.563242918780924, n_estimators=153, num_leaves=52, reg_alpha=0.6420316461542878, reg_lambda=0.16827992999009767, subsample=0.6646514856378455; total time= 2.8min\n",
      "[CV] END colsample_bytree=0.9594216754108317, learning_rate=0.131285811931918, max_depth=5, min_child_weight=4.722827665617431, n_estimators=198, num_leaves=44, reg_alpha=0.005061583846218687, reg_lambda=0.3216161028349973, subsample=0.8194935157466344; total time= 3.5min\n",
      "[CV] END colsample_bytree=0.8767580790770773, learning_rate=0.14039225190052013, max_depth=3, min_child_weight=2.759252526773454, n_estimators=167, num_leaves=52, reg_alpha=0.4938937151834346, reg_lambda=0.3576454184426576, subsample=0.7465875138331439; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.8976682092226249, learning_rate=0.15418798485042587, max_depth=3, min_child_weight=6.425402305548993, n_estimators=121, num_leaves=49, reg_alpha=0.9730105547524456, reg_lambda=0.7861954493335208, subsample=0.9568186220708453; total time= 1.7min\n",
      "[CV] END colsample_bytree=0.8524554503989051, learning_rate=0.1689622607083297, max_depth=8, min_child_weight=7.451033620305648, n_estimators=246, num_leaves=23, reg_alpha=0.02431596643145384, reg_lambda=1.2909445918143356, subsample=0.6708442717628196; total time= 3.7min\n",
      "[CV] END colsample_bytree=0.9761834337411657, learning_rate=0.20078571540051748, max_depth=7, min_child_weight=9.83494022266259, n_estimators=332, num_leaves=56, reg_alpha=0.9283185625877254, reg_lambda=0.8563682966346287, subsample=0.9866619276174678; total time= 3.5min\n",
      "[CV] END colsample_bytree=0.9854479908357011, learning_rate=0.18060189109347202, max_depth=9, min_child_weight=4.056970192871819, n_estimators=260, num_leaves=86, reg_alpha=0.1694927466860925, reg_lambda=1.1136025249167003, subsample=0.9744619096643123; total time= 3.6min\n",
      "[CV] END colsample_bytree=0.8784119186699892, learning_rate=0.124012234017873, max_depth=4, min_child_weight=7.150072266991698, n_estimators=250, num_leaves=85, reg_alpha=0.25416364906973876, reg_lambda=0.5905811768378775, subsample=0.7290203056954402; total time= 2.9min"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8603553891795411, learning_rate=0.021282315805420053, max_depth=6, min_child_weight=10.385527090157503, n_estimators=291, num_leaves=79, reg_alpha=0.18340450985343382, reg_lambda=0.6084844859190754, subsample=0.8099025726528951; total time= 6.1min\n",
      "[CV] END colsample_bytree=0.7727780074568463, learning_rate=0.06824582803960838, max_depth=5, min_child_weight=4.998609717152554, n_estimators=287, num_leaves=99, reg_alpha=0.23277134043030423, reg_lambda=0.1812128690656416, subsample=0.8473544037332349; total time= 3.8min\n",
      "[CV] END colsample_bytree=0.7529847965068651, learning_rate=0.20664617716135766, max_depth=3, min_child_weight=1.4645041271999772, n_estimators=234, num_leaves=40, reg_alpha=0.450499251969543, reg_lambda=0.026529922319733057, subsample=0.9768807022739411; total time= 1.8min\n",
      "[CV] END colsample_bytree=0.8253152871382157, learning_rate=0.08708330050798323, max_depth=4, min_child_weight=1.9767211400638387, n_estimators=191, num_leaves=79, reg_alpha=0.12203823484477883, reg_lambda=0.9903538202225404, subsample=0.6137554084460873; total time= 2.7min\n",
      "[CV] END colsample_bytree=0.9637281608315128, learning_rate=0.061755996320003385, max_depth=6, min_child_weight=4.11711076089411, n_estimators=153, num_leaves=23, reg_alpha=0.18485445552552704, reg_lambda=1.9391692555291171, subsample=0.9100531293444458; total time= 3.3min\n",
      "[CV] END colsample_bytree=0.9757995766256756, learning_rate=0.18896547008552977, max_depth=8, min_child_weight=8.27271995856421, n_estimators=370, num_leaves=91, reg_alpha=0.5704439744053994, reg_lambda=1.0416685200516473, subsample=0.9844688097397396; total time= 2.5min\n",
      "[CV] END colsample_bytree=0.9378135394712606, learning_rate=0.1594640220274762, max_depth=9, min_child_weight=9.287375091519294, n_estimators=316, num_leaves=79, reg_alpha=0.5426960831582485, reg_lambda=0.2818484499495253, subsample=0.9208787923016158; total time= 2.5min\n",
      "[CV] END colsample_bytree=0.6298202574719083, learning_rate=0.20737738732010347, max_depth=3, min_child_weight=2.987156815341724, n_estimators=162, num_leaves=30, reg_alpha=0.19884240408880516, reg_lambda=1.4226839054973, subsample=0.9160702162124823; total time= 1.5min\n",
      "[CV] END colsample_bytree=0.8423839899124046, learning_rate=0.19526017570266982, max_depth=4, min_child_weight=2.158690595251297, n_estimators=234, num_leaves=92, reg_alpha=0.6232981268275579, reg_lambda=0.6617960497052984, subsample=0.6254233401144095; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.7243929286862649, learning_rate=0.07503666440534941, max_depth=5, min_child_weight=6.912977877077271, n_estimators=313, num_leaves=54, reg_alpha=0.4722149251619493, reg_lambda=0.2391884918766034, subsample=0.885297914889198; total time= 3.4min\n",
      "[CV] END colsample_bytree=0.9043140194467589, learning_rate=0.12225543951389925, max_depth=9, min_child_weight=3.5606832276132394, n_estimators=382, num_leaves=28, reg_alpha=0.7106628896857874, reg_lambda=0.22178164162366265, subsample=0.7757346007463081; total time= 4.0min\n",
      "[CV] END colsample_bytree=0.6806876809341584, learning_rate=0.18915271913470388, max_depth=3, min_child_weight=4.143559810763267, n_estimators=195, num_leaves=23, reg_alpha=0.907566473926093, reg_lambda=0.4985844582977499, subsample=0.7641531692142519; total time= 1.7min\n",
      "[CV] END colsample_bytree=0.9022204554172195, learning_rate=0.0557596330983245, max_depth=9, min_child_weight=3.8975145291376805, n_estimators=185, num_leaves=47, reg_alpha=0.9296976523425731, reg_lambda=1.616240759128834, subsample=0.8533615026041694; total time= 4.5min\n",
      "[CV] END colsample_bytree=0.9485842360750871, learning_rate=0.17073441537982292, max_depth=6, min_child_weight=5.165099478703662, n_estimators=227, num_leaves=81, reg_alpha=0.11005192452767676, reg_lambda=0.45587032508388337, subsample=0.7708431154505025; total time= 2.1min\n",
      "[CV] END colsample_bytree=0.9272059063689972, learning_rate=0.1821461166512687, max_depth=9, min_child_weight=2.6465585314294175, n_estimators=236, num_leaves=81, reg_alpha=0.22210781047073025, reg_lambda=0.2397307346673656, subsample=0.7350460685614512; total time= 2.5min\n",
      "[CV] END colsample_bytree=0.9771638815650077, learning_rate=0.07464058640415104, max_depth=3, min_child_weight=5.038361710580408, n_estimators=151, num_leaves=31, reg_alpha=0.25178229582536416, reg_lambda=0.9944970117847709, subsample=0.7203513239267079; total time= 1.4min\n",
      "[CV] END colsample_bytree=0.713936197750987, learning_rate=0.01737738947090656, max_depth=3, min_child_weight=10.766149558326529, n_estimators=319, num_leaves=73, reg_alpha=0.033050732900548385, reg_lambda=0.690142496053366, subsample=0.8537405378805455; total time= 4.4min\n",
      "[CV] END colsample_bytree=0.8722821806219068, learning_rate=0.11618691666342727, max_depth=4, min_child_weight=10.856504541106007, n_estimators=346, num_leaves=87, reg_alpha=0.08085332633271525, reg_lambda=0.7393089121228089, subsample=0.6968639753109703; total time= 4.2min\n",
      "[CV] END colsample_bytree=0.9212559025519583, learning_rate=0.10406012688920768, max_depth=4, min_child_weight=7.335297107608947, n_estimators=339, num_leaves=35, reg_alpha=0.835302495589238, reg_lambda=0.6415601299434717, subsample=0.6746074041599417; total time= 4.7min\n",
      "[CV] END colsample_bytree=0.6163100566219055, learning_rate=0.12817858863764836, max_depth=5, min_child_weight=3.202410475655483, n_estimators=246, num_leaves=39, reg_alpha=0.6451727904094499, reg_lambda=0.3487328580099829, subsample=0.8763750952409863; total time= 5.1min\n",
      "[CV] END colsample_bytree=0.7546941385202149, learning_rate=0.19734599774734693, max_depth=3, min_child_weight=7.7569011703928075, n_estimators=250, num_leaves=50, reg_alpha=0.877339353380981, reg_lambda=0.5158832554303112, subsample=0.8639936184136716; total time= 2.8min\n",
      "[CV] END colsample_bytree=0.9268888800804863, learning_rate=0.12104016231989247, max_depth=6, min_child_weight=3.60829174830409, n_estimators=353, num_leaves=31, reg_alpha=0.5582934536070976, reg_lambda=1.7652726863786794, subsample=0.6754828433365517; total time= 6.2min\n",
      "[CV] END colsample_bytree=0.7115485410368727, learning_rate=0.15007156599455426, max_depth=5, min_child_weight=9.563242918780924, n_estimators=153, num_leaves=52, reg_alpha=0.6420316461542878, reg_lambda=0.16827992999009767, subsample=0.6646514856378455; total time= 3.0min\n",
      "[CV] END colsample_bytree=0.9594216754108317, learning_rate=0.131285811931918, max_depth=5, min_child_weight=4.722827665617431, n_estimators=198, num_leaves=44, reg_alpha=0.005061583846218687, reg_lambda=0.3216161028349973, subsample=0.8194935157466344; total time= 3.7min\n",
      "[CV] END colsample_bytree=0.8767580790770773, learning_rate=0.14039225190052013, max_depth=3, min_child_weight=2.759252526773454, n_estimators=167, num_leaves=52, reg_alpha=0.4938937151834346, reg_lambda=0.3576454184426576, subsample=0.7465875138331439; total time= 2.1min\n",
      "[CV] END colsample_bytree=0.8976682092226249, learning_rate=0.15418798485042587, max_depth=3, min_child_weight=6.425402305548993, n_estimators=121, num_leaves=49, reg_alpha=0.9730105547524456, reg_lambda=0.7861954493335208, subsample=0.9568186220708453; total time= 1.7min\n",
      "[CV] END colsample_bytree=0.8524554503989051, learning_rate=0.1689622607083297, max_depth=8, min_child_weight=7.451033620305648, n_estimators=246, num_leaves=23, reg_alpha=0.02431596643145384, reg_lambda=1.2909445918143356, subsample=0.6708442717628196; total time= 3.6min\n",
      "[CV] END colsample_bytree=0.9761834337411657, learning_rate=0.20078571540051748, max_depth=7, min_child_weight=9.83494022266259, n_estimators=332, num_leaves=56, reg_alpha=0.9283185625877254, reg_lambda=0.8563682966346287, subsample=0.9866619276174678; total time= 3.7min\n",
      "[CV] END colsample_bytree=0.9854479908357011, learning_rate=0.18060189109347202, max_depth=9, min_child_weight=4.056970192871819, n_estimators=260, num_leaves=86, reg_alpha=0.1694927466860925, reg_lambda=1.1136025249167003, subsample=0.9744619096643123; total time= 3.3min\n",
      "[CV] END colsample_bytree=0.8784119186699892, learning_rate=0.124012234017873, max_depth=4, min_child_weight=7.150072266991698, n_estimators=250, num_leaves=85, reg_alpha=0.25416364906973876, reg_lambda=0.5905811768378775, subsample=0.7290203056954402; total time= 2.8min"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8603553891795411, learning_rate=0.021282315805420053, max_depth=6, min_child_weight=10.385527090157503, n_estimators=291, num_leaves=79, reg_alpha=0.18340450985343382, reg_lambda=0.6084844859190754, subsample=0.8099025726528951; total time= 5.9min\n",
      "[CV] END colsample_bytree=0.7727780074568463, learning_rate=0.06824582803960838, max_depth=5, min_child_weight=4.998609717152554, n_estimators=287, num_leaves=99, reg_alpha=0.23277134043030423, reg_lambda=0.1812128690656416, subsample=0.8473544037332349; total time= 4.0min\n",
      "[CV] END colsample_bytree=0.7529847965068651, learning_rate=0.20664617716135766, max_depth=3, min_child_weight=1.4645041271999772, n_estimators=234, num_leaves=40, reg_alpha=0.450499251969543, reg_lambda=0.026529922319733057, subsample=0.9768807022739411; total time= 1.9min\n",
      "[CV] END colsample_bytree=0.8253152871382157, learning_rate=0.08708330050798323, max_depth=4, min_child_weight=1.9767211400638387, n_estimators=191, num_leaves=79, reg_alpha=0.12203823484477883, reg_lambda=0.9903538202225404, subsample=0.6137554084460873; total time= 2.9min\n",
      "[CV] END colsample_bytree=0.9637281608315128, learning_rate=0.061755996320003385, max_depth=6, min_child_weight=4.11711076089411, n_estimators=153, num_leaves=23, reg_alpha=0.18485445552552704, reg_lambda=1.9391692555291171, subsample=0.9100531293444458; total time= 3.5min\n",
      "[CV] END colsample_bytree=0.9757995766256756, learning_rate=0.18896547008552977, max_depth=8, min_child_weight=8.27271995856421, n_estimators=370, num_leaves=91, reg_alpha=0.5704439744053994, reg_lambda=1.0416685200516473, subsample=0.9844688097397396; total time= 2.5min\n",
      "[CV] END colsample_bytree=0.9378135394712606, learning_rate=0.1594640220274762, max_depth=9, min_child_weight=9.287375091519294, n_estimators=316, num_leaves=79, reg_alpha=0.5426960831582485, reg_lambda=0.2818484499495253, subsample=0.9208787923016158; total time= 2.5min\n",
      "[CV] END colsample_bytree=0.6298202574719083, learning_rate=0.20737738732010347, max_depth=3, min_child_weight=2.987156815341724, n_estimators=162, num_leaves=30, reg_alpha=0.19884240408880516, reg_lambda=1.4226839054973, subsample=0.9160702162124823; total time= 1.5min\n",
      "[CV] END colsample_bytree=0.8423839899124046, learning_rate=0.19526017570266982, max_depth=4, min_child_weight=2.158690595251297, n_estimators=234, num_leaves=92, reg_alpha=0.6232981268275579, reg_lambda=0.6617960497052984, subsample=0.6254233401144095; total time= 2.3min\n",
      "[CV] END colsample_bytree=0.7243929286862649, learning_rate=0.07503666440534941, max_depth=5, min_child_weight=6.912977877077271, n_estimators=313, num_leaves=54, reg_alpha=0.4722149251619493, reg_lambda=0.2391884918766034, subsample=0.885297914889198; total time= 3.6min\n",
      "[CV] END colsample_bytree=0.9043140194467589, learning_rate=0.12225543951389925, max_depth=9, min_child_weight=3.5606832276132394, n_estimators=382, num_leaves=28, reg_alpha=0.7106628896857874, reg_lambda=0.22178164162366265, subsample=0.7757346007463081; total time= 3.9min\n",
      "[CV] END colsample_bytree=0.6806876809341584, learning_rate=0.18915271913470388, max_depth=3, min_child_weight=4.143559810763267, n_estimators=195, num_leaves=23, reg_alpha=0.907566473926093, reg_lambda=0.4985844582977499, subsample=0.7641531692142519; total time= 1.5min\n",
      "[CV] END colsample_bytree=0.9022204554172195, learning_rate=0.0557596330983245, max_depth=9, min_child_weight=3.8975145291376805, n_estimators=185, num_leaves=47, reg_alpha=0.9296976523425731, reg_lambda=1.616240759128834, subsample=0.8533615026041694; total time= 4.3min\n",
      "[CV] END colsample_bytree=0.9485842360750871, learning_rate=0.17073441537982292, max_depth=6, min_child_weight=5.165099478703662, n_estimators=227, num_leaves=81, reg_alpha=0.11005192452767676, reg_lambda=0.45587032508388337, subsample=0.7708431154505025; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.9272059063689972, learning_rate=0.1821461166512687, max_depth=9, min_child_weight=2.6465585314294175, n_estimators=236, num_leaves=81, reg_alpha=0.22210781047073025, reg_lambda=0.2397307346673656, subsample=0.7350460685614512; total time= 2.5min\n",
      "[CV] END colsample_bytree=0.9771638815650077, learning_rate=0.07464058640415104, max_depth=3, min_child_weight=5.038361710580408, n_estimators=151, num_leaves=31, reg_alpha=0.25178229582536416, reg_lambda=0.9944970117847709, subsample=0.7203513239267079; total time= 1.3min\n",
      "[CV] END colsample_bytree=0.713936197750987, learning_rate=0.01737738947090656, max_depth=3, min_child_weight=10.766149558326529, n_estimators=319, num_leaves=73, reg_alpha=0.033050732900548385, reg_lambda=0.690142496053366, subsample=0.8537405378805455; total time= 4.7min\n",
      "[CV] END colsample_bytree=0.8722821806219068, learning_rate=0.11618691666342727, max_depth=4, min_child_weight=10.856504541106007, n_estimators=346, num_leaves=87, reg_alpha=0.08085332633271525, reg_lambda=0.7393089121228089, subsample=0.6968639753109703; total time= 4.1min\n",
      "[CV] END colsample_bytree=0.9212559025519583, learning_rate=0.10406012688920768, max_depth=4, min_child_weight=7.335297107608947, n_estimators=339, num_leaves=35, reg_alpha=0.835302495589238, reg_lambda=0.6415601299434717, subsample=0.6746074041599417; total time= 5.1min\n",
      "[CV] END colsample_bytree=0.6163100566219055, learning_rate=0.12817858863764836, max_depth=5, min_child_weight=3.202410475655483, n_estimators=246, num_leaves=39, reg_alpha=0.6451727904094499, reg_lambda=0.3487328580099829, subsample=0.8763750952409863; total time= 5.0min\n",
      "[CV] END colsample_bytree=0.7546941385202149, learning_rate=0.19734599774734693, max_depth=3, min_child_weight=7.7569011703928075, n_estimators=250, num_leaves=50, reg_alpha=0.877339353380981, reg_lambda=0.5158832554303112, subsample=0.8639936184136716; total time= 2.7min\n",
      "[CV] END colsample_bytree=0.9268888800804863, learning_rate=0.12104016231989247, max_depth=6, min_child_weight=3.60829174830409, n_estimators=353, num_leaves=31, reg_alpha=0.5582934536070976, reg_lambda=1.7652726863786794, subsample=0.6754828433365517; total time= 6.5min\n",
      "[CV] END colsample_bytree=0.7115485410368727, learning_rate=0.15007156599455426, max_depth=5, min_child_weight=9.563242918780924, n_estimators=153, num_leaves=52, reg_alpha=0.6420316461542878, reg_lambda=0.16827992999009767, subsample=0.6646514856378455; total time= 3.0min\n",
      "[CV] END colsample_bytree=0.9594216754108317, learning_rate=0.131285811931918, max_depth=5, min_child_weight=4.722827665617431, n_estimators=198, num_leaves=44, reg_alpha=0.005061583846218687, reg_lambda=0.3216161028349973, subsample=0.8194935157466344; total time= 3.7min\n",
      "[CV] END colsample_bytree=0.8976682092226249, learning_rate=0.15418798485042587, max_depth=3, min_child_weight=6.425402305548993, n_estimators=121, num_leaves=49, reg_alpha=0.9730105547524456, reg_lambda=0.7861954493335208, subsample=0.9568186220708453; total time= 1.7min\n",
      "[CV] END colsample_bytree=0.8976682092226249, learning_rate=0.15418798485042587, max_depth=3, min_child_weight=6.425402305548993, n_estimators=121, num_leaves=49, reg_alpha=0.9730105547524456, reg_lambda=0.7861954493335208, subsample=0.9568186220708453; total time= 1.8min\n",
      "[CV] END colsample_bytree=0.8524554503989051, learning_rate=0.1689622607083297, max_depth=8, min_child_weight=7.451033620305648, n_estimators=246, num_leaves=23, reg_alpha=0.02431596643145384, reg_lambda=1.2909445918143356, subsample=0.6708442717628196; total time= 3.9min\n",
      "[CV] END colsample_bytree=0.9761834337411657, learning_rate=0.20078571540051748, max_depth=7, min_child_weight=9.83494022266259, n_estimators=332, num_leaves=56, reg_alpha=0.9283185625877254, reg_lambda=0.8563682966346287, subsample=0.9866619276174678; total time= 3.5min\n",
      "[CV] END colsample_bytree=0.9854479908357011, learning_rate=0.18060189109347202, max_depth=9, min_child_weight=4.056970192871819, n_estimators=260, num_leaves=86, reg_alpha=0.1694927466860925, reg_lambda=1.1136025249167003, subsample=0.9744619096643123; total time= 3.9min\n",
      "[CV] END colsample_bytree=0.8784119186699892, learning_rate=0.124012234017873, max_depth=4, min_child_weight=7.150072266991698, n_estimators=250, num_leaves=85, reg_alpha=0.25416364906973876, reg_lambda=0.5905811768378775, subsample=0.7290203056954402; total time= 2.5min"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bytree': np.float64(0.8603553891795411), 'learning_rate': np.float64(0.021282315805420053), 'max_depth': 6, 'min_child_weight': np.float64(10.385527090157503), 'n_estimators': 291, 'num_leaves': 79, 'reg_alpha': np.float64(0.18340450985343382), 'reg_lambda': np.float64(0.6084844859190754), 'subsample': np.float64(0.8099025726528951)}\n",
      "Best ROC-AUC: 0.6162\n",
      "\n",
      "Tuning CatBoost...\n",
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
      "\n",
      "[CV] END colsample_bytree=0.9394679179698697, learning_rate=0.037324266288405766, max_depth=8, min_child_weight=4.594911512197552, n_estimators=269, num_leaves=45, reg_alpha=0.8101133946791808, reg_lambda=1.7341446371602074, subsample=0.9652962210225885; total time= 6.0min\n",
      "[CV] END colsample_bytree=0.8045369595443751, learning_rate=0.11030325893743992, max_depth=7, min_child_weight=2.942739535120422, n_estimators=363, num_leaves=35, reg_alpha=0.050768531039396936, reg_lambda=1.7732342979013198, subsample=0.6110467087494819; total time= 4.2min\n",
      "[CV] END colsample_bytree=0.8315459582030235, learning_rate=0.09769482460361739, max_depth=9, min_child_weight=1.3594227379674209, n_estimators=252, num_leaves=77, reg_alpha=0.5426446347075766, reg_lambda=0.5730825042565688, subsample=0.8363333042276043; total time= 4.3min\n",
      "[CV] END colsample_bytree=0.6122000999756197, learning_rate=0.017469637749842885, max_depth=8, min_child_weight=4.032655146732228, n_estimators=200, num_leaves=27, reg_alpha=0.7699935530986108, reg_lambda=0.43164205499368635, subsample=0.8491561903276001; total time= 6.0min\n",
      "[CV] END colsample_bytree=0.6341389859975072, learning_rate=0.02033634423372154, max_depth=6, min_child_weight=5.113539050566786, n_estimators=243, num_leaves=32, reg_alpha=0.969536867114159, reg_lambda=1.4291902083599042, subsample=0.6164270067071503; total time= 5.9min\n",
      "[CV] END colsample_bytree=0.7595283605779178, learning_rate=0.0967041475161484, max_depth=4, min_child_weight=1.7845638134226596, n_estimators=328, num_leaves=81, reg_alpha=0.8359801205122058, reg_lambda=1.391948412187396, subsample=0.763581177765708; total time= 6.0min\n",
      "[CV] END colsample_bytree=0.6693177280283383, learning_rate=0.04128740853421721, max_depth=4, min_child_weight=3.397873591574032, n_estimators=217, num_leaves=67, reg_alpha=0.18286599710730733, reg_lambda=1.8692279946794195, subsample=0.8553082375373402; total time= 3.2min\n",
      "[CV] END colsample_bytree=0.8066785029706267, learning_rate=0.14142226570003338, max_depth=7, min_child_weight=7.117207462343522, n_estimators=346, num_leaves=86, reg_alpha=0.24773098950115746, reg_lambda=0.7119453573025232, subsample=0.9031384441857476; total time= 2.8min\n",
      "[CV] END colsample_bytree=0.6057573954519023, learning_rate=0.03321452810138325, max_depth=7, min_child_weight=1.9415698826856012, n_estimators=193, num_leaves=81, reg_alpha=0.7036578593800237, reg_lambda=0.9483476581746504, subsample=0.6391336642604005; total time= 8.6min\n",
      "[CV] END colsample_bytree=0.7966463500467329, learning_rate=0.10469435415611314, max_depth=3, min_child_weight=5.646738129396114, n_estimators=122, num_leaves=29, reg_alpha=0.9491457315913859, reg_lambda=1.773360774596095, subsample=0.7043574493366855; total time= 1.7min\n",
      "[CV] END colsample_bytree=0.7966463500467329, learning_rate=0.10469435415611314, max_depth=3, min_child_weight=5.646738129396114, n_estimators=122, num_leaves=29, reg_alpha=0.9491457315913859, reg_lambda=1.773360774596095, subsample=0.7043574493366855; total time= 1.8min\n",
      "[CV] END colsample_bytree=0.8343102325093853, learning_rate=0.19804604828499153, max_depth=6, min_child_weight=4.881699262065219, n_estimators=132, num_leaves=52, reg_alpha=0.811204176736003, reg_lambda=1.6412789514879107, subsample=0.850375868040629; total time= 2.6min\n",
      "[CV] END colsample_bytree=0.9281707375085072, learning_rate=0.14029695437155762, max_depth=5, min_child_weight=2.9579113478929644, n_estimators=111, num_leaves=65, reg_alpha=0.018221825651549728, reg_lambda=0.1888859215118568, subsample=0.8732027093665427; total time= 2.7min\n",
      "[CV] END colsample_bytree=0.6284754593840916, learning_rate=0.07379512605875226, max_depth=4, min_child_weight=7.816136689727897, n_estimators=214, num_leaves=26, reg_alpha=0.11816482762165625, reg_lambda=1.3934743307283013, subsample=0.8515771387119535; total time= 4.0min\n",
      "[CV] END colsample_bytree=0.9509888054108212, learning_rate=0.15701420876077718, max_depth=7, min_child_weight=10.675805515202475, n_estimators=263, num_leaves=29, reg_alpha=0.42347094230811855, reg_lambda=1.1370405674999167, subsample=0.8303698301032338; total time= 3.1min\n",
      "[CV] END colsample_bytree=0.892659102119856, learning_rate=0.03553794588449312, max_depth=3, min_child_weight=8.764129607419967, n_estimators=251, num_leaves=42, reg_alpha=0.9307573256035647, reg_lambda=1.7168255036860236, subsample=0.7715976109500073; total time= 3.3min\n",
      "[CV] END colsample_bytree=0.9003484271165989, learning_rate=0.1609085748169365, max_depth=3, min_child_weight=4.7772888617629485, n_estimators=161, num_leaves=32, reg_alpha=0.8955232284962005, reg_lambda=0.7784033574683262, subsample=0.6043350605921193; total time= 2.1min\n",
      "[CV] END colsample_bytree=0.9621527905677054, learning_rate=0.028257335357226715, max_depth=9, min_child_weight=10.568008851264564, n_estimators=322, num_leaves=71, reg_alpha=0.5734378881232861, reg_lambda=1.2636744243395985, subsample=0.7793782087913279; total time= 9.7min\n",
      "[CV] END colsample_bytree=0.7172843086792258, learning_rate=0.0757329090739832, max_depth=5, min_child_weight=3.1272789502422897, n_estimators=152, num_leaves=42, reg_alpha=0.7812960504712025, reg_lambda=0.22692920403489603, subsample=0.972371642274917; total time= 4.0min\n",
      "[CV] END bagging_temperature=0.3745401188473625, border_count=124, depth=9, iterations=206, l2_leaf_reg=8.796910002727692, learning_rate=0.1293700315892974; total time= 3.9min\n",
      "[CV] END bagging_temperature=0.44583275285359114, border_count=246, depth=5, iterations=187, l2_leaf_reg=4.337086111390218, learning_rate=0.038573363584388155; total time=  40.4s\n",
      "[CV] END bagging_temperature=0.6508884729488529, border_count=84, depth=4, iterations=393, l2_leaf_reg=1.0077876584101433, learning_rate=0.20844231185824352; total time=  23.9s\n",
      "[CV] END bagging_temperature=0.6174815096277165, border_count=89, depth=8, iterations=352, l2_leaf_reg=5.319450186421157, learning_rate=0.06824582803960838; total time= 2.6min\n",
      "[CV] END bagging_temperature=0.6118528947223795, border_count=201, depth=6, iterations=287, l2_leaf_reg=4.663618432936917, learning_rate=0.10121399684340719; total time= 1.3min\n",
      "\n",
      "[CV] END colsample_bytree=0.9394679179698697, learning_rate=0.037324266288405766, max_depth=8, min_child_weight=4.594911512197552, n_estimators=269, num_leaves=45, reg_alpha=0.8101133946791808, reg_lambda=1.7341446371602074, subsample=0.9652962210225885; total time= 6.1min\n",
      "[CV] END colsample_bytree=0.8045369595443751, learning_rate=0.11030325893743992, max_depth=7, min_child_weight=2.942739535120422, n_estimators=363, num_leaves=35, reg_alpha=0.050768531039396936, reg_lambda=1.7732342979013198, subsample=0.6110467087494819; total time= 4.1min\n",
      "[CV] END colsample_bytree=0.8315459582030235, learning_rate=0.09769482460361739, max_depth=9, min_child_weight=1.3594227379674209, n_estimators=252, num_leaves=77, reg_alpha=0.5426446347075766, reg_lambda=0.5730825042565688, subsample=0.8363333042276043; total time= 4.8min\n",
      "[CV] END colsample_bytree=0.6122000999756197, learning_rate=0.017469637749842885, max_depth=8, min_child_weight=4.032655146732228, n_estimators=200, num_leaves=27, reg_alpha=0.7699935530986108, reg_lambda=0.43164205499368635, subsample=0.8491561903276001; total time= 6.2min\n",
      "[CV] END colsample_bytree=0.6341389859975072, learning_rate=0.02033634423372154, max_depth=6, min_child_weight=5.113539050566786, n_estimators=243, num_leaves=32, reg_alpha=0.969536867114159, reg_lambda=1.4291902083599042, subsample=0.6164270067071503; total time= 6.2min\n",
      "[CV] END colsample_bytree=0.7595283605779178, learning_rate=0.0967041475161484, max_depth=4, min_child_weight=1.7845638134226596, n_estimators=328, num_leaves=81, reg_alpha=0.8359801205122058, reg_lambda=1.391948412187396, subsample=0.763581177765708; total time= 5.7min\n",
      "[CV] END colsample_bytree=0.6693177280283383, learning_rate=0.04128740853421721, max_depth=4, min_child_weight=3.397873591574032, n_estimators=217, num_leaves=67, reg_alpha=0.18286599710730733, reg_lambda=1.8692279946794195, subsample=0.8553082375373402; total time= 3.0min\n",
      "[CV] END colsample_bytree=0.8066785029706267, learning_rate=0.14142226570003338, max_depth=7, min_child_weight=7.117207462343522, n_estimators=346, num_leaves=86, reg_alpha=0.24773098950115746, reg_lambda=0.7119453573025232, subsample=0.9031384441857476; total time= 2.8min\n",
      "[CV] END colsample_bytree=0.6057573954519023, learning_rate=0.03321452810138325, max_depth=7, min_child_weight=1.9415698826856012, n_estimators=193, num_leaves=81, reg_alpha=0.7036578593800237, reg_lambda=0.9483476581746504, subsample=0.6391336642604005; total time= 8.8min\n",
      "[CV] END colsample_bytree=0.7966463500467329, learning_rate=0.10469435415611314, max_depth=3, min_child_weight=5.646738129396114, n_estimators=122, num_leaves=29, reg_alpha=0.9491457315913859, reg_lambda=1.773360774596095, subsample=0.7043574493366855; total time= 1.6min\n",
      "[CV] END colsample_bytree=0.6061218161161539, learning_rate=0.1966872616158966, max_depth=3, min_child_weight=6.393774484000625, n_estimators=103, num_leaves=35, reg_alpha=0.07056874740042984, reg_lambda=1.2848385564126312, subsample=0.6106045242166487; total time= 1.2min\n",
      "[CV] END colsample_bytree=0.6061218161161539, learning_rate=0.1966872616158966, max_depth=3, min_child_weight=6.393774484000625, n_estimators=103, num_leaves=35, reg_alpha=0.07056874740042984, reg_lambda=1.2848385564126312, subsample=0.6106045242166487; total time= 1.2min\n",
      "[CV] END colsample_bytree=0.8343102325093853, learning_rate=0.19804604828499153, max_depth=6, min_child_weight=4.881699262065219, n_estimators=132, num_leaves=52, reg_alpha=0.811204176736003, reg_lambda=1.6412789514879107, subsample=0.850375868040629; total time= 2.7min\n",
      "[CV] END colsample_bytree=0.9281707375085072, learning_rate=0.14029695437155762, max_depth=5, min_child_weight=2.9579113478929644, n_estimators=111, num_leaves=65, reg_alpha=0.018221825651549728, reg_lambda=0.1888859215118568, subsample=0.8732027093665427; total time= 2.8min\n",
      "[CV] END colsample_bytree=0.6284754593840916, learning_rate=0.07379512605875226, max_depth=4, min_child_weight=7.816136689727897, n_estimators=214, num_leaves=26, reg_alpha=0.11816482762165625, reg_lambda=1.3934743307283013, subsample=0.8515771387119535; total time= 3.6min\n",
      "[CV] END colsample_bytree=0.9509888054108212, learning_rate=0.15701420876077718, max_depth=7, min_child_weight=10.675805515202475, n_estimators=263, num_leaves=29, reg_alpha=0.42347094230811855, reg_lambda=1.1370405674999167, subsample=0.8303698301032338; total time= 3.2min\n",
      "[CV] END colsample_bytree=0.892659102119856, learning_rate=0.03553794588449312, max_depth=3, min_child_weight=8.764129607419967, n_estimators=251, num_leaves=42, reg_alpha=0.9307573256035647, reg_lambda=1.7168255036860236, subsample=0.7715976109500073; total time= 3.2min\n",
      "[CV] END colsample_bytree=0.9003484271165989, learning_rate=0.1609085748169365, max_depth=3, min_child_weight=4.7772888617629485, n_estimators=161, num_leaves=32, reg_alpha=0.8955232284962005, reg_lambda=0.7784033574683262, subsample=0.6043350605921193; total time= 2.0min\n",
      "[CV] END colsample_bytree=0.9621527905677054, learning_rate=0.028257335357226715, max_depth=9, min_child_weight=10.568008851264564, n_estimators=322, num_leaves=71, reg_alpha=0.5734378881232861, reg_lambda=1.2636744243395985, subsample=0.7793782087913279; total time= 9.5min\n",
      "[CV] END colsample_bytree=0.7172843086792258, learning_rate=0.0757329090739832, max_depth=5, min_child_weight=3.1272789502422897, n_estimators=152, num_leaves=42, reg_alpha=0.7812960504712025, reg_lambda=0.22692920403489603, subsample=0.972371642274917; total time= 3.8min\n",
      "[CV] END bagging_temperature=0.3745401188473625, border_count=124, depth=9, iterations=206, l2_leaf_reg=8.796910002727692, learning_rate=0.1293700315892974; total time= 4.0min\n",
      "[CV] END bagging_temperature=0.44583275285359114, border_count=246, depth=5, iterations=187, l2_leaf_reg=4.337086111390218, learning_rate=0.038573363584388155; total time=  38.0s\n",
      "[CV] END bagging_temperature=0.6508884729488529, border_count=84, depth=4, iterations=393, l2_leaf_reg=1.0077876584101433, learning_rate=0.20844231185824352; total time=  26.8s\n",
      "[CV] END bagging_temperature=0.6174815096277165, border_count=89, depth=8, iterations=352, l2_leaf_reg=5.319450186421157, learning_rate=0.06824582803960838; total time= 2.6min\n",
      "[CV] END bagging_temperature=0.6118528947223795, border_count=201, depth=6, iterations=287, l2_leaf_reg=4.663618432936917, learning_rate=0.10121399684340719; total time= 1.3min\n",
      "\n",
      "[CV] END colsample_bytree=0.9394679179698697, learning_rate=0.037324266288405766, max_depth=8, min_child_weight=4.594911512197552, n_estimators=269, num_leaves=45, reg_alpha=0.8101133946791808, reg_lambda=1.7341446371602074, subsample=0.9652962210225885; total time= 6.1min\n",
      "[CV] END colsample_bytree=0.8045369595443751, learning_rate=0.11030325893743992, max_depth=7, min_child_weight=2.942739535120422, n_estimators=363, num_leaves=35, reg_alpha=0.050768531039396936, reg_lambda=1.7732342979013198, subsample=0.6110467087494819; total time= 4.2min\n",
      "[CV] END colsample_bytree=0.8315459582030235, learning_rate=0.09769482460361739, max_depth=9, min_child_weight=1.3594227379674209, n_estimators=252, num_leaves=77, reg_alpha=0.5426446347075766, reg_lambda=0.5730825042565688, subsample=0.8363333042276043; total time= 4.6min\n",
      "[CV] END colsample_bytree=0.6122000999756197, learning_rate=0.017469637749842885, max_depth=8, min_child_weight=4.032655146732228, n_estimators=200, num_leaves=27, reg_alpha=0.7699935530986108, reg_lambda=0.43164205499368635, subsample=0.8491561903276001; total time= 6.1min\n",
      "[CV] END colsample_bytree=0.6341389859975072, learning_rate=0.02033634423372154, max_depth=6, min_child_weight=5.113539050566786, n_estimators=243, num_leaves=32, reg_alpha=0.969536867114159, reg_lambda=1.4291902083599042, subsample=0.6164270067071503; total time= 6.9min\n",
      "[CV] END colsample_bytree=0.7595283605779178, learning_rate=0.0967041475161484, max_depth=4, min_child_weight=1.7845638134226596, n_estimators=328, num_leaves=81, reg_alpha=0.8359801205122058, reg_lambda=1.391948412187396, subsample=0.763581177765708; total time= 5.1min\n",
      "[CV] END colsample_bytree=0.6693177280283383, learning_rate=0.04128740853421721, max_depth=4, min_child_weight=3.397873591574032, n_estimators=217, num_leaves=67, reg_alpha=0.18286599710730733, reg_lambda=1.8692279946794195, subsample=0.8553082375373402; total time= 3.3min\n",
      "[CV] END colsample_bytree=0.8066785029706267, learning_rate=0.14142226570003338, max_depth=7, min_child_weight=7.117207462343522, n_estimators=346, num_leaves=86, reg_alpha=0.24773098950115746, reg_lambda=0.7119453573025232, subsample=0.9031384441857476; total time= 2.9min\n",
      "[CV] END colsample_bytree=0.6057573954519023, learning_rate=0.03321452810138325, max_depth=7, min_child_weight=1.9415698826856012, n_estimators=193, num_leaves=81, reg_alpha=0.7036578593800237, reg_lambda=0.9483476581746504, subsample=0.6391336642604005; total time= 9.6min\n",
      "[CV] END colsample_bytree=0.6061218161161539, learning_rate=0.1966872616158966, max_depth=3, min_child_weight=6.393774484000625, n_estimators=103, num_leaves=35, reg_alpha=0.07056874740042984, reg_lambda=1.2848385564126312, subsample=0.6106045242166487; total time= 1.4min\n",
      "[CV] END colsample_bytree=0.8343102325093853, learning_rate=0.19804604828499153, max_depth=6, min_child_weight=4.881699262065219, n_estimators=132, num_leaves=52, reg_alpha=0.811204176736003, reg_lambda=1.6412789514879107, subsample=0.850375868040629; total time= 2.6min\n",
      "[CV] END colsample_bytree=0.9281707375085072, learning_rate=0.14029695437155762, max_depth=5, min_child_weight=2.9579113478929644, n_estimators=111, num_leaves=65, reg_alpha=0.018221825651549728, reg_lambda=0.1888859215118568, subsample=0.8732027093665427; total time= 2.7min\n",
      "[CV] END colsample_bytree=0.6284754593840916, learning_rate=0.07379512605875226, max_depth=4, min_child_weight=7.816136689727897, n_estimators=214, num_leaves=26, reg_alpha=0.11816482762165625, reg_lambda=1.3934743307283013, subsample=0.8515771387119535; total time= 4.0min\n",
      "[CV] END colsample_bytree=0.9509888054108212, learning_rate=0.15701420876077718, max_depth=7, min_child_weight=10.675805515202475, n_estimators=263, num_leaves=29, reg_alpha=0.42347094230811855, reg_lambda=1.1370405674999167, subsample=0.8303698301032338; total time= 3.2min\n",
      "[CV] END colsample_bytree=0.892659102119856, learning_rate=0.03553794588449312, max_depth=3, min_child_weight=8.764129607419967, n_estimators=251, num_leaves=42, reg_alpha=0.9307573256035647, reg_lambda=1.7168255036860236, subsample=0.7715976109500073; total time= 3.2min\n",
      "[CV] END colsample_bytree=0.9003484271165989, learning_rate=0.1609085748169365, max_depth=3, min_child_weight=4.7772888617629485, n_estimators=161, num_leaves=32, reg_alpha=0.8955232284962005, reg_lambda=0.7784033574683262, subsample=0.6043350605921193; total time= 2.0min\n",
      "[CV] END colsample_bytree=0.9621527905677054, learning_rate=0.028257335357226715, max_depth=9, min_child_weight=10.568008851264564, n_estimators=322, num_leaves=71, reg_alpha=0.5734378881232861, reg_lambda=1.2636744243395985, subsample=0.7793782087913279; total time= 9.3min\n",
      "[CV] END colsample_bytree=0.7172843086792258, learning_rate=0.0757329090739832, max_depth=5, min_child_weight=3.1272789502422897, n_estimators=152, num_leaves=42, reg_alpha=0.7812960504712025, reg_lambda=0.22692920403489603, subsample=0.972371642274917; total time= 4.1min\n",
      "[CV] END bagging_temperature=0.3745401188473625, border_count=124, depth=9, iterations=206, l2_leaf_reg=8.796910002727692, learning_rate=0.1293700315892974; total time= 4.0min\n",
      "[CV] END bagging_temperature=0.44583275285359114, border_count=246, depth=5, iterations=187, l2_leaf_reg=4.337086111390218, learning_rate=0.038573363584388155; total time=  40.4s\n",
      "[CV] END bagging_temperature=0.6508884729488529, border_count=84, depth=4, iterations=393, l2_leaf_reg=1.0077876584101433, learning_rate=0.20844231185824352; total time=  28.3s\n",
      "[CV] END bagging_temperature=0.6174815096277165, border_count=89, depth=8, iterations=352, l2_leaf_reg=5.319450186421157, learning_rate=0.06824582803960838; total time= 2.5min\n",
      "[CV] END bagging_temperature=0.6118528947223795, border_count=201, depth=6, iterations=287, l2_leaf_reg=4.663618432936917, learning_rate=0.10121399684340719; total time= 1.3min\n",
      "\n",
      "[CV] END colsample_bytree=0.9394679179698697, learning_rate=0.037324266288405766, max_depth=8, min_child_weight=4.594911512197552, n_estimators=269, num_leaves=45, reg_alpha=0.8101133946791808, reg_lambda=1.7341446371602074, subsample=0.9652962210225885; total time= 6.0min\n",
      "[CV] END colsample_bytree=0.8045369595443751, learning_rate=0.11030325893743992, max_depth=7, min_child_weight=2.942739535120422, n_estimators=363, num_leaves=35, reg_alpha=0.050768531039396936, reg_lambda=1.7732342979013198, subsample=0.6110467087494819; total time= 4.1min\n",
      "[CV] END colsample_bytree=0.8315459582030235, learning_rate=0.09769482460361739, max_depth=9, min_child_weight=1.3594227379674209, n_estimators=252, num_leaves=77, reg_alpha=0.5426446347075766, reg_lambda=0.5730825042565688, subsample=0.8363333042276043; total time= 4.6min\n",
      "[CV] END colsample_bytree=0.6122000999756197, learning_rate=0.017469637749842885, max_depth=8, min_child_weight=4.032655146732228, n_estimators=200, num_leaves=27, reg_alpha=0.7699935530986108, reg_lambda=0.43164205499368635, subsample=0.8491561903276001; total time= 5.8min\n",
      "[CV] END colsample_bytree=0.6341389859975072, learning_rate=0.02033634423372154, max_depth=6, min_child_weight=5.113539050566786, n_estimators=243, num_leaves=32, reg_alpha=0.969536867114159, reg_lambda=1.4291902083599042, subsample=0.6164270067071503; total time= 6.1min\n",
      "[CV] END colsample_bytree=0.7595283605779178, learning_rate=0.0967041475161484, max_depth=4, min_child_weight=1.7845638134226596, n_estimators=328, num_leaves=81, reg_alpha=0.8359801205122058, reg_lambda=1.391948412187396, subsample=0.763581177765708; total time= 5.8min\n",
      "[CV] END colsample_bytree=0.6693177280283383, learning_rate=0.04128740853421721, max_depth=4, min_child_weight=3.397873591574032, n_estimators=217, num_leaves=67, reg_alpha=0.18286599710730733, reg_lambda=1.8692279946794195, subsample=0.8553082375373402; total time= 3.3min\n",
      "[CV] END colsample_bytree=0.8066785029706267, learning_rate=0.14142226570003338, max_depth=7, min_child_weight=7.117207462343522, n_estimators=346, num_leaves=86, reg_alpha=0.24773098950115746, reg_lambda=0.7119453573025232, subsample=0.9031384441857476; total time= 2.8min\n",
      "[CV] END colsample_bytree=0.6057573954519023, learning_rate=0.03321452810138325, max_depth=7, min_child_weight=1.9415698826856012, n_estimators=193, num_leaves=81, reg_alpha=0.7036578593800237, reg_lambda=0.9483476581746504, subsample=0.6391336642604005; total time= 8.6min\n",
      "[CV] END colsample_bytree=0.7966463500467329, learning_rate=0.10469435415611314, max_depth=3, min_child_weight=5.646738129396114, n_estimators=122, num_leaves=29, reg_alpha=0.9491457315913859, reg_lambda=1.773360774596095, subsample=0.7043574493366855; total time= 1.7min\n",
      "[CV] END colsample_bytree=0.6061218161161539, learning_rate=0.1966872616158966, max_depth=3, min_child_weight=6.393774484000625, n_estimators=103, num_leaves=35, reg_alpha=0.07056874740042984, reg_lambda=1.2848385564126312, subsample=0.6106045242166487; total time= 1.5min\n",
      "[CV] END colsample_bytree=0.8343102325093853, learning_rate=0.19804604828499153, max_depth=6, min_child_weight=4.881699262065219, n_estimators=132, num_leaves=52, reg_alpha=0.811204176736003, reg_lambda=1.6412789514879107, subsample=0.850375868040629; total time= 2.6min\n",
      "[CV] END colsample_bytree=0.9281707375085072, learning_rate=0.14029695437155762, max_depth=5, min_child_weight=2.9579113478929644, n_estimators=111, num_leaves=65, reg_alpha=0.018221825651549728, reg_lambda=0.1888859215118568, subsample=0.8732027093665427; total time= 2.7min\n",
      "[CV] END colsample_bytree=0.6284754593840916, learning_rate=0.07379512605875226, max_depth=4, min_child_weight=7.816136689727897, n_estimators=214, num_leaves=26, reg_alpha=0.11816482762165625, reg_lambda=1.3934743307283013, subsample=0.8515771387119535; total time= 3.9min\n",
      "[CV] END colsample_bytree=0.9509888054108212, learning_rate=0.15701420876077718, max_depth=7, min_child_weight=10.675805515202475, n_estimators=263, num_leaves=29, reg_alpha=0.42347094230811855, reg_lambda=1.1370405674999167, subsample=0.8303698301032338; total time= 3.1min\n",
      "[CV] END colsample_bytree=0.892659102119856, learning_rate=0.03553794588449312, max_depth=3, min_child_weight=8.764129607419967, n_estimators=251, num_leaves=42, reg_alpha=0.9307573256035647, reg_lambda=1.7168255036860236, subsample=0.7715976109500073; total time= 3.5min\n",
      "[CV] END colsample_bytree=0.9003484271165989, learning_rate=0.1609085748169365, max_depth=3, min_child_weight=4.7772888617629485, n_estimators=161, num_leaves=32, reg_alpha=0.8955232284962005, reg_lambda=0.7784033574683262, subsample=0.6043350605921193; total time= 2.1min\n",
      "[CV] END colsample_bytree=0.9621527905677054, learning_rate=0.028257335357226715, max_depth=9, min_child_weight=10.568008851264564, n_estimators=322, num_leaves=71, reg_alpha=0.5734378881232861, reg_lambda=1.2636744243395985, subsample=0.7793782087913279; total time= 9.3min\n",
      "[CV] END colsample_bytree=0.7172843086792258, learning_rate=0.0757329090739832, max_depth=5, min_child_weight=3.1272789502422897, n_estimators=152, num_leaves=42, reg_alpha=0.7812960504712025, reg_lambda=0.22692920403489603, subsample=0.972371642274917; total time= 4.2min\n",
      "[CV] END bagging_temperature=0.3745401188473625, border_count=124, depth=9, iterations=206, l2_leaf_reg=8.796910002727692, learning_rate=0.1293700315892974; total time= 3.9min\n",
      "[CV] END bagging_temperature=0.44583275285359114, border_count=246, depth=5, iterations=187, l2_leaf_reg=4.337086111390218, learning_rate=0.038573363584388155; total time=  42.3s\n",
      "[CV] END bagging_temperature=0.6508884729488529, border_count=84, depth=4, iterations=393, l2_leaf_reg=1.0077876584101433, learning_rate=0.20844231185824352; total time=  24.1s\n",
      "[CV] END bagging_temperature=0.6174815096277165, border_count=89, depth=8, iterations=352, l2_leaf_reg=5.319450186421157, learning_rate=0.06824582803960838; total time= 2.6min\n",
      "[CV] END bagging_temperature=0.6118528947223795, border_count=201, depth=6, iterations=287, l2_leaf_reg=4.663618432936917, learning_rate=0.10121399684340719; total time= 1.3min\n",
      "[CV] END bagging_temperature=0.7851759613930136, border_count=82, depth=6, iterations=154, l2_leaf_reg=10.832308858067883, learning_rate=0.10335257864959599; total time=  19.3s\n",
      "[CV] END bagging_temperature=0.8599404067363206, border_count=166, depth=7, iterations=266, l2_leaf_reg=1.1326496115986653, learning_rate=0.19844035113697056; total time= 1.9min\n",
      "[CV] END bagging_temperature=0.7851759613930136, border_count=82, depth=6, iterations=154, l2_leaf_reg=10.832308858067883, learning_rate=0.10335257864959599; total time=  21.5s\n",
      "[CV] END bagging_temperature=0.8599404067363206, border_count=166, depth=7, iterations=266, l2_leaf_reg=1.1326496115986653, learning_rate=0.19844035113697056; total time= 1.9min\n",
      "[CV] END bagging_temperature=0.7851759613930136, border_count=82, depth=6, iterations=154, l2_leaf_reg=10.832308858067883, learning_rate=0.10335257864959599; total time=  20.5s\n",
      "[CV] END bagging_temperature=0.8599404067363206, border_count=166, depth=7, iterations=266, l2_leaf_reg=1.1326496115986653, learning_rate=0.19844035113697056; total time= 1.9min\n",
      "[CV] END bagging_temperature=0.5632882178455393, border_count=40, depth=4, iterations=152, l2_leaf_reg=3.3089382562214897, learning_rate=0.05820509320520235; total time=   7.9s\n",
      "[CV] END bagging_temperature=0.6832635188254582, border_count=203, depth=7, iterations=363, l2_leaf_reg=1.343885211152184, learning_rate=0.19186408041575642; total time= 3.1min\n",
      "[CV] END bagging_temperature=0.2587799816000169, border_count=135, depth=6, iterations=101, l2_leaf_reg=5.2515587449124475, learning_rate=0.05158833257363777; total time=  22.7s\n",
      "[CV] END bagging_temperature=0.5677003278199915, border_count=252, depth=9, iterations=317, l2_leaf_reg=5.497541333697656, learning_rate=0.08903004720036288; total time=12.8min\n",
      "[CV] END bagging_temperature=0.7851759613930136, border_count=82, depth=6, iterations=154, l2_leaf_reg=10.832308858067883, learning_rate=0.10335257864959599; total time=  21.9s\n",
      "[CV] END bagging_temperature=0.8599404067363206, border_count=166, depth=7, iterations=266, l2_leaf_reg=1.1326496115986653, learning_rate=0.19844035113697056; total time= 1.9min\n",
      "[CV] END bagging_temperature=0.6832635188254582, border_count=203, depth=7, iterations=363, l2_leaf_reg=1.343885211152184, learning_rate=0.19186408041575642; total time= 3.1min\n",
      "[CV] END bagging_temperature=0.2587799816000169, border_count=135, depth=6, iterations=101, l2_leaf_reg=5.2515587449124475, learning_rate=0.05158833257363777; total time=  22.3s\n",
      "[CV] END bagging_temperature=0.5677003278199915, border_count=252, depth=9, iterations=317, l2_leaf_reg=5.497541333697656, learning_rate=0.08903004720036288; total time=12.9min\n",
      "[CV] END bagging_temperature=0.9266588657937942, border_count=126, depth=9, iterations=314, l2_leaf_reg=6.208342600258237, learning_rate=0.20223440486986985; total time= 6.1min\n",
      "[CV] END bagging_temperature=0.5632882178455393, border_count=40, depth=4, iterations=152, l2_leaf_reg=3.3089382562214897, learning_rate=0.05820509320520235; total time=  10.0s\n",
      "[CV] END bagging_temperature=0.6832635188254582, border_count=203, depth=7, iterations=363, l2_leaf_reg=1.343885211152184, learning_rate=0.19186408041575642; total time= 3.1min\n",
      "[CV] END bagging_temperature=0.2587799816000169, border_count=135, depth=6, iterations=101, l2_leaf_reg=5.2515587449124475, learning_rate=0.05158833257363777; total time=  25.2s\n",
      "[CV] END bagging_temperature=0.5677003278199915, border_count=252, depth=9, iterations=317, l2_leaf_reg=5.497541333697656, learning_rate=0.08903004720036288; total time=12.8min\n",
      "[CV] END bagging_temperature=0.9266588657937942, border_count=126, depth=9, iterations=314, l2_leaf_reg=6.208342600258237, learning_rate=0.20223440486986985; total time= 6.0min\n",
      "[CV] END bagging_temperature=0.8445338486781514, border_count=113, depth=9, iterations=152, l2_leaf_reg=6.867511656638483, learning_rate=0.2030510614528276; total time= 2.8min\n",
      "[CV] END bagging_temperature=0.8445338486781514, border_count=113, depth=9, iterations=152, l2_leaf_reg=6.867511656638483, learning_rate=0.2030510614528276; total time= 2.7min\n",
      "[CV] END bagging_temperature=0.6070342476866847, border_count=72, depth=7, iterations=114, l2_leaf_reg=2.6526693906300247, learning_rate=0.013127281348238786; total time=  26.9s\n",
      "[CV] END bagging_temperature=0.4234014807063696, border_count=160, depth=6, iterations=235, l2_leaf_reg=1.055221171236024, learning_rate=0.17309228569096685; total time=  55.5s\n",
      "[CV] END bagging_temperature=0.7068573438476171, border_count=194, depth=5, iterations=388, l2_leaf_reg=7.059599747810114, learning_rate=0.19526017570266982; total time= 1.1min\n",
      "[CV] END bagging_temperature=0.6510770255019445, border_count=59, depth=9, iterations=300, l2_leaf_reg=7.232981268275579, learning_rate=0.07617960497052984; total time= 2.8min\n",
      "[CV] END bagging_temperature=0.06355835028602363, border_count=182, depth=8, iterations=315, l2_leaf_reg=7.659223566174966, learning_rate=0.12825955754154544; total time= 4.5min\n",
      "[CV] END bagging_temperature=0.27472179299006416, border_count=66, depth=3, iterations=326, l2_leaf_reg=2.195942459383017, learning_rate=0.15264895744459903; total time=  13.0s\n",
      "[CV] END bagging_temperature=0.7607850486168974, border_count=249, depth=9, iterations=354, l2_leaf_reg=3.5606832276132394, learning_rate=0.01808671790768627; total time=12.8min\n",
      "[CV] END bagging_temperature=0.5632882178455393, border_count=40, depth=4, iterations=152, l2_leaf_reg=3.3089382562214897, learning_rate=0.05820509320520235; total time=   8.4s\n",
      "[CV] END bagging_temperature=0.5632882178455393, border_count=40, depth=4, iterations=152, l2_leaf_reg=3.3089382562214897, learning_rate=0.05820509320520235; total time=   9.2s\n",
      "[CV] END bagging_temperature=0.6832635188254582, border_count=203, depth=7, iterations=363, l2_leaf_reg=1.343885211152184, learning_rate=0.19186408041575642; total time= 3.2min\n",
      "[CV] END bagging_temperature=0.2587799816000169, border_count=135, depth=6, iterations=101, l2_leaf_reg=5.2515587449124475, learning_rate=0.05158833257363777; total time=  25.2s\n",
      "[CV] END bagging_temperature=0.5677003278199915, border_count=252, depth=9, iterations=317, l2_leaf_reg=5.497541333697656, learning_rate=0.08903004720036288; total time=12.9min\n",
      "[CV] END bagging_temperature=0.9266588657937942, border_count=126, depth=9, iterations=314, l2_leaf_reg=6.208342600258237, learning_rate=0.20223440486986985; total time= 6.1min\n",
      "[CV] END bagging_temperature=0.8445338486781514, border_count=113, depth=9, iterations=152, l2_leaf_reg=6.867511656638483, learning_rate=0.2030510614528276; total time= 2.7min\n",
      "[CV] END bagging_temperature=0.6070342476866847, border_count=72, depth=7, iterations=114, l2_leaf_reg=2.6526693906300247, learning_rate=0.013127281348238786; total time=  26.4s\n",
      "[CV] END bagging_temperature=0.4234014807063696, border_count=160, depth=6, iterations=235, l2_leaf_reg=1.055221171236024, learning_rate=0.17309228569096685; total time=  56.7s\n",
      "[CV] END bagging_temperature=0.7068573438476171, border_count=194, depth=5, iterations=388, l2_leaf_reg=7.059599747810114, learning_rate=0.19526017570266982; total time= 1.2min\n",
      "[CV] END bagging_temperature=0.6510770255019445, border_count=59, depth=9, iterations=300, l2_leaf_reg=7.232981268275579, learning_rate=0.07617960497052984; total time= 2.8min\n",
      "[CV] END bagging_temperature=0.06355835028602363, border_count=182, depth=8, iterations=315, l2_leaf_reg=7.659223566174966, learning_rate=0.12825955754154544; total time= 4.5min\n",
      "[CV] END bagging_temperature=0.27472179299006416, border_count=66, depth=3, iterations=326, l2_leaf_reg=2.195942459383017, learning_rate=0.15264895744459903; total time=  12.2s\n",
      "[CV] END bagging_temperature=0.7607850486168974, border_count=249, depth=9, iterations=354, l2_leaf_reg=3.5606832276132394, learning_rate=0.01808671790768627; total time=12.8min\n",
      "[CV] END bagging_temperature=0.7106628896857874, border_count=121, depth=4, iterations=278, l2_leaf_reg=1.3142918568673425, learning_rate=0.1372820822527561; total time=  21.6s\n",
      "[CV] END bagging_temperature=0.3143559810763267, border_count=127, depth=6, iterations=321, l2_leaf_reg=2.393314544058757, learning_rate=0.13088347585556345; total time= 1.0min\n",
      "[CV] END bagging_temperature=0.5398410913016731, border_count=60, depth=6, iterations=112, l2_leaf_reg=1.76979909828793, learning_rate=0.0679502905827536; total time=  13.0s\n",
      "[CV] END bagging_temperature=0.16122128725400442, border_count=97, depth=4, iterations=144, l2_leaf_reg=3.95633685837714, learning_rate=0.031098851966054122; total time=   9.4s\n",
      "[CV] END bagging_temperature=0.45653457048291024, border_count=139, depth=6, iterations=385, l2_leaf_reg=9.832802589188683, learning_rate=0.07486900420105479; total time= 1.3min\n",
      "[CV] END bagging_temperature=0.12208795470067335, border_count=248, depth=9, iterations=289, l2_leaf_reg=2.1005192452767676, learning_rate=0.05558703250838834; total time=10.4min\n",
      "[CV] END bagging_temperature=0.4271077886262563, border_count=147, depth=7, iterations=332, l2_leaf_reg=4.04781258158029, learning_rate=0.04293117062858835; total time= 1.9min\n",
      "[CV] END bagging_temperature=0.534089419375442, border_count=93, depth=7, iterations=324, l2_leaf_reg=2.1986536733368283, learning_rate=0.07752303428072559; total time= 1.3min\n",
      "[CV] END bagging_temperature=0.9429097039125192, border_count=149, depth=3, iterations=279, l2_leaf_reg=4.63629602379294, learning_rate=0.20435641654419215; total time=  15.6s\n",
      "[CV] END bagging_temperature=0.9624472949421112, border_count=70, depth=4, iterations=212, l2_leaf_reg=2.4808692995339987, learning_rate=0.20954809700978838; total time=  11.6s\n",
      "[CV] END bagging_temperature=0.266781014275285, border_count=33, depth=4, iterations=319, l2_leaf_reg=1.5147875124998935, learning_rate=0.06572929284732229; total time=  12.2s\n",
      "[CV] END bagging_temperature=0.9082658859666537, border_count=178, depth=8, iterations=229, l2_leaf_reg=6.309345833171363, learning_rate=0.09955663291461833; total time= 2.9min\n",
      "[CV] END bagging_temperature=0.552893089071328, border_count=99, depth=9, iterations=302, l2_leaf_reg=4.696544560614044, learning_rate=0.05843198765548518; total time= 4.4min\n",
      "Best params: {'bagging_temperature': np.float64(0.5769038846263591), 'border_count': 223, 'depth': 3, 'iterations': 246, 'l2_leaf_reg': np.float64(6.720041992091831), 'learning_rate': np.float64(0.16371080286126183)}\n",
      "Best ROC-AUC: 0.6236\n",
      "\n",
      "Tuning Random Forest...\n",
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
      "[CV] END bagging_temperature=0.6070342476866847, border_count=72, depth=7, iterations=114, l2_leaf_reg=2.6526693906300247, learning_rate=0.013127281348238786; total time=  25.3s\n",
      "[CV] END bagging_temperature=0.4234014807063696, border_count=160, depth=6, iterations=235, l2_leaf_reg=1.055221171236024, learning_rate=0.17309228569096685; total time=  52.5s\n",
      "[CV] END bagging_temperature=0.7068573438476171, border_count=194, depth=5, iterations=388, l2_leaf_reg=7.059599747810114, learning_rate=0.19526017570266982; total time= 1.1min\n",
      "[CV] END bagging_temperature=0.6510770255019445, border_count=59, depth=9, iterations=300, l2_leaf_reg=7.232981268275579, learning_rate=0.07617960497052984; total time= 2.8min\n",
      "[CV] END bagging_temperature=0.06355835028602363, border_count=182, depth=8, iterations=315, l2_leaf_reg=7.659223566174966, learning_rate=0.12825955754154544; total time= 4.5min\n",
      "[CV] END bagging_temperature=0.27472179299006416, border_count=66, depth=3, iterations=326, l2_leaf_reg=2.195942459383017, learning_rate=0.15264895744459903; total time=  13.1s\n",
      "[CV] END bagging_temperature=0.7607850486168974, border_count=249, depth=9, iterations=354, l2_leaf_reg=3.5606832276132394, learning_rate=0.01808671790768627; total time=12.9min\n",
      "[CV] END bagging_temperature=0.7106628896857874, border_count=121, depth=4, iterations=278, l2_leaf_reg=1.3142918568673425, learning_rate=0.1372820822527561; total time=  21.4s\n",
      "[CV] END bagging_temperature=0.3143559810763267, border_count=127, depth=6, iterations=321, l2_leaf_reg=2.393314544058757, learning_rate=0.13088347585556345; total time=  57.4s\n",
      "[CV] END bagging_temperature=0.5398410913016731, border_count=60, depth=6, iterations=112, l2_leaf_reg=1.76979909828793, learning_rate=0.0679502905827536; total time=  12.3s\n",
      "[CV] END bagging_temperature=0.16122128725400442, border_count=97, depth=4, iterations=144, l2_leaf_reg=3.95633685837714, learning_rate=0.031098851966054122; total time=  10.6s\n",
      "[CV] END bagging_temperature=0.16122128725400442, border_count=97, depth=4, iterations=144, l2_leaf_reg=3.95633685837714, learning_rate=0.031098851966054122; total time=  11.1s\n",
      "[CV] END bagging_temperature=0.45653457048291024, border_count=139, depth=6, iterations=385, l2_leaf_reg=9.832802589188683, learning_rate=0.07486900420105479; total time= 1.3min\n",
      "[CV] END bagging_temperature=0.12208795470067335, border_count=248, depth=9, iterations=289, l2_leaf_reg=2.1005192452767676, learning_rate=0.05558703250838834; total time=10.4min\n",
      "[CV] END bagging_temperature=0.4271077886262563, border_count=147, depth=7, iterations=332, l2_leaf_reg=4.04781258158029, learning_rate=0.04293117062858835; total time= 1.9min\n",
      "[CV] END bagging_temperature=0.534089419375442, border_count=93, depth=7, iterations=324, l2_leaf_reg=2.1986536733368283, learning_rate=0.07752303428072559; total time= 1.3min\n",
      "[CV] END bagging_temperature=0.9429097039125192, border_count=149, depth=3, iterations=279, l2_leaf_reg=4.63629602379294, learning_rate=0.20435641654419215; total time=  16.0s\n",
      "[CV] END bagging_temperature=0.9624472949421112, border_count=70, depth=4, iterations=212, l2_leaf_reg=2.4808692995339987, learning_rate=0.20954809700978838; total time=  11.6s\n",
      "[CV] END bagging_temperature=0.266781014275285, border_count=33, depth=4, iterations=319, l2_leaf_reg=1.5147875124998935, learning_rate=0.06572929284732229; total time=  12.9s\n",
      "[CV] END bagging_temperature=0.9082658859666537, border_count=178, depth=8, iterations=229, l2_leaf_reg=6.309345833171363, learning_rate=0.09955663291461833; total time= 2.9min\n",
      "[CV] END bagging_temperature=0.552893089071328, border_count=99, depth=9, iterations=302, l2_leaf_reg=4.696544560614044, learning_rate=0.05843198765548518; total time= 4.4min\n",
      "[CV] END bagging_temperature=0.8031397563798959, border_count=100, depth=6, iterations=197, l2_leaf_reg=7.335297107608947, learning_rate=0.11715493681495169; total time=  32.7s\n",
      "[CV] END bagging_temperature=0.0902897700544083, border_count=128, depth=3, iterations=223, l2_leaf_reg=6.0819877674071865, learning_rate=0.14916256135817638; total time=  13.2s\n",
      "[CV] END bagging_temperature=0.8583588048137198, border_count=218, depth=6, iterations=246, l2_leaf_reg=4.4866598729172935, learning_rate=0.029235310218284155; total time= 1.3min\n",
      "[CV] END bagging_temperature=0.940523264489604, border_count=199, depth=9, iterations=228, l2_leaf_reg=7.7569011703928075, learning_rate=0.15704322384815445; total time= 7.4min\n",
      "[CV] END bagging_temperature=0.20907162073771368, border_count=190, depth=8, iterations=397, l2_leaf_reg=3.579416277151556, learning_rate=0.14199680920683583; total time= 6.2min\n",
      "[CV] END bagging_temperature=0.8172222002012158, border_count=91, depth=3, iterations=101, l2_leaf_reg=10.962536997579242, learning_rate=0.20308387025775876; total time=   7.4s\n",
      "[CV] END bagging_temperature=0.5582934536070976, border_count=191, depth=5, iterations=108, l2_leaf_reg=3.7887135259218185, learning_rate=0.15007156599455426; total time=  19.0s\n",
      "[CV] END bagging_temperature=0.8466611422383059, border_count=179, depth=8, iterations=219, l2_leaf_reg=9.877700987609598, learning_rate=0.18018568975350258; total time= 2.8min\n",
      "[CV] END bagging_temperature=0.9356349942209475, border_count=195, depth=8, iterations=203, l2_leaf_reg=7.0642905965958995, learning_rate=0.01183941032332593; total time= 2.8min\n",
      "[CV] END bagging_temperature=0.1014715428660321, border_count=130, depth=3, iterations=293, l2_leaf_reg=7.918951976926932, learning_rate=0.14039225190052013; total time=  18.1s\n",
      "[CV] END bagging_temperature=0.22426930946055978, border_count=192, depth=6, iterations=388, l2_leaf_reg=5.938937151834346, learning_rate=0.04576454184426577; total time= 1.6min\n",
      "[CV] END bagging_temperature=0.3664687845828599, border_count=167, depth=9, iterations=294, l2_leaf_reg=7.576128923003433, learning_rate=0.12366172066709433; total time= 6.9min\n",
      "[CV] END bagging_temperature=0.09367476782809248, border_count=146, depth=8, iterations=121, l2_leaf_reg=3.4398964337908358, learning_rate=0.20460211095048914; total time= 1.3min\n",
      "[CV] END bagging_temperature=0.3930977246667604, border_count=213, depth=5, iterations=126, l2_leaf_reg=8.948113035416483, learning_rate=0.11052741862103842; total time=  24.8s\n",
      "[CV] END bagging_temperature=0.5769038846263591, border_count=223, depth=3, iterations=246, l2_leaf_reg=6.720041992091831, learning_rate=0.16371080286126183; total time=  18.6s\n",
      "[CV] END bagging_temperature=0.04360377175443375, border_count=203, depth=6, iterations=257, l2_leaf_reg=10.539285770025874, learning_rate=0.19297287804408972; total time= 1.1min\n",
      "[CV] END bagging_temperature=0.3701587002554444, border_count=68, depth=7, iterations=280, l2_leaf_reg=6.722924691708383, learning_rate=0.20606631674320916; total time=  50.1s\n",
      "[CV] END bootstrap=True, max_depth=24, max_features=sqrt, min_samples_leaf=8, min_samples_split=8, n_estimators=171; total time=   6.3s\n",
      "[CV] END bootstrap=True, max_depth=27, max_features=None, min_samples_leaf=8, min_samples_split=5, n_estimators=153; total time= 2.4min\n",
      "[CV] END bootstrap=False, max_depth=7, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=137; total time=   2.7s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=253; total time=   5.2s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=253; total time=   4.8s\n",
      "[CV] END bootstrap=False, max_depth=26, max_features=sqrt, min_samples_leaf=9, min_samples_split=18, n_estimators=268; total time=  17.3s\n",
      "[CV] END bootstrap=True, max_depth=14, max_features=None, min_samples_leaf=3, min_samples_split=13, n_estimators=104; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=29, max_features=None, min_samples_leaf=5, min_samples_split=8, n_estimators=70; total time= 2.5min\n",
      "[CV] END bootstrap=False, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=133; total time=   3.1s\n",
      "[CV] END bootstrap=False, max_depth=19, max_features=None, min_samples_leaf=8, min_samples_split=16, n_estimators=84; total time= 2.6min\n",
      "[CV] END bootstrap=False, max_depth=21, max_features=log2, min_samples_leaf=8, min_samples_split=5, n_estimators=51; total time=   1.2s[CV] END bagging_temperature=0.9266588657937942, border_count=126, depth=9, iterations=314, l2_leaf_reg=6.208342600258237, learning_rate=0.20223440486986985; total time= 6.1min\n",
      "[CV] END bagging_temperature=0.8445338486781514, border_count=113, depth=9, iterations=152, l2_leaf_reg=6.867511656638483, learning_rate=0.2030510614528276; total time= 2.8min\n",
      "[CV] END bagging_temperature=0.6070342476866847, border_count=72, depth=7, iterations=114, l2_leaf_reg=2.6526693906300247, learning_rate=0.013127281348238786; total time=  26.0s\n",
      "[CV] END bagging_temperature=0.4234014807063696, border_count=160, depth=6, iterations=235, l2_leaf_reg=1.055221171236024, learning_rate=0.17309228569096685; total time=  57.0s\n",
      "[CV] END bagging_temperature=0.7068573438476171, border_count=194, depth=5, iterations=388, l2_leaf_reg=7.059599747810114, learning_rate=0.19526017570266982; total time= 1.2min\n",
      "[CV] END bagging_temperature=0.6510770255019445, border_count=59, depth=9, iterations=300, l2_leaf_reg=7.232981268275579, learning_rate=0.07617960497052984; total time= 2.9min\n",
      "[CV] END bagging_temperature=0.06355835028602363, border_count=182, depth=8, iterations=315, l2_leaf_reg=7.659223566174966, learning_rate=0.12825955754154544; total time= 4.4min\n",
      "[CV] END bagging_temperature=0.27472179299006416, border_count=66, depth=3, iterations=326, l2_leaf_reg=2.195942459383017, learning_rate=0.15264895744459903; total time=  15.2s\n",
      "[CV] END bagging_temperature=0.7607850486168974, border_count=249, depth=9, iterations=354, l2_leaf_reg=3.5606832276132394, learning_rate=0.01808671790768627; total time=12.8min\n",
      "[CV] END bagging_temperature=0.7106628896857874, border_count=121, depth=4, iterations=278, l2_leaf_reg=1.3142918568673425, learning_rate=0.1372820822527561; total time=  21.0s\n",
      "[CV] END bagging_temperature=0.3143559810763267, border_count=127, depth=6, iterations=321, l2_leaf_reg=2.393314544058757, learning_rate=0.13088347585556345; total time= 1.0min\n",
      "[CV] END bagging_temperature=0.5398410913016731, border_count=60, depth=6, iterations=112, l2_leaf_reg=1.76979909828793, learning_rate=0.0679502905827536; total time=  13.3s\n",
      "[CV] END bagging_temperature=0.45653457048291024, border_count=139, depth=6, iterations=385, l2_leaf_reg=9.832802589188683, learning_rate=0.07486900420105479; total time= 1.3min\n",
      "[CV] END bagging_temperature=0.12208795470067335, border_count=248, depth=9, iterations=289, l2_leaf_reg=2.1005192452767676, learning_rate=0.05558703250838834; total time=10.5min\n",
      "[CV] END bagging_temperature=0.4271077886262563, border_count=147, depth=7, iterations=332, l2_leaf_reg=4.04781258158029, learning_rate=0.04293117062858835; total time= 1.9min\n",
      "[CV] END bagging_temperature=0.534089419375442, border_count=93, depth=7, iterations=324, l2_leaf_reg=2.1986536733368283, learning_rate=0.07752303428072559; total time= 1.3min\n",
      "[CV] END bagging_temperature=0.9429097039125192, border_count=149, depth=3, iterations=279, l2_leaf_reg=4.63629602379294, learning_rate=0.20435641654419215; total time=  16.0s\n",
      "[CV] END bagging_temperature=0.9624472949421112, border_count=70, depth=4, iterations=212, l2_leaf_reg=2.4808692995339987, learning_rate=0.20954809700978838; total time=  11.9s\n",
      "[CV] END bagging_temperature=0.266781014275285, border_count=33, depth=4, iterations=319, l2_leaf_reg=1.5147875124998935, learning_rate=0.06572929284732229; total time=  12.6s\n",
      "[CV] END bagging_temperature=0.9082658859666537, border_count=178, depth=8, iterations=229, l2_leaf_reg=6.309345833171363, learning_rate=0.09955663291461833; total time= 2.9min\n",
      "[CV] END bagging_temperature=0.552893089071328, border_count=99, depth=9, iterations=302, l2_leaf_reg=4.696544560614044, learning_rate=0.05843198765548518; total time= 4.4min\n",
      "[CV] END bagging_temperature=0.8031397563798959, border_count=100, depth=6, iterations=197, l2_leaf_reg=7.335297107608947, learning_rate=0.11715493681495169; total time=  33.4s\n",
      "[CV] END bagging_temperature=0.0902897700544083, border_count=128, depth=3, iterations=223, l2_leaf_reg=6.0819877674071865, learning_rate=0.14916256135817638; total time=  14.4s\n",
      "[CV] END bagging_temperature=0.8583588048137198, border_count=218, depth=6, iterations=246, l2_leaf_reg=4.4866598729172935, learning_rate=0.029235310218284155; total time= 1.3min\n",
      "[CV] END bagging_temperature=0.940523264489604, border_count=199, depth=9, iterations=228, l2_leaf_reg=7.7569011703928075, learning_rate=0.15704322384815445; total time= 7.4min\n",
      "[CV] END bagging_temperature=0.20907162073771368, border_count=190, depth=8, iterations=397, l2_leaf_reg=3.579416277151556, learning_rate=0.14199680920683583; total time= 6.2min\n",
      "[CV] END bagging_temperature=0.8172222002012158, border_count=91, depth=3, iterations=101, l2_leaf_reg=10.962536997579242, learning_rate=0.20308387025775876; total time=   5.9s\n",
      "[CV] END bagging_temperature=0.5582934536070976, border_count=191, depth=5, iterations=108, l2_leaf_reg=3.7887135259218185, learning_rate=0.15007156599455426; total time=  17.0s\n",
      "[CV] END bagging_temperature=0.8466611422383059, border_count=179, depth=8, iterations=219, l2_leaf_reg=9.877700987609598, learning_rate=0.18018568975350258; total time= 2.8min\n",
      "[CV] END bagging_temperature=0.9356349942209475, border_count=195, depth=8, iterations=203, l2_leaf_reg=7.0642905965958995, learning_rate=0.01183941032332593; total time= 2.8min\n",
      "[CV] END bagging_temperature=0.1014715428660321, border_count=130, depth=3, iterations=293, l2_leaf_reg=7.918951976926932, learning_rate=0.14039225190052013; total time=  16.9s\n",
      "[CV] END bagging_temperature=0.22426930946055978, border_count=192, depth=6, iterations=388, l2_leaf_reg=5.938937151834346, learning_rate=0.04576454184426577; total time= 1.6min\n",
      "[CV] END bagging_temperature=0.3664687845828599, border_count=167, depth=9, iterations=294, l2_leaf_reg=7.576128923003433, learning_rate=0.12366172066709433; total time= 6.9min\n",
      "[CV] END bagging_temperature=0.09367476782809248, border_count=146, depth=8, iterations=121, l2_leaf_reg=3.4398964337908358, learning_rate=0.20460211095048914; total time= 1.2min\n",
      "[CV] END bagging_temperature=0.3930977246667604, border_count=213, depth=5, iterations=126, l2_leaf_reg=8.948113035416483, learning_rate=0.11052741862103842; total time=  24.3s\n",
      "[CV] END bagging_temperature=0.5769038846263591, border_count=223, depth=3, iterations=246, l2_leaf_reg=6.720041992091831, learning_rate=0.16371080286126183; total time=  19.3s\n",
      "[CV] END bagging_temperature=0.04360377175443375, border_count=203, depth=6, iterations=257, l2_leaf_reg=10.539285770025874, learning_rate=0.19297287804408972; total time= 1.1min\n",
      "[CV] END bagging_temperature=0.3701587002554444, border_count=68, depth=7, iterations=280, l2_leaf_reg=6.722924691708383, learning_rate=0.20606631674320916; total time=  50.2s\n",
      "[CV] END bootstrap=True, max_depth=24, max_features=sqrt, min_samples_leaf=8, min_samples_split=8, n_estimators=171; total time=   6.0s\n",
      "[CV] END bootstrap=True, max_depth=27, max_features=None, min_samples_leaf=8, min_samples_split=5, n_estimators=153; total time= 2.6min\n",
      "[CV] END bootstrap=False, max_depth=26, max_features=sqrt, min_samples_leaf=9, min_samples_split=18, n_estimators=268; total time=  16.5s\n",
      "[CV] END bootstrap=True, max_depth=14, max_features=None, min_samples_leaf=3, min_samples_split=13, n_estimators=104; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=29, max_features=None, min_samples_leaf=5, min_samples_split=8, n_estimators=70; total time= 3.0min\n",
      "[CV] END bootstrap=False, max_depth=19, max_features=None, min_samples_leaf=8, min_samples_split=16, n_estimators=84; total time= 2.7min\n",
      "[CV] END bootstrap=False, max_depth=19, max_features=log2, min_samples_leaf=7, min_samples_split=9, n_estimators=262; total time=   5.9s\n",
      "[CV] END bootstrap=False, max_depth=17, max_features=log2, min_samples_leaf=5, min_samples_split=14, n_estimators=90; total time=   2.2s\n",
      "[CV] END bootstrap=True, max_depth=19, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=58; total time=   2.6s\n",
      "[CV] END bootstrap=False, max_depth=5, max_features=None, min_samples_leaf=3, min_samples_split=18, n_estimators=185; total time= 3.9min\n",
      "[CV] END bootstrap=True, max_depth=7, max_features=sqrt, min_samples_leaf=5, min_samples_split=11, n_estimators=280; total time=   8.6s[CV] END bagging_temperature=0.7106628896857874, border_count=121, depth=4, iterations=278, l2_leaf_reg=1.3142918568673425, learning_rate=0.1372820822527561; total time=  20.3s\n",
      "[CV] END bagging_temperature=0.3143559810763267, border_count=127, depth=6, iterations=321, l2_leaf_reg=2.393314544058757, learning_rate=0.13088347585556345; total time=  58.7s\n",
      "[CV] END bagging_temperature=0.5398410913016731, border_count=60, depth=6, iterations=112, l2_leaf_reg=1.76979909828793, learning_rate=0.0679502905827536; total time=  12.8s\n",
      "[CV] END bagging_temperature=0.16122128725400442, border_count=97, depth=4, iterations=144, l2_leaf_reg=3.95633685837714, learning_rate=0.031098851966054122; total time=   9.1s\n",
      "[CV] END bagging_temperature=0.45653457048291024, border_count=139, depth=6, iterations=385, l2_leaf_reg=9.832802589188683, learning_rate=0.07486900420105479; total time= 1.3min\n",
      "[CV] END bagging_temperature=0.12208795470067335, border_count=248, depth=9, iterations=289, l2_leaf_reg=2.1005192452767676, learning_rate=0.05558703250838834; total time=10.5min\n",
      "[CV] END bagging_temperature=0.4271077886262563, border_count=147, depth=7, iterations=332, l2_leaf_reg=4.04781258158029, learning_rate=0.04293117062858835; total time= 1.9min\n",
      "[CV] END bagging_temperature=0.534089419375442, border_count=93, depth=7, iterations=324, l2_leaf_reg=2.1986536733368283, learning_rate=0.07752303428072559; total time= 1.3min\n",
      "[CV] END bagging_temperature=0.9429097039125192, border_count=149, depth=3, iterations=279, l2_leaf_reg=4.63629602379294, learning_rate=0.20435641654419215; total time=  15.9s\n",
      "[CV] END bagging_temperature=0.9624472949421112, border_count=70, depth=4, iterations=212, l2_leaf_reg=2.4808692995339987, learning_rate=0.20954809700978838; total time=  11.9s\n",
      "[CV] END bagging_temperature=0.266781014275285, border_count=33, depth=4, iterations=319, l2_leaf_reg=1.5147875124998935, learning_rate=0.06572929284732229; total time=  12.1s\n",
      "[CV] END bagging_temperature=0.9082658859666537, border_count=178, depth=8, iterations=229, l2_leaf_reg=6.309345833171363, learning_rate=0.09955663291461833; total time= 2.9min\n",
      "[CV] END bagging_temperature=0.552893089071328, border_count=99, depth=9, iterations=302, l2_leaf_reg=4.696544560614044, learning_rate=0.05843198765548518; total time= 4.3min\n",
      "[CV] END bagging_temperature=0.8031397563798959, border_count=100, depth=6, iterations=197, l2_leaf_reg=7.335297107608947, learning_rate=0.11715493681495169; total time=  30.7s\n",
      "[CV] END bagging_temperature=0.0902897700544083, border_count=128, depth=3, iterations=223, l2_leaf_reg=6.0819877674071865, learning_rate=0.14916256135817638; total time=  14.1s\n",
      "[CV] END bagging_temperature=0.8583588048137198, border_count=218, depth=6, iterations=246, l2_leaf_reg=4.4866598729172935, learning_rate=0.029235310218284155; total time= 1.3min\n",
      "[CV] END bagging_temperature=0.940523264489604, border_count=199, depth=9, iterations=228, l2_leaf_reg=7.7569011703928075, learning_rate=0.15704322384815445; total time= 7.4min\n",
      "[CV] END bagging_temperature=0.20907162073771368, border_count=190, depth=8, iterations=397, l2_leaf_reg=3.579416277151556, learning_rate=0.14199680920683583; total time= 6.1min\n",
      "[CV] END bagging_temperature=0.8172222002012158, border_count=91, depth=3, iterations=101, l2_leaf_reg=10.962536997579242, learning_rate=0.20308387025775876; total time=   8.9s\n",
      "[CV] END bagging_temperature=0.8172222002012158, border_count=91, depth=3, iterations=101, l2_leaf_reg=10.962536997579242, learning_rate=0.20308387025775876; total time=   6.5s\n",
      "[CV] END bagging_temperature=0.5582934536070976, border_count=191, depth=5, iterations=108, l2_leaf_reg=3.7887135259218185, learning_rate=0.15007156599455426; total time=  18.4s\n",
      "[CV] END bagging_temperature=0.8466611422383059, border_count=179, depth=8, iterations=219, l2_leaf_reg=9.877700987609598, learning_rate=0.18018568975350258; total time= 2.8min\n",
      "[CV] END bagging_temperature=0.9356349942209475, border_count=195, depth=8, iterations=203, l2_leaf_reg=7.0642905965958995, learning_rate=0.01183941032332593; total time= 2.8min\n",
      "[CV] END bagging_temperature=0.1014715428660321, border_count=130, depth=3, iterations=293, l2_leaf_reg=7.918951976926932, learning_rate=0.14039225190052013; total time=  16.9s\n",
      "[CV] END bagging_temperature=0.22426930946055978, border_count=192, depth=6, iterations=388, l2_leaf_reg=5.938937151834346, learning_rate=0.04576454184426577; total time= 1.7min\n",
      "[CV] END bagging_temperature=0.3664687845828599, border_count=167, depth=9, iterations=294, l2_leaf_reg=7.576128923003433, learning_rate=0.12366172066709433; total time= 6.9min\n",
      "[CV] END bagging_temperature=0.09367476782809248, border_count=146, depth=8, iterations=121, l2_leaf_reg=3.4398964337908358, learning_rate=0.20460211095048914; total time= 1.3min\n",
      "[CV] END bagging_temperature=0.3930977246667604, border_count=213, depth=5, iterations=126, l2_leaf_reg=8.948113035416483, learning_rate=0.11052741862103842; total time=  24.4s\n",
      "[CV] END bagging_temperature=0.5769038846263591, border_count=223, depth=3, iterations=246, l2_leaf_reg=6.720041992091831, learning_rate=0.16371080286126183; total time=  20.3s\n",
      "[CV] END bagging_temperature=0.04360377175443375, border_count=203, depth=6, iterations=257, l2_leaf_reg=10.539285770025874, learning_rate=0.19297287804408972; total time= 1.2min\n",
      "[CV] END bagging_temperature=0.3701587002554444, border_count=68, depth=7, iterations=280, l2_leaf_reg=6.722924691708383, learning_rate=0.20606631674320916; total time=  44.1s\n",
      "[CV] END bootstrap=True, max_depth=24, max_features=sqrt, min_samples_leaf=8, min_samples_split=8, n_estimators=171; total time=   6.3s\n",
      "[CV] END bootstrap=True, max_depth=27, max_features=None, min_samples_leaf=8, min_samples_split=5, n_estimators=153; total time= 2.5min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=253; total time=   5.6s\n",
      "[CV] END bootstrap=False, max_depth=26, max_features=sqrt, min_samples_leaf=9, min_samples_split=18, n_estimators=268; total time=  15.6s\n",
      "[CV] END bootstrap=True, max_depth=14, max_features=None, min_samples_leaf=3, min_samples_split=13, n_estimators=104; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=29, max_features=None, min_samples_leaf=5, min_samples_split=8, n_estimators=70; total time= 2.4min\n",
      "[CV] END bootstrap=True, max_depth=11, max_features=log2, min_samples_leaf=4, min_samples_split=15, n_estimators=291; total time=   4.4s\n",
      "[CV] END bootstrap=True, max_depth=11, max_features=log2, min_samples_leaf=4, min_samples_split=15, n_estimators=291; total time=   4.4s\n",
      "[CV] END bootstrap=True, max_depth=11, max_features=log2, min_samples_leaf=4, min_samples_split=15, n_estimators=291; total time=   4.6s\n",
      "[CV] END bootstrap=True, max_depth=11, max_features=log2, min_samples_leaf=4, min_samples_split=15, n_estimators=291; total time=   4.4s\n",
      "[CV] END bootstrap=False, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=133; total time=   2.9s\n",
      "[CV] END bootstrap=False, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=133; total time=   2.4s\n",
      "[CV] END bootstrap=False, max_depth=13, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=133; total time=   2.9s\n",
      "[CV] END bootstrap=False, max_depth=19, max_features=None, min_samples_leaf=8, min_samples_split=16, n_estimators=84; total time= 3.4min\n",
      "[CV] END bootstrap=False, max_depth=5, max_features=None, min_samples_leaf=3, min_samples_split=18, n_estimators=185; total time= 3.9min\n",
      "[CV] END bootstrap=False, max_depth=13, max_features=None, min_samples_leaf=9, min_samples_split=9, n_estimators=61; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=5, max_features=None, min_samples_leaf=7, min_samples_split=6, n_estimators=148; total time= 3.1min\n",
      "[CV] END bootstrap=False, max_depth=12, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=276; total time=   6.7s\n",
      "[CV] END bootstrap=False, max_depth=12, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=276; total time=   6.1s\n",
      "[CV] END bootstrap=True, max_depth=19, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=54; total time=   0.9s[CV] END bagging_temperature=0.8031397563798959, border_count=100, depth=6, iterations=197, l2_leaf_reg=7.335297107608947, learning_rate=0.11715493681495169; total time=  34.2s\n",
      "[CV] END bagging_temperature=0.0902897700544083, border_count=128, depth=3, iterations=223, l2_leaf_reg=6.0819877674071865, learning_rate=0.14916256135817638; total time=  13.2s\n",
      "[CV] END bagging_temperature=0.8583588048137198, border_count=218, depth=6, iterations=246, l2_leaf_reg=4.4866598729172935, learning_rate=0.029235310218284155; total time= 1.3min\n",
      "[CV] END bagging_temperature=0.940523264489604, border_count=199, depth=9, iterations=228, l2_leaf_reg=7.7569011703928075, learning_rate=0.15704322384815445; total time= 7.4min\n",
      "[CV] END bagging_temperature=0.20907162073771368, border_count=190, depth=8, iterations=397, l2_leaf_reg=3.579416277151556, learning_rate=0.14199680920683583; total time= 6.2min\n",
      "[CV] END bagging_temperature=0.5582934536070976, border_count=191, depth=5, iterations=108, l2_leaf_reg=3.7887135259218185, learning_rate=0.15007156599455426; total time=  17.2s\n",
      "[CV] END bagging_temperature=0.8466611422383059, border_count=179, depth=8, iterations=219, l2_leaf_reg=9.877700987609598, learning_rate=0.18018568975350258; total time= 2.8min\n",
      "[CV] END bagging_temperature=0.9356349942209475, border_count=195, depth=8, iterations=203, l2_leaf_reg=7.0642905965958995, learning_rate=0.01183941032332593; total time= 2.9min\n",
      "[CV] END bagging_temperature=0.1014715428660321, border_count=130, depth=3, iterations=293, l2_leaf_reg=7.918951976926932, learning_rate=0.14039225190052013; total time=  16.3s\n",
      "[CV] END bagging_temperature=0.22426930946055978, border_count=192, depth=6, iterations=388, l2_leaf_reg=5.938937151834346, learning_rate=0.04576454184426577; total time= 1.7min\n",
      "[CV] END bagging_temperature=0.3664687845828599, border_count=167, depth=9, iterations=294, l2_leaf_reg=7.576128923003433, learning_rate=0.12366172066709433; total time= 6.9min\n",
      "[CV] END bagging_temperature=0.09367476782809248, border_count=146, depth=8, iterations=121, l2_leaf_reg=3.4398964337908358, learning_rate=0.20460211095048914; total time= 1.3min\n",
      "[CV] END bagging_temperature=0.3930977246667604, border_count=213, depth=5, iterations=126, l2_leaf_reg=8.948113035416483, learning_rate=0.11052741862103842; total time=  23.6s\n",
      "[CV] END bagging_temperature=0.5769038846263591, border_count=223, depth=3, iterations=246, l2_leaf_reg=6.720041992091831, learning_rate=0.16371080286126183; total time=  19.6s\n",
      "[CV] END bagging_temperature=0.04360377175443375, border_count=203, depth=6, iterations=257, l2_leaf_reg=10.539285770025874, learning_rate=0.19297287804408972; total time= 1.1min\n",
      "[CV] END bagging_temperature=0.3701587002554444, border_count=68, depth=7, iterations=280, l2_leaf_reg=6.722924691708383, learning_rate=0.20606631674320916; total time=  49.8s\n",
      "[CV] END bootstrap=True, max_depth=24, max_features=sqrt, min_samples_leaf=8, min_samples_split=8, n_estimators=171; total time=   5.7s\n",
      "[CV] END bootstrap=True, max_depth=27, max_features=None, min_samples_leaf=8, min_samples_split=5, n_estimators=153; total time= 2.4min\n",
      "[CV] END bootstrap=False, max_depth=7, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=137; total time=   2.7s\n",
      "[CV] END bootstrap=False, max_depth=7, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=137; total time=   2.4s\n",
      "[CV] END bootstrap=False, max_depth=7, max_features=log2, min_samples_leaf=5, min_samples_split=3, n_estimators=137; total time=   2.3s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=253; total time=   5.8s\n",
      "[CV] END bootstrap=False, max_depth=26, max_features=sqrt, min_samples_leaf=9, min_samples_split=18, n_estimators=268; total time=  16.9s\n",
      "[CV] END bootstrap=True, max_depth=14, max_features=None, min_samples_leaf=3, min_samples_split=13, n_estimators=104; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=29, max_features=None, min_samples_leaf=5, min_samples_split=8, n_estimators=70; total time= 2.4min\n",
      "[CV] END bootstrap=False, max_depth=19, max_features=None, min_samples_leaf=8, min_samples_split=16, n_estimators=84; total time= 2.6min\n",
      "[CV] END bootstrap=False, max_depth=21, max_features=log2, min_samples_leaf=8, min_samples_split=5, n_estimators=51; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=21, max_features=log2, min_samples_leaf=8, min_samples_split=5, n_estimators=51; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=19, n_estimators=267; total time=   6.1s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=19, n_estimators=267; total time=   5.9s\n",
      "[CV] END bootstrap=False, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=15, n_estimators=144; total time=   2.9s\n",
      "[CV] END bootstrap=False, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=15, n_estimators=144; total time=   3.2s\n",
      "[CV] END bootstrap=False, max_depth=19, max_features=log2, min_samples_leaf=7, min_samples_split=9, n_estimators=262; total time=   5.8s\n",
      "[CV] END bootstrap=False, max_depth=17, max_features=log2, min_samples_leaf=5, min_samples_split=14, n_estimators=90; total time=   2.2s\n",
      "[CV] END bootstrap=False, max_depth=17, max_features=log2, min_samples_leaf=5, min_samples_split=14, n_estimators=90; total time=   2.0s\n",
      "[CV] END bootstrap=False, max_depth=17, max_features=log2, min_samples_leaf=5, min_samples_split=14, n_estimators=90; total time=   2.2s\n",
      "[CV] END bootstrap=True, max_depth=19, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=58; total time=   2.1s\n",
      "[CV] END bootstrap=False, max_depth=5, max_features=None, min_samples_leaf=3, min_samples_split=18, n_estimators=185; total time= 4.0min\n",
      "[CV] END bootstrap=True, max_depth=7, max_features=sqrt, min_samples_leaf=5, min_samples_split=11, n_estimators=280; total time=   9.5s\n",
      "[CV] END bootstrap=False, max_depth=13, max_features=None, min_samples_leaf=9, min_samples_split=9, n_estimators=61; total time= 2.4min\n",
      "[CV] END bootstrap=False, max_depth=5, max_features=None, min_samples_leaf=7, min_samples_split=6, n_estimators=148; total time= 3.1min\n",
      "[CV] END bootstrap=False, max_depth=27, max_features=None, min_samples_leaf=7, min_samples_split=10, n_estimators=256; total time= 8.6min\n",
      "[CV] END bootstrap=True, max_depth=15, max_features=sqrt, min_samples_leaf=4, min_samples_split=14, n_estimators=209; total time=   9.7s\n",
      "[CV] END bootstrap=True, max_depth=23, max_features=log2, min_samples_leaf=2, min_samples_split=11, n_estimators=94; total time=   1.7s\n",
      "[CV] END bootstrap=True, max_depth=23, max_features=log2, min_samples_leaf=2, min_samples_split=11, n_estimators=94; total time=   1.8s\n",
      "[CV] END bootstrap=True, max_depth=23, max_features=log2, min_samples_leaf=2, min_samples_split=11, n_estimators=94; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=29, max_features=sqrt, min_samples_leaf=6, min_samples_split=13, n_estimators=93; total time=   6.0s\n",
      "[CV] END bootstrap=False, max_depth=15, max_features=log2, min_samples_leaf=7, min_samples_split=8, n_estimators=239; total time=   5.7s\n",
      "[CV] END bootstrap=False, max_depth=15, max_features=log2, min_samples_leaf=7, min_samples_split=8, n_estimators=239; total time=   5.7s\n",
      "[CV] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=9, min_samples_split=14, n_estimators=282; total time=   8.0s\n",
      "[CV] END bootstrap=True, max_depth=11, max_features=log2, min_samples_leaf=8, min_samples_split=10, n_estimators=111; total time=   1.7s\n",
      "[CV] END bootstrap=True, max_depth=11, max_features=log2, min_samples_leaf=8, min_samples_split=10, n_estimators=111; total time=   1.7s\n",
      "[CV] END bootstrap=True, max_depth=5, max_features=None, min_samples_leaf=8, min_samples_split=16, n_estimators=108; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=28, max_features=sqrt, min_samples_leaf=4, min_samples_split=18, n_estimators=111; total time=   7.6s\n",
      "[CV] END bootstrap=True, max_depth=24, max_features=log2, min_samples_leaf=7, min_samples_split=3, n_estimators=180; total time=   2.7s\n",
      "[CV] END bootstrap=True, max_depth=24, max_features=log2, min_samples_leaf=7, min_samples_split=3, n_estimators=180; total time=   2.7sBest params: {'bootstrap': True, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 9, 'min_samples_split': 14, 'n_estimators': 282}\n",
      "Best ROC-AUC: 0.5844\n",
      "\n",
      "Tuning Logistic Regression...\n",
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END bootstrap=False, max_depth=21, max_features=log2, min_samples_leaf=8, min_samples_split=5, n_estimators=51; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=19, n_estimators=267; total time=   5.2s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=19, n_estimators=267; total time=   5.6s\n",
      "[CV] END bootstrap=False, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=15, n_estimators=144; total time=   2.5s\n",
      "[CV] END bootstrap=False, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=15, n_estimators=144; total time=   3.9s\n",
      "[CV] END bootstrap=False, max_depth=19, max_features=log2, min_samples_leaf=7, min_samples_split=9, n_estimators=262; total time=   6.2s\n",
      "[CV] END bootstrap=False, max_depth=19, max_features=log2, min_samples_leaf=7, min_samples_split=9, n_estimators=262; total time=   5.9s\n",
      "[CV] END bootstrap=True, max_depth=19, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=58; total time=   2.4s\n",
      "[CV] END bootstrap=True, max_depth=19, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=58; total time=   2.4s\n",
      "[CV] END bootstrap=False, max_depth=5, max_features=None, min_samples_leaf=3, min_samples_split=18, n_estimators=185; total time= 3.9min\n",
      "[CV] END bootstrap=True, max_depth=7, max_features=sqrt, min_samples_leaf=5, min_samples_split=11, n_estimators=280; total time=   9.9s\n",
      "[CV] END bootstrap=False, max_depth=13, max_features=None, min_samples_leaf=9, min_samples_split=9, n_estimators=61; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=5, max_features=None, min_samples_leaf=7, min_samples_split=6, n_estimators=148; total time= 3.2min\n",
      "[CV] END bootstrap=True, max_depth=19, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=54; total time=   1.1s\n",
      "[CV] END bootstrap=True, max_depth=19, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=54; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=19, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=54; total time=   0.9s\n",
      "[CV] END bootstrap=False, max_depth=27, max_features=None, min_samples_leaf=7, min_samples_split=10, n_estimators=256; total time= 8.4min\n",
      "[CV] END bootstrap=True, max_depth=14, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=290; total time=  11.8s\n",
      "[CV] END bootstrap=True, max_depth=14, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=290; total time=  12.1s\n",
      "[CV] END bootstrap=False, max_depth=8, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=286; total time=   6.1s\n",
      "[CV] END bootstrap=False, max_depth=8, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=286; total time=   6.0s\n",
      "[CV] END bootstrap=True, max_depth=15, max_features=sqrt, min_samples_leaf=4, min_samples_split=14, n_estimators=209; total time=   9.3s\n",
      "[CV] END bootstrap=True, max_depth=15, max_features=sqrt, min_samples_leaf=4, min_samples_split=14, n_estimators=209; total time=   7.7s\n",
      "[CV] END bootstrap=False, max_depth=29, max_features=sqrt, min_samples_leaf=6, min_samples_split=13, n_estimators=93; total time=   6.7s\n",
      "[CV] END bootstrap=False, max_depth=15, max_features=log2, min_samples_leaf=7, min_samples_split=8, n_estimators=239; total time=   5.5s\n",
      "[CV] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=9, min_samples_split=14, n_estimators=282; total time=   7.6s\n",
      "[CV] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=9, min_samples_split=14, n_estimators=282; total time=   7.6s\n",
      "[CV] END bootstrap=True, max_depth=5, max_features=None, min_samples_leaf=8, min_samples_split=16, n_estimators=108; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=28, max_features=sqrt, min_samples_leaf=4, min_samples_split=18, n_estimators=111; total time=   7.8s\n",
      "[CV] END bootstrap=True, max_depth=24, max_features=log2, min_samples_leaf=7, min_samples_split=3, n_estimators=180; total time=   2.7s\n",
      "[CV] END bootstrap=True, max_depth=9, max_features=sqrt, min_samples_leaf=8, min_samples_split=18, n_estimators=236; total time=   8.2s\n",
      "[CV] END bootstrap=True, max_depth=9, max_features=sqrt, min_samples_leaf=8, min_samples_split=18, n_estimators=236; total time=   8.0s\n",
      "[CV] END bootstrap=True, max_depth=5, max_features=None, min_samples_leaf=2, min_samples_split=13, n_estimators=267; total time= 3.5min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=None, min_samples_leaf=4, min_samples_split=12, n_estimators=233; total time= 6.8min\n",
      "[CV] END bootstrap=True, max_depth=21, max_features=None, min_samples_leaf=6, min_samples_split=6, n_estimators=165; total time= 2.7min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=173; total time=   4.8s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=173; total time=   4.0s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=173; total time=   4.0s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=173; total time=   4.1s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=196; total time=   7.3s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=196; total time=   6.3s\n",
      "[CV] END bootstrap=False, max_depth=7, max_features=None, min_samples_leaf=3, min_samples_split=8, n_estimators=101; total time= 2.9min\n",
      "[CV] END bootstrap=True, max_depth=5, max_features=None, min_samples_leaf=2, min_samples_split=9, n_estimators=178; total time= 2.3min\n",
      "[CV] END bootstrap=True, max_depth=29, max_features=sqrt, min_samples_leaf=2, min_samples_split=11, n_estimators=148; total time=   6.2s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=9, min_samples_split=18, n_estimators=51; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=9, min_samples_split=18, n_estimators=51; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=209; total time=   3.2s\n",
      "[CV] END bootstrap=True, max_depth=27, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=196; total time=   6.9s\n",
      "[CV] END bootstrap=True, max_depth=27, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=196; total time=   6.3s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=None, min_samples_leaf=4, min_samples_split=2, n_estimators=201; total time= 7.0min\n",
      "[CV] END bootstrap=False, max_depth=15, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=215; total time=  14.0s\n",
      "[CV] END bootstrap=False, max_depth=15, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=215; total time=  14.2s\n",
      "[CV] END bootstrap=False, max_depth=24, max_features=log2, min_samples_leaf=3, min_samples_split=17, n_estimators=266; total time=   6.4s\n",
      "[CV] END C=3.746401188473625, l1_ratio=0.9507143064099162, max_iter=1000, penalty=l1, solver=saga; total time=  32.5s\n",
      "[CV] END C=5.96950157946487, l1_ratio=0.44583275285359114, max_iter=1000, penalty=elasticnet, solver=saga; total time=  16.1s\n",
      "[CV] END C=4.593488919658672, l1_ratio=0.33370861113902184, max_iter=1000, penalty=l2, solver=saga; total time=   6.3s\n",
      "[CV] END C=0.5651157902710026, l1_ratio=0.7219987722668247, max_iter=500, penalty=l2, solver=saga; total time=   2.1s\n",
      "[CV] END C=0.5651157902710026, l1_ratio=0.7219987722668247, max_iter=500, penalty=l2, solver=saga; total time=   1.5s\n",
      "[CV] END C=5.248564316322379, l1_ratio=0.43194501864211576, max_iter=200, penalty=elasticnet, solver=saga; total time=   7.1s\n",
      "[CV] END C=6.119528947223795, l1_ratio=0.13949386065204183, max_iter=1000, penalty=l2, solver=saga; total time=   7.9s\n",
      "[CV] END C=0.907064345328208, l1_ratio=0.6183860093330873, max_iter=1000, penalty=l1, solver=saga; total time=   9.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END bootstrap=True, max_depth=7, max_features=sqrt, min_samples_leaf=5, min_samples_split=11, n_estimators=280; total time=  10.8s\n",
      "[CV] END bootstrap=False, max_depth=13, max_features=None, min_samples_leaf=9, min_samples_split=9, n_estimators=61; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=5, max_features=None, min_samples_leaf=7, min_samples_split=6, n_estimators=148; total time= 3.1min\n",
      "[CV] END bootstrap=False, max_depth=12, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=276; total time=   5.9s\n",
      "[CV] END bootstrap=False, max_depth=12, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=276; total time=   6.0s\n",
      "[CV] END bootstrap=False, max_depth=27, max_features=None, min_samples_leaf=7, min_samples_split=10, n_estimators=256; total time= 8.4min\n",
      "[CV] END bootstrap=True, max_depth=14, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=290; total time=  12.0s\n",
      "[CV] END bootstrap=True, max_depth=14, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=290; total time=  12.7s\n",
      "[CV] END bootstrap=False, max_depth=8, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=286; total time=   5.3s\n",
      "[CV] END bootstrap=False, max_depth=8, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=286; total time=   6.1s\n",
      "[CV] END bootstrap=True, max_depth=15, max_features=sqrt, min_samples_leaf=4, min_samples_split=14, n_estimators=209; total time=   9.2s\n",
      "[CV] END bootstrap=True, max_depth=23, max_features=log2, min_samples_leaf=2, min_samples_split=11, n_estimators=94; total time=   1.9s\n",
      "[CV] END bootstrap=False, max_depth=29, max_features=sqrt, min_samples_leaf=6, min_samples_split=13, n_estimators=93; total time=   6.3s\n",
      "[CV] END bootstrap=False, max_depth=29, max_features=sqrt, min_samples_leaf=6, min_samples_split=13, n_estimators=93; total time=   6.3s\n",
      "[CV] END bootstrap=False, max_depth=15, max_features=log2, min_samples_leaf=7, min_samples_split=8, n_estimators=239; total time=   5.3s\n",
      "[CV] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=9, min_samples_split=14, n_estimators=282; total time=   7.8s\n",
      "[CV] END bootstrap=True, max_depth=11, max_features=log2, min_samples_leaf=8, min_samples_split=10, n_estimators=111; total time=   1.8s\n",
      "[CV] END bootstrap=True, max_depth=11, max_features=log2, min_samples_leaf=8, min_samples_split=10, n_estimators=111; total time=   1.5s\n",
      "[CV] END bootstrap=True, max_depth=5, max_features=None, min_samples_leaf=8, min_samples_split=16, n_estimators=108; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=28, max_features=sqrt, min_samples_leaf=4, min_samples_split=18, n_estimators=111; total time=   8.6s\n",
      "[CV] END bootstrap=False, max_depth=28, max_features=sqrt, min_samples_leaf=4, min_samples_split=18, n_estimators=111; total time=   8.8s\n",
      "[CV] END bootstrap=True, max_depth=24, max_features=log2, min_samples_leaf=7, min_samples_split=3, n_estimators=180; total time=   2.9s\n",
      "[CV] END bootstrap=True, max_depth=9, max_features=sqrt, min_samples_leaf=8, min_samples_split=18, n_estimators=236; total time=   8.1s\n",
      "[CV] END bootstrap=True, max_depth=6, max_features=log2, min_samples_leaf=6, min_samples_split=6, n_estimators=273; total time=   3.2s\n",
      "[CV] END bootstrap=True, max_depth=6, max_features=log2, min_samples_leaf=6, min_samples_split=6, n_estimators=273; total time=   3.5s\n",
      "[CV] END bootstrap=True, max_depth=5, max_features=None, min_samples_leaf=2, min_samples_split=13, n_estimators=267; total time= 3.5min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=None, min_samples_leaf=4, min_samples_split=12, n_estimators=233; total time= 6.9min\n",
      "[CV] END bootstrap=True, max_depth=21, max_features=None, min_samples_leaf=6, min_samples_split=6, n_estimators=165; total time= 3.2min\n",
      "[CV] END bootstrap=False, max_depth=7, max_features=None, min_samples_leaf=3, min_samples_split=8, n_estimators=101; total time= 2.9min\n",
      "[CV] END bootstrap=True, max_depth=5, max_features=None, min_samples_leaf=2, min_samples_split=9, n_estimators=178; total time= 2.3min\n",
      "[CV] END bootstrap=True, max_depth=29, max_features=sqrt, min_samples_leaf=2, min_samples_split=11, n_estimators=148; total time=   5.9s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=209; total time=   3.2s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=209; total time=   3.0s\n",
      "[CV] END bootstrap=True, max_depth=27, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=196; total time=   6.6s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=None, min_samples_leaf=4, min_samples_split=2, n_estimators=201; total time= 8.0min\n",
      "[CV] END C=3.746401188473625, l1_ratio=0.9507143064099162, max_iter=1000, penalty=l1, solver=saga; total time=  32.8s\n",
      "[CV] END C=5.96950157946487, l1_ratio=0.44583275285359114, max_iter=1000, penalty=elasticnet, solver=saga; total time=  18.1s\n",
      "[CV] END C=4.593488919658672, l1_ratio=0.33370861113902184, max_iter=1000, penalty=l2, solver=saga; total time=   6.5s\n",
      "[CV] END C=0.5651157902710026, l1_ratio=0.7219987722668247, max_iter=500, penalty=l2, solver=saga; total time=   1.5s\n",
      "[CV] END C=5.248564316322379, l1_ratio=0.43194501864211576, max_iter=200, penalty=elasticnet, solver=saga; total time=   7.1s\n",
      "[CV] END C=6.119528947223795, l1_ratio=0.13949386065204183, max_iter=1000, penalty=l2, solver=saga; total time=   7.8s\n",
      "[CV] END C=0.907064345328208, l1_ratio=0.6183860093330873, max_iter=1000, penalty=l1, solver=saga; total time=  16.4s\n",
      "[CV] END C=0.46550412719997725, l1_ratio=0.6075448519014384, max_iter=200, penalty=l1, solver=saga; total time=   6.4s\n",
      "[CV] END C=3.855165025399161, l1_ratio=0.015966252220214194, max_iter=500, penalty=elasticnet, solver=saga; total time=  10.6s\n",
      "[CV] END C=6.833635188254583, l1_ratio=0.6099966577826209, max_iter=1000, penalty=elasticnet, solver=saga; total time=  23.5s\n",
      "[CV] END C=9.09420402078782, l1_ratio=0.2587799816000169, max_iter=500, penalty=l2, solver=saga; total time=  10.5s\n",
      "[CV] END C=5.2016802117781085, l1_ratio=0.5467102793432796, max_iter=500, penalty=l1, solver=saga; total time=  16.5s\n",
      "[CV] END C=9.696846277645585, l1_ratio=0.7751328233611146, max_iter=500, penalty=l2, solver=saga; total time=  12.7s\n",
      "[CV] END C=8.949273504276487, l1_ratio=0.5978999788110851, max_iter=1000, penalty=l2, solver=saga; total time=  10.9s\n",
      "[CV] END C=1.9608286241914519, l1_ratio=0.045227288910538066, max_iter=200, penalty=l1, solver=saga; total time=   6.3s\n",
      "[CV] END C=2.7144903177389588, l1_ratio=0.8287375091519293, max_iter=500, penalty=l1, solver=saga; total time=  16.6s\n",
      "[CV] END C=2.8103450968738075, l1_ratio=0.5426960831582485, max_iter=200, penalty=l1, solver=saga; total time=   6.3s\n",
      "[CV] END C=8.022969807540397, l1_ratio=0.07455064367977082, max_iter=1000, penalty=l1, solver=saga; total time=  35.4s\n",
      "[CV] END C=7.723447692966574, l1_ratio=0.1987156815341724, max_iter=1000, penalty=elasticnet, solver=saga; total time=  20.6s\n",
      "[CV] END C=1.9894240408880515, l1_ratio=0.71134195274865, max_iter=1000, penalty=l1, solver=saga; total time=  32.6s\n",
      "[CV] END C=6.060599747810114, l1_ratio=0.926300878513349, max_iter=500, penalty=l1, solver=saga; total time=  18.8s\n",
      "[CV] END C=9.150596755437807, l1_ratio=0.8500385777897993, max_iter=500, penalty=l1, solver=saga; total time=  18.0s\n",
      "[CV] END C=5.913977877077271, l1_ratio=0.27472179299006416, max_iter=1000, penalty=l1, solver=saga; total time=  34.0s\n",
      "[CV] END C=3.830268747537898, l1_ratio=0.9717120953891037, max_iter=1000, penalty=l1, solver=saga; total time=  33.9s\n",
      "[CV] END C=7.218295211648733, l1_ratio=0.23598491974895575, max_iter=500, penalty=elasticnet, solver=saga; total time=  19.2s\n",
      "[CV] END C=4.394365018657702, l1_ratio=0.2017192023353962, max_iter=1000, penalty=l1, solver=saga; total time=  34.4s\n",
      "[CV] END C=3.144559810763267, l1_ratio=0.5085706911647028, max_iter=500, penalty=l1, solver=saga; total time=  16.1s\n",
      "[CV] END C=2.4939222914887496, l1_ratio=0.41038292303562973, max_iter=1000, penalty=l1, solver=saga; total time=  31.7s\n",
      "[CV] END C=2.2889816549162245, l1_ratio=0.07697990982879299, max_iter=1000, penalty=elasticnet, solver=saga; total time=   8.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END bootstrap=False, max_depth=27, max_features=None, min_samples_leaf=7, min_samples_split=10, n_estimators=256; total time=10.5min\n",
      "[CV] END bootstrap=True, max_depth=5, max_features=None, min_samples_leaf=8, min_samples_split=16, n_estimators=108; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=5, max_features=None, min_samples_leaf=2, min_samples_split=13, n_estimators=267; total time= 3.5min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=None, min_samples_leaf=4, min_samples_split=12, n_estimators=233; total time= 7.0min\n",
      "[CV] END bootstrap=True, max_depth=21, max_features=None, min_samples_leaf=6, min_samples_split=6, n_estimators=165; total time= 2.8min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=196; total time=   7.7s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=196; total time=   7.5s\n",
      "[CV] END bootstrap=False, max_depth=7, max_features=None, min_samples_leaf=3, min_samples_split=8, n_estimators=101; total time= 2.7min\n",
      "[CV] END bootstrap=True, max_depth=5, max_features=None, min_samples_leaf=2, min_samples_split=9, n_estimators=178; total time= 2.2min\n",
      "[CV] END bootstrap=True, max_depth=29, max_features=sqrt, min_samples_leaf=2, min_samples_split=11, n_estimators=148; total time=   5.6s\n",
      "[CV] END bootstrap=True, max_depth=29, max_features=sqrt, min_samples_leaf=2, min_samples_split=11, n_estimators=148; total time=   5.9s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=9, min_samples_split=18, n_estimators=51; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=9, min_samples_split=18, n_estimators=51; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=209; total time=   3.2s\n",
      "[CV] END bootstrap=True, max_depth=27, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=196; total time=   7.2s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=None, min_samples_leaf=4, min_samples_split=2, n_estimators=201; total time= 6.9min\n",
      "[CV] END bootstrap=False, max_depth=15, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=215; total time=  12.3s\n",
      "[CV] END bootstrap=False, max_depth=15, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=215; total time=  13.6s\n",
      "[CV] END bootstrap=False, max_depth=24, max_features=log2, min_samples_leaf=3, min_samples_split=17, n_estimators=266; total time=   6.4s\n",
      "[CV] END bootstrap=False, max_depth=24, max_features=log2, min_samples_leaf=3, min_samples_split=17, n_estimators=266; total time=   7.8s\n",
      "[CV] END bootstrap=False, max_depth=24, max_features=log2, min_samples_leaf=3, min_samples_split=17, n_estimators=266; total time=   6.5s\n",
      "[CV] END C=3.746401188473625, l1_ratio=0.9507143064099162, max_iter=1000, penalty=l1, solver=saga; total time=  32.3s\n",
      "[CV] END C=5.96950157946487, l1_ratio=0.44583275285359114, max_iter=1000, penalty=elasticnet, solver=saga; total time=  15.5s\n",
      "[CV] END C=4.593488919658672, l1_ratio=0.33370861113902184, max_iter=1000, penalty=l2, solver=saga; total time=   8.2s\n",
      "[CV] END C=0.5651157902710026, l1_ratio=0.7219987722668247, max_iter=500, penalty=l2, solver=saga; total time=   1.5s\n",
      "[CV] END C=0.008787658410143284, l1_ratio=0.9922115592912175, max_iter=200, penalty=l2, solver=saga; total time=   0.5s\n",
      "[CV] END C=0.008787658410143284, l1_ratio=0.9922115592912175, max_iter=200, penalty=l2, solver=saga; total time=   0.5s\n",
      "[CV] END C=5.248564316322379, l1_ratio=0.43194501864211576, max_iter=200, penalty=elasticnet, solver=saga; total time=   7.2s\n",
      "[CV] END C=6.119528947223795, l1_ratio=0.13949386065204183, max_iter=1000, penalty=l2, solver=saga; total time=   7.8s\n",
      "[CV] END C=0.907064345328208, l1_ratio=0.6183860093330873, max_iter=1000, penalty=l1, solver=saga; total time=  20.0s\n",
      "[CV] END C=0.6515159298527952, l1_ratio=0.9488855372533332, max_iter=500, penalty=l2, solver=saga; total time=   1.7s\n",
      "[CV] END C=3.855165025399161, l1_ratio=0.015966252220214194, max_iter=500, penalty=elasticnet, solver=saga; total time=  13.9s\n",
      "[CV] END C=6.833635188254583, l1_ratio=0.6099966577826209, max_iter=1000, penalty=elasticnet, solver=saga; total time=  24.2s\n",
      "[CV] END C=9.09420402078782, l1_ratio=0.2587799816000169, max_iter=500, penalty=l2, solver=saga; total time=  11.3s\n",
      "[CV] END C=5.2016802117781085, l1_ratio=0.5467102793432796, max_iter=500, penalty=l1, solver=saga; total time=  16.6s\n",
      "[CV] END C=9.696846277645585, l1_ratio=0.7751328233611146, max_iter=500, penalty=l2, solver=saga; total time=  13.2s\n",
      "[CV] END C=8.949273504276487, l1_ratio=0.5978999788110851, max_iter=1000, penalty=l2, solver=saga; total time=  11.0s\n",
      "[CV] END C=2.7144903177389588, l1_ratio=0.8287375091519293, max_iter=500, penalty=l1, solver=saga; total time=  16.6s\n",
      "[CV] END C=2.8103450968738075, l1_ratio=0.5426960831582485, max_iter=200, penalty=l1, solver=saga; total time=   7.1s\n",
      "[CV] END C=8.022969807540397, l1_ratio=0.07455064367977082, max_iter=1000, penalty=l1, solver=saga; total time=  34.0s\n",
      "[CV] END C=7.723447692966574, l1_ratio=0.1987156815341724, max_iter=1000, penalty=elasticnet, solver=saga; total time=  18.5s\n",
      "[CV] END C=1.9894240408880515, l1_ratio=0.71134195274865, max_iter=1000, penalty=l1, solver=saga; total time=  31.7s\n",
      "[CV] END C=6.060599747810114, l1_ratio=0.926300878513349, max_iter=500, penalty=l1, solver=saga; total time=  17.5s\n",
      "[CV] END C=9.150596755437807, l1_ratio=0.8500385777897993, max_iter=500, penalty=l1, solver=saga; total time=  17.1s\n",
      "[CV] END C=0.6365835028602363, l1_ratio=0.3109823217156622, max_iter=200, penalty=elasticnet, solver=saga; total time=   4.1s\n",
      "[CV] END C=0.6365835028602363, l1_ratio=0.3109823217156622, max_iter=200, penalty=elasticnet, solver=saga; total time=   2.5s\n",
      "[CV] END C=5.913977877077271, l1_ratio=0.27472179299006416, max_iter=1000, penalty=l1, solver=saga; total time=  32.4s\n",
      "[CV] END C=3.830268747537898, l1_ratio=0.9717120953891037, max_iter=1000, penalty=l1, solver=saga; total time=  35.8s\n",
      "[CV] END C=7.218295211648733, l1_ratio=0.23598491974895575, max_iter=500, penalty=elasticnet, solver=saga; total time=  17.7s\n",
      "[CV] END C=0.40533589538431347, l1_ratio=0.7106628896857874, max_iter=500, penalty=l2, solver=saga; total time=   1.9s\n",
      "[CV] END C=4.394365018657702, l1_ratio=0.2017192023353962, max_iter=1000, penalty=l1, solver=saga; total time=  32.8s\n",
      "[CV] END C=3.144559810763267, l1_ratio=0.5085706911647028, max_iter=500, penalty=l1, solver=saga; total time=  16.3s\n",
      "[CV] END C=2.4939222914887496, l1_ratio=0.41038292303562973, max_iter=1000, penalty=l1, solver=saga; total time=  31.4s\n",
      "[CV] END C=2.2889816549162245, l1_ratio=0.07697990982879299, max_iter=1000, penalty=elasticnet, solver=saga; total time=  12.1s\n",
      "[CV] END C=1.613212872540044, l1_ratio=0.9296976523425731, max_iter=200, penalty=l2, solver=saga; total time=   2.8s\n",
      "[CV] END C=6.335037565104235, l1_ratio=0.8714605901877177, max_iter=500, penalty=l2, solver=saga; total time=   8.1s\n",
      "[CV] END C=5.394422419156507, l1_ratio=0.8074401551640625, max_iter=200, penalty=elasticnet, solver=saga; total time=   6.5s\n",
      "[CV] END C=9.06928441545754, l1_ratio=0.2721322493846353, max_iter=1000, penalty=l2, solver=saga; total time=  10.5s\n",
      "[CV] END C=0.006203769953158188, l1_ratio=0.352568856334169, max_iter=1000, penalty=elasticnet, solver=saga; total time=   0.6s\n",
      "[CV] END C=0.006203769953158188, l1_ratio=0.352568856334169, max_iter=1000, penalty=elasticnet, solver=saga; total time=   0.5s\n",
      "[CV] END C=0.006203769953158188, l1_ratio=0.352568856334169, max_iter=1000, penalty=elasticnet, solver=saga; total time=   0.6s\n",
      "[CV] END C=1.6475585314294172, l1_ratio=0.534089419375442, max_iter=500, penalty=l1, solver=saga; total time=  15.3s\n",
      "[CV] END C=6.925360328902704, l1_ratio=0.2694123337985215, max_iter=1000, penalty=elasticnet, solver=saga; total time=  18.9s\n",
      "[CV] END C=3.233029320207552, l1_ratio=0.5187906217433661, max_iter=200, penalty=l1, solver=saga; total time=   6.6s\n",
      "[CV] END C=0.6499224710898156, l1_ratio=0.2539154139343447, max_iter=500, penalty=elasticnet, solver=saga; total time=   2.5s\n",
      "[CV] END C=0.6499224710898156, l1_ratio=0.2539154139343447, max_iter=500, penalty=elasticnet, solver=saga; total time=   2.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/templarius/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': np.float64(6.833635188254583), 'l1_ratio': np.float64(0.6099966577826209), 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "Best F1: 0.6444\n",
      "\n",
      "\n",
      "================================================================================\n",
      "saved to 'best_hyperparameters.joblib'\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Random Search\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from scipy.stats import randint, uniform\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def tune_xgboost(X_train, y_train, n_iter=20, cv_folds=3):\n",
    "    \"\"\"Tune XGBoost hyperparameters\"\"\"\n",
    "    print(\"Tuning XGBoost...\")\n",
    "    \n",
    "    n_pos = np.sum(y_train == 1)\n",
    "    n_neg = np.sum(y_train == 0)\n",
    "    scale_pos_weight = n_neg / n_pos if n_pos > 0 else 1\n",
    "    \n",
    "    param_dist = {\n",
    "        'max_depth': randint(3, 10),\n",
    "        'learning_rate': uniform(0.01, 0.2),\n",
    "        'n_estimators': randint(100, 400),\n",
    "        'subsample': uniform(0.6, 0.4),\n",
    "        'colsample_bytree': uniform(0.6, 0.4),\n",
    "        'min_child_weight': randint(1, 7),\n",
    "        'gamma': uniform(0, 0.3),\n",
    "        'reg_alpha': uniform(0, 1),\n",
    "        'reg_lambda': uniform(0, 2)\n",
    "    }\n",
    "    \n",
    "    base_model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        tree_method='hist',\n",
    "        device='cpu',\n",
    "        random_state=42,\n",
    "        scale_pos_weight=scale_pos_weight\n",
    "    )\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=base_model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter,\n",
    "        cv=cv,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best params: {random_search.best_params_}\")\n",
    "    print(f\"Best F1: {random_search.best_score_:.4f}\\n\")\n",
    "    \n",
    "    return random_search.best_params_\n",
    "\n",
    "def tune_lightgbm(X_train, y_train, n_iter=20, cv_folds=3):\n",
    "    \"\"\"Tune LightGBM hyperparameters\"\"\"\n",
    "    print(\"Tuning LightGBM...\")\n",
    "    \n",
    "    n_pos = np.sum(y_train == 1)\n",
    "    n_neg = np.sum(y_train == 0)\n",
    "    scale_pos_weight = n_neg / n_pos if n_pos > 0 else 1\n",
    "    \n",
    "    param_dist = {\n",
    "        'max_depth': randint(3, 10),\n",
    "        'learning_rate': uniform(0.01, 0.2),\n",
    "        'n_estimators': randint(100, 400),\n",
    "        'subsample': uniform(0.6, 0.4),\n",
    "        'colsample_bytree': uniform(0.6, 0.4),\n",
    "        'min_child_weight': uniform(1, 10),\n",
    "        'reg_alpha': uniform(0, 1),\n",
    "        'reg_lambda': uniform(0, 2),\n",
    "        'num_leaves': randint(20, 100)\n",
    "    }\n",
    "    \n",
    "    base_model = lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        metric='binary_logloss',\n",
    "        device='cpu',\n",
    "        random_state=42,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=base_model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter,\n",
    "        cv=cv,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best params: {random_search.best_params_}\")\n",
    "    print(f\"Best F1: {random_search.best_score_:.4f}\\n\")\n",
    "    \n",
    "    return random_search.best_params_\n",
    "\n",
    "def tune_catboost(X_train, y_train, n_iter=20, cv_folds=3):\n",
    "    \"\"\"Tune CatBoost hyperparameters\"\"\"\n",
    "    print(\"Tuning CatBoost...\")\n",
    "    \n",
    "    n_pos = np.sum(y_train == 1)\n",
    "    n_neg = np.sum(y_train == 0)\n",
    "    scale_pos_weight = n_neg / n_pos if n_pos > 0 else 1\n",
    "    \n",
    "    param_dist = {\n",
    "        'depth': randint(3, 10),\n",
    "        'learning_rate': uniform(0.01, 0.2),\n",
    "        'iterations': randint(100, 400),\n",
    "        'l2_leaf_reg': uniform(1, 10),\n",
    "        'border_count': randint(32, 255),\n",
    "        'bagging_temperature': uniform(0, 1)\n",
    "    }\n",
    "    \n",
    "    base_model = CatBoostClassifier(\n",
    "        random_seed=42,\n",
    "        verbose=False,\n",
    "        scale_pos_weight=scale_pos_weight\n",
    "    )\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=base_model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter,\n",
    "        cv=cv,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best params: {random_search.best_params_}\")\n",
    "    print(f\"Best F1: {random_search.best_score_:.4f}\\n\")\n",
    "    \n",
    "    return random_search.best_params_\n",
    "\n",
    "def tune_random_forest(X_train, y_train, n_iter=20, cv_folds=3):\n",
    "    \"\"\"Tune Random Forest hyperparameters\"\"\"\n",
    "    print(\"Tuning Random Forest...\")\n",
    "    \n",
    "    param_dist = {\n",
    "        'n_estimators': randint(50, 300),\n",
    "        'max_depth': randint(5, 30),\n",
    "        'min_samples_split': randint(2, 20),\n",
    "        'min_samples_leaf': randint(1, 10),\n",
    "        'max_features': ['sqrt', 'log2', None],\n",
    "        'bootstrap': [True, False]\n",
    "    }\n",
    "    \n",
    "    base_model = RandomForestClassifier(\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=base_model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter,\n",
    "        cv=cv,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best params: {random_search.best_params_}\")\n",
    "    print(f\"Best : {random_search.best_score_:.4f}\\n\")\n",
    "    \n",
    "    return random_search.best_params_\n",
    "\n",
    "def tune_logistic_regression(X_train, y_train, n_iter=15, cv_folds=3):\n",
    "    \"\"\"Tune Logistic Regression hyperparameters\"\"\"\n",
    "    print(\"Tuning Logistic Regression...\")\n",
    "    \n",
    "    param_dist = {\n",
    "        'C': uniform(0.001, 10),\n",
    "        'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "        'solver': ['saga'],\n",
    "        'l1_ratio': uniform(0, 1),  # Only used with elasticnet\n",
    "        'max_iter': [200, 500, 1000]\n",
    "    }\n",
    "    \n",
    "    base_model = LogisticRegression(\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=base_model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter,\n",
    "        cv=cv,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best params: {random_search.best_params_}\")\n",
    "    print(f\"Best F1: {random_search.best_score_:.4f}\\n\")\n",
    "    \n",
    "    return random_search.best_params_\n",
    "\n",
    "# Run hyperparameter tuning\n",
    "print(\"=\"*80)\n",
    "print(\"HYPERPARAMETER TUNING FOR ALL MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_params = {}\n",
    "best_params['xgboost'] = tune_xgboost(X_train_reduced, y_train, n_iter=50, cv_folds=4)\n",
    "best_params['lightgbm'] = tune_lightgbm(X_train_reduced, y_train, n_iter=50, cv_folds=4)\n",
    "best_params['catboost'] = tune_catboost(X_train_reduced, y_train, n_iter=50, cv_folds=4)\n",
    "best_params['random_forest'] = tune_random_forest(X_train_reduced, y_train, n_iter=50, cv_folds=4)\n",
    "best_params['logistic'] = tune_logistic_regression(X_train_reduced, y_train, n_iter=50, cv_folds=4)\n",
    "\n",
    "# Save best parameters\n",
    "joblib.dump(best_params, 'best_hyperparameters.joblib')\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"saved to 'best_hyperparameters.joblib'\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fbcbd33b-a6cd-431f-bdc4-e574bf192268",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tuned hyperparameters!\n",
      "================================================================================\n",
      "Class distribution - Negative: 1666, Positive: 273\n",
      "Scale pos weight: 6.1026\n",
      "\n",
      "================================================================================\n",
      "CROSS-VALIDATION FOR ALL MODELS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Model: XGBOOST\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "xgboost CV:  20%|██████▌                          | 1/5 [00:12<00:51, 12.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: acc=0.8763, logloss=0.2814, ROC-AUC=0.8921, PR-AUC=0.6297, F1=0.6050 @thresh=0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "xgboost CV:  40%|█████████████▏                   | 2/5 [00:25<00:38, 12.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: acc=0.8866, logloss=0.2606, ROC-AUC=0.9178, PR-AUC=0.7051, F1=0.6571 @thresh=0.370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "xgboost CV:  60%|███████████████████▊             | 3/5 [00:37<00:24, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: acc=0.8686, logloss=0.2769, ROC-AUC=0.9058, PR-AUC=0.6131, F1=0.6000 @thresh=0.348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "xgboost CV:  80%|██████████████████████████▍      | 4/5 [00:53<00:13, 13.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: acc=0.8789, logloss=0.2729, ROC-AUC=0.9019, PR-AUC=0.6566, F1=0.6299 @thresh=0.461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "xgboost CV: 100%|█████████████████████████████████| 5/5 [01:05<00:00, 13.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: acc=0.8863, logloss=0.2603, ROC-AUC=0.9284, PR-AUC=0.6906, F1=0.6607 @thresh=0.556\n",
      "\n",
      "================================================================================\n",
      "Model: LIGHTGBM\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lightgbm CV:  20%|██████▍                         | 1/5 [00:04<00:17,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: acc=0.8866, logloss=0.2571, ROC-AUC=0.9030, PR-AUC=0.6633, F1=0.6504 @thresh=0.403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lightgbm CV:  40%|████████████▊                   | 2/5 [00:08<00:13,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: acc=0.8918, logloss=0.2417, ROC-AUC=0.9158, PR-AUC=0.7009, F1=0.6885 @thresh=0.376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lightgbm CV:  60%|███████████████████▏            | 3/5 [00:14<00:09,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: acc=0.8789, logloss=0.2481, ROC-AUC=0.9120, PR-AUC=0.6707, F1=0.6338 @thresh=0.292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lightgbm CV:  80%|█████████████████████████▌      | 4/5 [00:18<00:04,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: acc=0.8892, logloss=0.2499, ROC-AUC=0.9129, PR-AUC=0.6803, F1=0.6415 @thresh=0.568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lightgbm CV: 100%|████████████████████████████████| 5/5 [00:22<00:00,  4.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: acc=0.8889, logloss=0.2295, ROC-AUC=0.9379, PR-AUC=0.6953, F1=0.6600 @thresh=0.625\n",
      "\n",
      "================================================================================\n",
      "Model: CATBOOST\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "catboost CV:  20%|██████▍                         | 1/5 [00:04<00:19,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: acc=0.8814, logloss=0.2735, ROC-AUC=0.8993, PR-AUC=0.6448, F1=0.6412 @thresh=0.162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "catboost CV:  40%|████████████▊                   | 2/5 [00:09<00:14,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: acc=0.8995, logloss=0.2406, ROC-AUC=0.9113, PR-AUC=0.6884, F1=0.7154 @thresh=0.320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "catboost CV:  60%|███████████████████▏            | 3/5 [00:14<00:09,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: acc=0.8918, logloss=0.2338, ROC-AUC=0.9196, PR-AUC=0.7146, F1=0.6552 @thresh=0.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "catboost CV:  80%|█████████████████████████▌      | 4/5 [00:20<00:05,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: acc=0.8840, logloss=0.2973, ROC-AUC=0.8879, PR-AUC=0.5718, F1=0.6078 @thresh=0.582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "catboost CV: 100%|████████████████████████████████| 5/5 [00:25<00:00,  5.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: acc=0.8889, logloss=0.2356, ROC-AUC=0.9293, PR-AUC=0.6499, F1=0.6400 @thresh=0.325\n",
      "\n",
      "================================================================================\n",
      "Model: RANDOM_FOREST\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "random_forest CV:  20%|█████▍                     | 1/5 [00:02<00:08,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: acc=0.8866, logloss=0.4051, ROC-AUC=0.8586, PR-AUC=0.5559, F1=0.6195 @thresh=0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "random_forest CV:  40%|██████████▊                | 2/5 [00:04<00:06,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: acc=0.8943, logloss=0.4020, ROC-AUC=0.9020, PR-AUC=0.6236, F1=0.6557 @thresh=0.458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "random_forest CV:  60%|████████████████▏          | 3/5 [00:06<00:04,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: acc=0.8711, logloss=0.4032, ROC-AUC=0.8872, PR-AUC=0.5806, F1=0.6026 @thresh=0.407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "random_forest CV:  80%|█████████████████████▌     | 4/5 [00:08<00:02,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: acc=0.8943, logloss=0.4005, ROC-AUC=0.8877, PR-AUC=0.6157, F1=0.6496 @thresh=0.479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "random_forest CV: 100%|███████████████████████████| 5/5 [00:10<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: acc=0.8941, logloss=0.4046, ROC-AUC=0.9132, PR-AUC=0.6851, F1=0.6496 @thresh=0.490\n",
      "\n",
      "================================================================================\n",
      "Model: LOGISTIC\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logistic CV:  20%|██████▍                         | 1/5 [00:21<01:24, 21.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: acc=0.8608, logloss=0.3397, ROC-AUC=0.9038, PR-AUC=0.6761, F1=0.6408 @thresh=0.790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logistic CV:  40%|████████████▊                   | 2/5 [00:40<01:00, 20.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: acc=0.8686, logloss=0.3400, ROC-AUC=0.9118, PR-AUC=0.6196, F1=0.6885 @thresh=0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logistic CV:  60%|███████████████████▏            | 3/5 [01:01<00:40, 20.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: acc=0.8634, logloss=0.3301, ROC-AUC=0.9186, PR-AUC=0.6350, F1=0.6370 @thresh=0.531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logistic CV:  80%|█████████████████████████▌      | 4/5 [01:19<00:19, 19.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: acc=0.8737, logloss=0.3114, ROC-AUC=0.9032, PR-AUC=0.7233, F1=0.6833 @thresh=0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logistic CV: 100%|████████████████████████████████| 5/5 [01:39<00:00, 19.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: acc=0.8630, logloss=0.3121, ROC-AUC=0.9401, PR-AUC=0.7069, F1=0.6815 @thresh=0.562\n",
      "\n",
      "================================================================================\n",
      "CROSS-VALIDATION SUMMARY\n",
      "================================================================================\n",
      "Model           Accuracy     LogLoss      ROC-AUC      PR-AUC       F1          \n",
      "--------------------------------------------------------------------------------\n",
      "xgboost         0.8793±0.0067  0.2704±0.0086  0.9092±0.0127  0.6590±0.0349  0.6306±0.0253\n",
      "lightgbm        0.8871±0.0044  0.2453±0.0093  0.9163±0.0116  0.6821±0.0142  0.6548±0.0190\n",
      "catboost        0.8891±0.0063  0.2562±0.0251  0.9095±0.0146  0.6539±0.0484  0.6519±0.0353\n",
      "random_forest   0.8881±0.0090  0.4031±0.0017  0.8897±0.0183  0.6122±0.0439  0.6354±0.0207\n",
      "logistic        0.8659±0.0047  0.3267±0.0127  0.9155±0.0135  0.6722±0.0400  0.6662±0.0225\n",
      "\n",
      "================================================================================\n",
      "TRAINING FINAL MODELS ON FULL DATASET\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training final models:  20%|████▍                 | 1/5 [00:13<00:53, 13.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved xgboost_final_model.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training final models:  40%|████████▊             | 2/5 [00:21<00:31, 10.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved lightgbm_final_model.joblib\n",
      "\n",
      "[CV] END C=1.613212872540044, l1_ratio=0.9296976523425731, max_iter=200, penalty=l2, solver=saga; total time=   5.2s\n",
      "[CV] END C=6.335037565104235, l1_ratio=0.8714605901877177, max_iter=500, penalty=l2, solver=saga; total time=   8.1s\n",
      "[CV] END C=5.394422419156507, l1_ratio=0.8074401551640625, max_iter=200, penalty=elasticnet, solver=saga; total time=   7.4s\n",
      "[CV] END C=9.06928441545754, l1_ratio=0.2721322493846353, max_iter=1000, penalty=l2, solver=saga; total time=  10.6s\n",
      "[CV] END C=1.6475585314294172, l1_ratio=0.534089419375442, max_iter=500, penalty=l1, solver=saga; total time=  15.7s\n",
      "[CV] END C=6.925360328902704, l1_ratio=0.2694123337985215, max_iter=1000, penalty=elasticnet, solver=saga; total time=  18.9s\n",
      "[CV] END C=3.233029320207552, l1_ratio=0.5187906217433661, max_iter=200, penalty=l1, solver=saga; total time=   6.5s\n",
      "[CV] END C=0.6499224710898156, l1_ratio=0.2539154139343447, max_iter=500, penalty=elasticnet, solver=saga; total time=   2.3s\n",
      "[CV] END C=4.973485058923855, l1_ratio=0.30087830981676966, max_iter=200, penalty=l1, solver=saga; total time=   6.6s\n",
      "[CV] END C=2.6688101427528497, l1_ratio=0.9766149558326529, max_iter=500, penalty=elasticnet, solver=saga; total time=  15.7s\n",
      "[CV] END C=2.7874646423661145, l1_ratio=0.9082658859666537, max_iter=1000, penalty=l2, solver=saga; total time=   6.6s\n",
      "[CV] END C=1.4499487209122308, l1_ratio=0.489452760277563, max_iter=500, penalty=elasticnet, solver=saga; total time=   5.0s\n",
      "[CV] END C=6.722355474058786, l1_ratio=0.7616196153287176, max_iter=1000, penalty=l1, solver=saga; total time=  33.2s\n",
      "[CV] END C=7.283163486118596, l1_ratio=0.3677831327192532, max_iter=500, penalty=l2, solver=saga; total time=   9.0s\n",
      "[CV] END C=3.9892444244455305, l1_ratio=0.8164318732193839, max_iter=200, penalty=l1, solver=saga; total time=   6.5s\n",
      "[CV] END C=3.2088006497173582, l1_ratio=0.18651851039985423, max_iter=200, penalty=elasticnet, solver=saga; total time=   7.7s\n",
      "\n",
      "[CV] END C=0.46550412719997725, l1_ratio=0.6075448519014384, max_iter=200, penalty=l1, solver=saga; total time=   6.3s\n",
      "[CV] END C=0.46550412719997725, l1_ratio=0.6075448519014384, max_iter=200, penalty=l1, solver=saga; total time=   5.6s\n",
      "[CV] END C=3.855165025399161, l1_ratio=0.015966252220214194, max_iter=500, penalty=elasticnet, solver=saga; total time=  10.9s\n",
      "[CV] END C=6.833635188254583, l1_ratio=0.6099966577826209, max_iter=1000, penalty=elasticnet, solver=saga; total time=  20.0s\n",
      "[CV] END C=9.09420402078782, l1_ratio=0.2587799816000169, max_iter=500, penalty=l2, solver=saga; total time=  10.8s\n",
      "[CV] END C=5.2016802117781085, l1_ratio=0.5467102793432796, max_iter=500, penalty=l1, solver=saga; total time=  16.3s\n",
      "[CV] END C=9.696846277645585, l1_ratio=0.7751328233611146, max_iter=500, penalty=l2, solver=saga; total time=  12.7s\n",
      "[CV] END C=8.949273504276487, l1_ratio=0.5978999788110851, max_iter=1000, penalty=l2, solver=saga; total time=  11.0s\n",
      "[CV] END C=1.9608286241914519, l1_ratio=0.045227288910538066, max_iter=200, penalty=l1, solver=saga; total time=   6.4s\n",
      "[CV] END C=1.9608286241914519, l1_ratio=0.045227288910538066, max_iter=200, penalty=l1, solver=saga; total time=   7.1s\n",
      "[CV] END C=2.7144903177389588, l1_ratio=0.8287375091519293, max_iter=500, penalty=l1, solver=saga; total time=  16.5s\n",
      "[CV] END C=2.8103450968738075, l1_ratio=0.5426960831582485, max_iter=200, penalty=l1, solver=saga; total time=   7.1s\n",
      "[CV] END C=8.022969807540397, l1_ratio=0.07455064367977082, max_iter=1000, penalty=l1, solver=saga; total time=  34.2s\n",
      "[CV] END C=7.723447692966574, l1_ratio=0.1987156815341724, max_iter=1000, penalty=elasticnet, solver=saga; total time=  18.7s\n",
      "[CV] END C=1.9894240408880515, l1_ratio=0.71134195274865, max_iter=1000, penalty=l1, solver=saga; total time=  32.1s\n",
      "[CV] END C=6.060599747810114, l1_ratio=0.926300878513349, max_iter=500, penalty=l1, solver=saga; total time=  17.0s\n",
      "[CV] END C=9.150596755437807, l1_ratio=0.8500385777897993, max_iter=500, penalty=l1, solver=saga; total time=  16.9s\n",
      "[CV] END C=0.6365835028602363, l1_ratio=0.3109823217156622, max_iter=200, penalty=elasticnet, solver=saga; total time=   2.5s\n",
      "[CV] END C=5.913977877077271, l1_ratio=0.27472179299006416, max_iter=1000, penalty=l1, solver=saga; total time=  32.3s\n",
      "[CV] END C=3.830268747537898, l1_ratio=0.9717120953891037, max_iter=1000, penalty=l1, solver=saga; total time=  32.8s\n",
      "[CV] END C=7.218295211648733, l1_ratio=0.23598491974895575, max_iter=500, penalty=elasticnet, solver=saga; total time=  18.5s\n",
      "[CV] END C=0.40533589538431347, l1_ratio=0.7106628896857874, max_iter=500, penalty=l2, solver=saga; total time=   1.3s\n",
      "[CV] END C=0.40533589538431347, l1_ratio=0.7106628896857874, max_iter=500, penalty=l2, solver=saga; total time=   1.6s\n",
      "[CV] END C=0.40533589538431347, l1_ratio=0.7106628896857874, max_iter=500, penalty=l2, solver=saga; total time=   1.6s\n",
      "[CV] END C=4.394365018657702, l1_ratio=0.2017192023353962, max_iter=1000, penalty=l1, solver=saga; total time=  34.7s\n",
      "[CV] END C=3.144559810763267, l1_ratio=0.5085706911647028, max_iter=500, penalty=l1, solver=saga; total time=  16.1s\n",
      "[CV] END C=2.4939222914887496, l1_ratio=0.41038292303562973, max_iter=1000, penalty=l1, solver=saga; total time=  32.7s\n",
      "[CV] END C=2.2889816549162245, l1_ratio=0.07697990982879299, max_iter=1000, penalty=elasticnet, solver=saga; total time=   8.8s\n",
      "[CV] END C=1.613212872540044, l1_ratio=0.9296976523425731, max_iter=200, penalty=l2, solver=saga; total time=   3.4s\n",
      "[CV] END C=6.335037565104235, l1_ratio=0.8714605901877177, max_iter=500, penalty=l2, solver=saga; total time=   8.5s\n",
      "[CV] END C=5.394422419156507, l1_ratio=0.8074401551640625, max_iter=200, penalty=elasticnet, solver=saga; total time=   6.7s\n",
      "[CV] END C=9.06928441545754, l1_ratio=0.2721322493846353, max_iter=1000, penalty=l2, solver=saga; total time=  10.6s\n",
      "[CV] END C=1.6475585314294172, l1_ratio=0.534089419375442, max_iter=500, penalty=l1, solver=saga; total time=  15.7s\n",
      "[CV] END C=6.925360328902704, l1_ratio=0.2694123337985215, max_iter=1000, penalty=elasticnet, solver=saga; total time=  18.4s\n",
      "[CV] END C=3.233029320207552, l1_ratio=0.5187906217433661, max_iter=200, penalty=l1, solver=saga; total time=   6.3s\n",
      "[CV] END C=0.6499224710898156, l1_ratio=0.2539154139343447, max_iter=500, penalty=elasticnet, solver=saga; total time=   3.6s\n",
      "[CV] END C=4.973485058923855, l1_ratio=0.30087830981676966, max_iter=200, penalty=l1, solver=saga; total time=   7.3s\n",
      "[CV] END C=2.6688101427528497, l1_ratio=0.9766149558326529, max_iter=500, penalty=elasticnet, solver=saga; total time=  16.0s\n",
      "[CV] END C=2.7874646423661145, l1_ratio=0.9082658859666537, max_iter=1000, penalty=l2, solver=saga; total time=   4.4s\n",
      "[CV] END C=1.4499487209122308, l1_ratio=0.489452760277563, max_iter=500, penalty=elasticnet, solver=saga; total time=   5.6s\n",
      "[CV] END C=6.722355474058786, l1_ratio=0.7616196153287176, max_iter=1000, penalty=l1, solver=saga; total time=  34.5s\n",
      "[CV] END C=7.283163486118596, l1_ratio=0.3677831327192532, max_iter=500, penalty=l2, solver=saga; total time=   9.0s\n",
      "[CV] END C=3.9892444244455305, l1_ratio=0.8164318732193839, max_iter=200, penalty=l1, solver=saga; total time=   6.5s\n",
      "[CV] END C=3.2088006497173582, l1_ratio=0.18651851039985423, max_iter=200, penalty=elasticnet, solver=saga; total time=   8.1s\n",
      "\n",
      "[CV] END C=4.973485058923855, l1_ratio=0.30087830981676966, max_iter=200, penalty=l1, solver=saga; total time=   6.8s\n",
      "[CV] END C=2.6688101427528497, l1_ratio=0.9766149558326529, max_iter=500, penalty=elasticnet, solver=saga; total time=  15.6s\n",
      "[CV] END C=2.7874646423661145, l1_ratio=0.9082658859666537, max_iter=1000, penalty=l2, solver=saga; total time=   4.2s\n",
      "[CV] END C=1.4499487209122308, l1_ratio=0.489452760277563, max_iter=500, penalty=elasticnet, solver=saga; total time=   5.2s\n",
      "[CV] END C=6.722355474058786, l1_ratio=0.7616196153287176, max_iter=1000, penalty=l1, solver=saga; total time=  34.5s\n",
      "[CV] END C=7.283163486118596, l1_ratio=0.3677831327192532, max_iter=500, penalty=l2, solver=saga; total time=   9.3s\n",
      "[CV] END C=3.9892444244455305, l1_ratio=0.8164318732193839, max_iter=200, penalty=l1, solver=saga; total time=   6.6s\n",
      "[CV] END C=3.2088006497173582, l1_ratio=0.18651851039985423, max_iter=200, penalty=elasticnet, solver=saga; total time=   8.0s\n",
      "\n",
      "[CV] END bootstrap=True, max_depth=9, max_features=sqrt, min_samples_leaf=8, min_samples_split=18, n_estimators=236; total time=   8.6s\n",
      "[CV] END bootstrap=True, max_depth=6, max_features=log2, min_samples_leaf=6, min_samples_split=6, n_estimators=273; total time=   3.6s\n",
      "[CV] END bootstrap=True, max_depth=6, max_features=log2, min_samples_leaf=6, min_samples_split=6, n_estimators=273; total time=   3.4s\n",
      "[CV] END bootstrap=True, max_depth=5, max_features=None, min_samples_leaf=2, min_samples_split=13, n_estimators=267; total time= 3.5min\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=None, min_samples_leaf=4, min_samples_split=12, n_estimators=233; total time= 8.7min\n",
      "[CV] END bootstrap=True, max_depth=21, max_features=None, min_samples_leaf=6, min_samples_split=6, n_estimators=165; total time= 2.8min\n",
      "[CV] END bootstrap=False, max_depth=7, max_features=None, min_samples_leaf=3, min_samples_split=8, n_estimators=101; total time= 2.8min\n",
      "[CV] END bootstrap=True, max_depth=5, max_features=None, min_samples_leaf=2, min_samples_split=9, n_estimators=178; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=None, min_samples_leaf=4, min_samples_split=2, n_estimators=201; total time= 6.8min\n",
      "[CV] END C=3.746401188473625, l1_ratio=0.9507143064099162, max_iter=1000, penalty=l1, solver=saga; total time=  34.2s\n",
      "[CV] END C=5.96950157946487, l1_ratio=0.44583275285359114, max_iter=1000, penalty=elasticnet, solver=saga; total time=  16.7s\n",
      "[CV] END C=4.593488919658672, l1_ratio=0.33370861113902184, max_iter=1000, penalty=l2, solver=saga; total time=   6.6s\n",
      "[CV] END C=0.008787658410143284, l1_ratio=0.9922115592912175, max_iter=200, penalty=l2, solver=saga; total time=   0.5s\n",
      "[CV] END C=0.008787658410143284, l1_ratio=0.9922115592912175, max_iter=200, penalty=l2, solver=saga; total time=   0.6s\n",
      "[CV] END C=5.248564316322379, l1_ratio=0.43194501864211576, max_iter=200, penalty=elasticnet, solver=saga; total time=   7.9s\n",
      "[CV] END C=6.119528947223795, l1_ratio=0.13949386065204183, max_iter=1000, penalty=l2, solver=saga; total time=   7.8s\n",
      "[CV] END C=0.907064345328208, l1_ratio=0.6183860093330873, max_iter=1000, penalty=l1, solver=saga; total time=  10.3s\n",
      "[CV] END C=0.46550412719997725, l1_ratio=0.6075448519014384, max_iter=200, penalty=l1, solver=saga; total time=   6.4s\n",
      "[CV] END C=0.6515159298527952, l1_ratio=0.9488855372533332, max_iter=500, penalty=l2, solver=saga; total time=   2.5s\n",
      "[CV] END C=0.6515159298527952, l1_ratio=0.9488855372533332, max_iter=500, penalty=l2, solver=saga; total time=   1.8s\n",
      "[CV] END C=0.6515159298527952, l1_ratio=0.9488855372533332, max_iter=500, penalty=l2, solver=saga; total time=   1.7s\n",
      "[CV] END C=3.855165025399161, l1_ratio=0.015966252220214194, max_iter=500, penalty=elasticnet, solver=saga; total time=  11.2s\n",
      "[CV] END C=6.833635188254583, l1_ratio=0.6099966577826209, max_iter=1000, penalty=elasticnet, solver=saga; total time=  23.6s\n",
      "[CV] END C=9.09420402078782, l1_ratio=0.2587799816000169, max_iter=500, penalty=l2, solver=saga; total time=  11.1s\n",
      "[CV] END C=5.2016802117781085, l1_ratio=0.5467102793432796, max_iter=500, penalty=l1, solver=saga; total time=  17.9s\n",
      "[CV] END C=9.696846277645585, l1_ratio=0.7751328233611146, max_iter=500, penalty=l2, solver=saga; total time=  12.7s\n",
      "[CV] END C=8.949273504276487, l1_ratio=0.5978999788110851, max_iter=1000, penalty=l2, solver=saga; total time=  11.5s\n",
      "[CV] END C=1.9608286241914519, l1_ratio=0.045227288910538066, max_iter=200, penalty=l1, solver=saga; total time=   6.8s\n",
      "[CV] END C=2.7144903177389588, l1_ratio=0.8287375091519293, max_iter=500, penalty=l1, solver=saga; total time=  16.0s\n",
      "[CV] END C=2.8103450968738075, l1_ratio=0.5426960831582485, max_iter=200, penalty=l1, solver=saga; total time=   6.5s\n",
      "[CV] END C=8.022969807540397, l1_ratio=0.07455064367977082, max_iter=1000, penalty=l1, solver=saga; total time=  35.2s\n",
      "[CV] END C=7.723447692966574, l1_ratio=0.1987156815341724, max_iter=1000, penalty=elasticnet, solver=saga; total time=  18.6s\n",
      "[CV] END C=1.9894240408880515, l1_ratio=0.71134195274865, max_iter=1000, penalty=l1, solver=saga; total time=  33.1s\n",
      "[CV] END C=6.060599747810114, l1_ratio=0.926300878513349, max_iter=500, penalty=l1, solver=saga; total time=  16.3s\n",
      "[CV] END C=9.150596755437807, l1_ratio=0.8500385777897993, max_iter=500, penalty=l1, solver=saga; total time=  17.1s\n",
      "[CV] END C=0.6365835028602363, l1_ratio=0.3109823217156622, max_iter=200, penalty=elasticnet, solver=saga; total time=   2.7s\n",
      "[CV] END C=5.913977877077271, l1_ratio=0.27472179299006416, max_iter=1000, penalty=l1, solver=saga; total time=  33.8s\n",
      "[CV] END C=3.830268747537898, l1_ratio=0.9717120953891037, max_iter=1000, penalty=l1, solver=saga; total time=  34.0s\n",
      "[CV] END C=7.218295211648733, l1_ratio=0.23598491974895575, max_iter=500, penalty=elasticnet, solver=saga; total time=  19.6s\n",
      "[CV] END C=4.394365018657702, l1_ratio=0.2017192023353962, max_iter=1000, penalty=l1, solver=saga; total time=  34.0s\n",
      "[CV] END C=3.144559810763267, l1_ratio=0.5085706911647028, max_iter=500, penalty=l1, solver=saga; total time=  17.0s\n",
      "[CV] END C=2.4939222914887496, l1_ratio=0.41038292303562973, max_iter=1000, penalty=l1, solver=saga; total time=  33.0s\n",
      "[CV] END C=2.2889816549162245, l1_ratio=0.07697990982879299, max_iter=1000, penalty=elasticnet, solver=saga; total time=   7.6s\n",
      "[CV] END C=1.613212872540044, l1_ratio=0.9296976523425731, max_iter=200, penalty=l2, solver=saga; total time=   2.9s\n",
      "[CV] END C=6.335037565104235, l1_ratio=0.8714605901877177, max_iter=500, penalty=l2, solver=saga; total time=   8.2s\n",
      "[CV] END C=5.394422419156507, l1_ratio=0.8074401551640625, max_iter=200, penalty=elasticnet, solver=saga; total time=   6.6s\n",
      "[CV] END C=9.06928441545754, l1_ratio=0.2721322493846353, max_iter=1000, penalty=l2, solver=saga; total time=  10.6s\n",
      "[CV] END C=0.006203769953158188, l1_ratio=0.352568856334169, max_iter=1000, penalty=elasticnet, solver=saga; total time=   0.5s\n",
      "[CV] END C=1.6475585314294172, l1_ratio=0.534089419375442, max_iter=500, penalty=l1, solver=saga; total time=  16.1s\n",
      "[CV] END C=6.925360328902704, l1_ratio=0.2694123337985215, max_iter=1000, penalty=elasticnet, solver=saga; total time=  20.1s\n",
      "[CV] END C=3.233029320207552, l1_ratio=0.5187906217433661, max_iter=200, penalty=l1, solver=saga; total time=   6.9s\n",
      "[CV] END C=4.973485058923855, l1_ratio=0.30087830981676966, max_iter=200, penalty=l1, solver=saga; total time=   6.9s\n",
      "[CV] END C=2.6688101427528497, l1_ratio=0.9766149558326529, max_iter=500, penalty=elasticnet, solver=saga; total time=  16.7s\n",
      "[CV] END C=2.7874646423661145, l1_ratio=0.9082658859666537, max_iter=1000, penalty=l2, solver=saga; total time=   4.4s\n",
      "[CV] END C=1.4499487209122308, l1_ratio=0.489452760277563, max_iter=500, penalty=elasticnet, solver=saga; total time=   6.1s\n",
      "[CV] END C=6.722355474058786, l1_ratio=0.7616196153287176, max_iter=1000, penalty=l1, solver=saga; total time=  34.3s\n",
      "[CV] END C=7.283163486118596, l1_ratio=0.3677831327192532, max_iter=500, penalty=l2, solver=saga; total time=   9.0s\n",
      "[CV] END C=3.9892444244455305, l1_ratio=0.8164318732193839, max_iter=200, penalty=l1, solver=saga; total time=   6.9s\n",
      "[CV] END C=3.2088006497173582, l1_ratio=0.18651851039985423, max_iter=200, penalty=elasticnet, solver=saga; total time=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training final models:  60%|█████████████▏        | 3/5 [00:27<00:16,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved catboost_final_model.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training final models:  80%|█████████████████▌    | 4/5 [00:29<00:05,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved random_forest_final_model.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training final models: 100%|██████████████████████| 5/5 [00:56<00:00, 11.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved logistic_final_model.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, average_precision_score, f1_score, precision_recall_curve\n",
    "# -----------------------------\n",
    "# Load best parameters (or use defaults)\n",
    "# -----------------------------\n",
    "try:\n",
    "    best_params = joblib.load('best_hyperparameters.joblib')\n",
    "    print(\"Loaded tuned hyperparameters!\")\n",
    "    print(\"=\"*80)\n",
    "except:\n",
    "    print(\"No tuned parameters found, using defaults...\")\n",
    "    print(\"=\"*80)\n",
    "    best_params = {\n",
    "        'xgboost': {'max_depth': 6, 'learning_rate': 0.1, 'n_estimators': 200, \n",
    "                    'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_weight': 3, \n",
    "                    'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 1.0},\n",
    "        'lightgbm': {'max_depth': 6, 'learning_rate': 0.1, 'n_estimators': 200, \n",
    "                     'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_weight': 3, \n",
    "                     'reg_alpha': 0.1, 'reg_lambda': 1.0, 'num_leaves': 31},\n",
    "        'catboost': {'depth': 6, 'learning_rate': 0.1, 'iterations': 200, \n",
    "                     'l2_leaf_reg': 3, 'border_count': 128, 'bagging_temperature': 0.5},\n",
    "        'random_forest': {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, \n",
    "                         'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': True},\n",
    "        'logistic': {'C': 0.1, 'penalty': 'l2', 'max_iter': 500}\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# Compute class weights\n",
    "# -----------------------------\n",
    "n_pos = np.sum(y_train == 1)\n",
    "n_neg = np.sum(y_train == 0)\n",
    "scale_pos_weight = n_neg / n_pos if n_pos > 0 else 1\n",
    "\n",
    "print(f\"Class distribution - Negative: {n_neg}, Positive: {n_pos}\")\n",
    "print(f\"Scale pos weight: {scale_pos_weight:.4f}\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# Define models with tuned parameters\n",
    "# -----------------------------\n",
    "def get_models(best_params, scale_pos_weight):\n",
    "    return {\n",
    "        'xgboost': xgb.XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            eval_metric='logloss',\n",
    "            tree_method='hist',\n",
    "            device='cpu',\n",
    "            random_state=42,\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            **best_params['xgboost']\n",
    "        ),\n",
    "        'lightgbm': lgb.LGBMClassifier(\n",
    "            objective='binary',\n",
    "            metric='binary_logloss',\n",
    "            device='cpu',\n",
    "            random_state=42,\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            verbose=-1,\n",
    "            **best_params['lightgbm']\n",
    "        ),\n",
    "        'catboost': CatBoostClassifier(\n",
    "            random_seed=42,\n",
    "            verbose=False,\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            **best_params['catboost']\n",
    "        ),\n",
    "        'random_forest': RandomForestClassifier(\n",
    "            class_weight='balanced',\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            **best_params['random_forest']\n",
    "        ),\n",
    "        'logistic': LogisticRegression(\n",
    "            class_weight='balanced',\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            **best_params['logistic']\n",
    "        )\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# Cross-validation for all models\n",
    "# -----------------------------\n",
    "k = 5\n",
    "cv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "model_scores = {name: {'acc': [], 'logloss': [], 'roc_auc': [], 'pr_auc': [], 'f1': [], 'thresh': []} \n",
    "                for name in ['xgboost', 'lightgbm', 'catboost', 'random_forest', 'logistic']}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CROSS-VALIDATION FOR ALL MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "oof_preds = {name: np.zeros(len(X_train_reduced)) for name in model_names}\n",
    "\n",
    "for model_name in ['xgboost', 'lightgbm', 'catboost', 'random_forest', 'logistic']:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Model: {model_name.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(tqdm(cv.split(X_train_reduced, y_train), \n",
    "                                                       total=k, \n",
    "                                                       desc=f\"{model_name} CV\"), 1):\n",
    "        X_tr, X_val = X_train_reduced[train_idx], X_train_reduced[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        # Get fresh model for this fold\n",
    "        models = get_models(best_params, scale_pos_weight)\n",
    "        model = models[model_name]\n",
    "        \n",
    "        # Train model\n",
    "        if model_name == 'catboost':\n",
    "            model.fit(X_tr, y_tr, verbose=False)\n",
    "        elif model_name == 'lightgbm':\n",
    "            model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], callbacks=[lgb.early_stopping(50, verbose=False)])\n",
    "        else:\n",
    "            model.fit(X_tr, y_tr)\n",
    "        \n",
    "        # Predict probabilities\n",
    "        y_prob = model.predict_proba(X_val)[:, 1]\n",
    "        y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "        oof_preds[model_name][val_idx] = y_prob\n",
    "        \n",
    "        # Metrics\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        ll = log_loss(y_val, y_prob)\n",
    "        roc = roc_auc_score(y_val, y_prob)\n",
    "        pr = average_precision_score(y_val, y_prob)\n",
    "        \n",
    "        # Find best threshold by F1\n",
    "        precisions, recalls, thresholds = precision_recall_curve(y_val, y_prob)\n",
    "        f1_scores = 2 * (precisions[:-1] * recalls[:-1]) / (precisions[:-1] + recalls[:-1] + 1e-12)\n",
    "        best_idx = np.argmax(f1_scores) if f1_scores.size else 0\n",
    "        best_thresh = thresholds[best_idx] if f1_scores.size else 0.5\n",
    "        best_f1 = f1_scores[best_idx] if f1_scores.size else f1_score(y_val, y_pred)\n",
    "        \n",
    "        model_scores[model_name]['acc'].append(acc)\n",
    "        model_scores[model_name]['logloss'].append(ll)\n",
    "        model_scores[model_name]['roc_auc'].append(roc)\n",
    "        model_scores[model_name]['pr_auc'].append(pr)\n",
    "        model_scores[model_name]['f1'].append(best_f1)\n",
    "        model_scores[model_name]['thresh'].append(best_thresh)\n",
    "        \n",
    "        print(f\"Fold {fold}: acc={acc:.4f}, logloss={ll:.4f}, ROC-AUC={roc:.4f}, PR-AUC={pr:.4f}, F1={best_f1:.4f} @thresh={best_thresh:.3f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Print CV summary\n",
    "# -----------------------------\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"CROSS-VALIDATION SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"{'Model':<15} {'Accuracy':<12} {'LogLoss':<12} {'ROC-AUC':<12} {'PR-AUC':<12} {'F1':<12}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for model_name in ['xgboost', 'lightgbm', 'catboost', 'random_forest', 'logistic']:\n",
    "    scores = model_scores[model_name]\n",
    "    print(f\"{model_name:<15} \"\n",
    "          f\"{np.mean(scores['acc']):.4f}±{np.std(scores['acc']):.4f}  \"\n",
    "          f\"{np.mean(scores['logloss']):.4f}±{np.std(scores['logloss']):.4f}  \"\n",
    "          f\"{np.mean(scores['roc_auc']):.4f}±{np.std(scores['roc_auc']):.4f}  \"\n",
    "          f\"{np.mean(scores['pr_auc']):.4f}±{np.std(scores['pr_auc']):.4f}  \"\n",
    "          f\"{np.mean(scores['f1']):.4f}±{np.std(scores['f1']):.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Train final models on full data\n",
    "# -----------------------------\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TRAINING FINAL MODELS ON FULL DATASET\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "final_models = get_models(best_params, scale_pos_weight)\n",
    "test_predictions = {}\n",
    "\n",
    "for model_name, model in tqdm(final_models.items(), desc=\"Training final models\"):\n",
    "    if model_name == 'catboost':\n",
    "        model.fit(X_train_reduced, y_train, verbose=False)\n",
    "    elif model_name == 'lightgbm':\n",
    "        model.fit(X_train_reduced, y_train, callbacks=[lgb.log_evaluation(0)])\n",
    "    else:\n",
    "        model.fit(X_train_reduced, y_train)\n",
    "    \n",
    "    test_predictions[model_name] = model.predict_proba(X_test_reduced)[:, 1]\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(model, f\"{model_name}_final_model.joblib\")\n",
    "    print(f\"Saved {model_name}_final_model.joblib\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9919f04d-c4a9-4592-97e0-c581181d1beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(oof_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7d128302-5b38-4230-8e1c-4c36f568cbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ENSEMBLE PREDICTIONS\n",
      "================================================================================\n",
      "\n",
      "Model weights (based on CV F1):\n",
      "  xgboost: 0.0000\n",
      "  lightgbm: 0.4692\n",
      "  catboost: 0.4560\n",
      "  random_forest: 0.0000\n",
      "  logistic: 0.0747\n",
      "\n",
      "Average optimal threshold: 0.4678\n",
      "Saved submission_xgboost.csv (threshold=0.4499)\n",
      "Saved submission_lightgbm.csv (threshold=0.4527)\n",
      "Saved submission_catboost.csv (threshold=0.3503)\n",
      "Saved submission_random_forest.csv (threshold=0.4665)\n",
      "Saved submission_logistic.csv (threshold=0.6194)\n",
      "\n",
      "Saved submission_ensemble.csv (weighted average, threshold=0.4678)\n",
      "Saved submission_conservative.csv (majority voting, 3/5 agreement)\n",
      "\n",
      "================================================================================\n",
      "COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import f1_score\n",
    "# -----------------------------\n",
    "# Ensemble predictions\n",
    "# -----------------------------\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ENSEMBLE PREDICTIONS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Weighted average based on CV F1 scores\n",
    "#weights = {name: np.mean(model_scores[name]['f1']) for name in final_models.keys()}\n",
    "#total_weight = sum(weights.values())\n",
    "#weights = {name: w/total_weight for name, w in weights.items()}\n",
    "\n",
    "##################### test\n",
    "\n",
    "\n",
    "model_names = list(final_models.keys())\n",
    "n_models = len(model_names)\n",
    "\n",
    "def objective(weights):\n",
    "    weights = np.array(weights)\n",
    "    weights = weights / weights.sum()  # normalize\n",
    "    ensemble_pred = sum(weights[i] * oof_preds[m] for i, m in enumerate(model_names))\n",
    "    return log_loss(y_train, ensemble_pred)\n",
    "\n",
    "# Initial equal weights\n",
    "x0 = np.ones(n_models) / n_models\n",
    "\n",
    "# Constraints: weights sum to 1\n",
    "constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "bounds = [(0, 1) for _ in range(n_models)]\n",
    "\n",
    "res = minimize(objective, x0, bounds=bounds, constraints=constraints)\n",
    "best_weights = res.x / res.x.sum()\n",
    "weights = dict(zip(model_names, best_weights))\n",
    "\n",
    "\n",
    "#####################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Model weights (based on CV F1):\")\n",
    "for name, weight in weights.items():\n",
    "    print(f\"  {name}: {weight:.4f}\")\n",
    "\n",
    "# Compute weighted ensemble\n",
    "ensemble_probs = np.zeros(len(X_test_reduced))\n",
    "for model_name, prob in test_predictions.items():\n",
    "    ensemble_probs += weights[model_name] * prob\n",
    "\n",
    "# Compute average threshold from all models\n",
    "avg_threshold = np.mean([np.mean(model_scores[name]['thresh']) for name in final_models.keys()])\n",
    "print(f\"\\nAverage optimal threshold: {avg_threshold:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Generate submissions\n",
    "# -----------------------------\n",
    "import pandas as pd\n",
    "\n",
    "# Individual model submissions\n",
    "for model_name, prob in test_predictions.items():\n",
    "    thresh = np.mean(model_scores[model_name]['thresh'])\n",
    "    pred = (prob >= thresh).astype(int)\n",
    "    submission = pd.DataFrame({\"id\": ids_test, \"label\": pred})\n",
    "    submission.to_csv(f\"submission_{model_name}.csv\", index=False)\n",
    "    print(f\"Saved submission_{model_name}.csv (threshold={thresh:.4f})\")\n",
    "\n",
    "# Ensemble submission\n",
    "ensemble_pred = (ensemble_probs >= avg_threshold).astype(int)\n",
    "submission_ensemble = pd.DataFrame({\"id\": ids_test, \"label\": ensemble_pred})\n",
    "submission_ensemble.to_csv(\"submission_ensemble.csv\", index=False)\n",
    "print(f\"\\nSaved submission_ensemble.csv (weighted average, threshold={avg_threshold:.4f})\")\n",
    "\n",
    "# Conservative ensemble (require multiple models to agree)\n",
    "conservative_pred = np.zeros(len(X_test_reduced))\n",
    "for prob in test_predictions.values():\n",
    "    conservative_pred += (prob >= 0.5).astype(int)\n",
    "conservative_pred = (conservative_pred >= 3).astype(int)  # At least 3 models agree\n",
    "submission_conservative = pd.DataFrame({\"id\": ids_test, \"label\": conservative_pred})\n",
    "submission_conservative.to_csv(\"submission_conservative.csv\", index=False)\n",
    "print(f\"Saved submission_conservative.csv (majority voting, 3/5 agreement)\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"COMPLETE!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0835d99f-cdb5-490f-b32a-be2ba02fbe8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
